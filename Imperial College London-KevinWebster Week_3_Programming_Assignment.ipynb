{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "tensor-flow-2-1",
      "graded_item_id": "mtZ4n",
      "launcher_item_id": "WphgK"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Week 3 Programming Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satyake/Deep-Learning/blob/master/Imperial%20College%20London-KevinWebster%20Week_3_Programming_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crtnb3v_-QN8"
      },
      "source": [
        "# Programming Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5lhOgL2-QN9"
      },
      "source": [
        "## Model validation on the Iris dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mu5pYMU-QN-"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "In this notebook, you will build, compile and fit a neural network model to the Iris dataset. You will also implement validation, regularisation and callbacks to improve your model.\n",
        "\n",
        "Some code cells are provided you in the notebook. You should avoid editing provided code, and make sure to execute the cells in order to avoid unexpected errors. Some cells begin with the line: \n",
        "\n",
        "`#### GRADED CELL ####`\n",
        "\n",
        "Don't move or edit this first line - this is what the automatic grader looks for to recognise graded cells. These cells require you to write your own code to complete them, and are automatically graded when you submit the notebook. Don't edit the function name or signature provided in these cells, otherwise the automatic grader might not function properly. Inside these graded cells, you can use any functions or classes that are imported below, but make sure you don't use any variables that are outside the scope of the function.\n",
        "\n",
        "### How to submit\n",
        "\n",
        "Complete all the tasks you are asked for in the worksheet. When you have finished and are happy with your code, press the **Submit Assignment** button at the top of this notebook.\n",
        "\n",
        "### Let's get started!\n",
        "\n",
        "We'll start running some imports, and loading the dataset. Do not edit the existing imports in the following cell. If you would like to make further Tensorflow imports, you should add them here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcJ88o-A-QOA"
      },
      "source": [
        "#### PACKAGE IMPORTS ####\n",
        "\n",
        "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
        "from numpy.random import seed\n",
        "seed(8)\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets, model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "\n",
        "# If you would like to make further imports from tensorflow, add them here\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVxBqpU_-QOF"
      },
      "source": [
        "#### The Iris dataset\n",
        "\n",
        "In this assignment, you will use the [Iris dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html). It consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. For a reference, see the following papers:\n",
        "\n",
        "- R. A. Fisher. \"The use of multiple measurements in taxonomic problems\". Annals of Eugenics. 7 (2): 179â€“188, 1936.\n",
        "\n",
        "Your goal is to construct a neural network that classifies each sample into the correct class, as well as applying validation and regularisation techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcDc7CXG-QOG"
      },
      "source": [
        "#### Load and preprocess the data\n",
        "\n",
        "First read in the Iris dataset using `datasets.load_iris()`, and split the dataset into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QCdzIiC-QOH"
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def read_in_and_split_data(iris_data):\n",
        "    \"\"\"\n",
        "    This function takes the Iris dataset as loaded by sklearn.datasets.load_iris(), and then \n",
        "    splits so that the training set includes 90% of the full dataset, with the test set \n",
        "    making up the remaining 10%.\n",
        "    Your function should return a tuple (train_data, test_data, train_targets, test_targets) \n",
        "    of appropriately split training and test data and targets.\n",
        "    \n",
        "    If you would like to import any further packages to aid you in this task, please do so in the \n",
        "    Package Imports cell above.\n",
        "    \"\"\"\n",
        "    x_train,x_test,y_train,y_test=train_test_split(iris_data['data'],iris_data['target'],test_size=0.10, random_state=1)\n",
        "    return   (x_train,x_test,y_train,y_test)  "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVTDnj1W-QOJ"
      },
      "source": [
        "# Run your function to generate the test and training data.\n",
        "\n",
        "iris_data = datasets.load_iris()\n",
        "train_data, test_data, train_targets, test_targets = read_in_and_split_data(iris_data)\n",
        "#iris_data['']"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i_TGqos-QON"
      },
      "source": [
        "We will now convert the training and test targets using a one hot encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uolvGsLl-QOO"
      },
      "source": [
        "# Convert targets to a one-hot encoding\n",
        "\n",
        "train_targets = tf.keras.utils.to_categorical(np.array(train_targets))\n",
        "test_targets = tf.keras.utils.to_categorical(np.array(test_targets))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_targets.shape\n",
        "test_targets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY1-I2bs1CN3",
        "outputId": "37b2adc9-f0ed-4a95-dee6-d3501b4152df"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeGhb9pA2ibI",
        "outputId": "d24752d3-855a-4ec2-f206-c1cb6a8860a0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(135, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t1SZvAX72P2-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6i8xjbh-QOR"
      },
      "source": [
        "#### Build the neural network model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDQeTk4u-QOT"
      },
      "source": [
        "You can now construct a model to fit to the data. Using the Sequential API, build your model according to the following specifications:\n",
        "\n",
        "* The model should use the `input_shape` in the function argument to set the input size in the first layer.\n",
        "* The first layer should be a dense layer with 64 units.\n",
        "* The weights of the first layer should be initialised with the He uniform initializer.\n",
        "* The biases of the first layer should be all initially equal to one.\n",
        "* There should then be a further four dense layers, each with 128 units.\n",
        "* This should be followed with four dense layers, each with 64 units.\n",
        "* All of these Dense layers should use the ReLU activation function.\n",
        "* The output Dense layer should have 3 units and the softmax activation function.\n",
        "\n",
        "In total, the network should have 10 layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOCmCe2l-QOU"
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_model(input_shape):\n",
        "    \"\"\"\n",
        "    This function should build a Sequential model according to the above specification. Ensure the \n",
        "    weights are initialised by providing the input_shape argument in the first layer, given by the\n",
        "    function argument.\n",
        "    Your function should return the model.\n",
        "    \"\"\"\n",
        "    model= tf.keras.Sequential([tf.keras.layers.Dense(128,activation='relu',input_shape=(4,)),\n",
        "                                tf.keras.layers.Dense(100,activation='relu'),\n",
        "                                tf.keras.layers.Dense(100,activation='relu'),\n",
        "                                tf.keras.layers.Dense(3,activation='softmax')\n",
        "                                \n",
        "    \n",
        "                                \n",
        "                                ])\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEnEugVV-QOX"
      },
      "source": [
        "# Run your function to get the model\n",
        "\n",
        "model = get_model(train_data[0].shape)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC0h-ud1-QOa"
      },
      "source": [
        "#### Compile the model\n",
        "\n",
        "You should now compile the model using the `compile` method. Remember that you need to specify an optimizer, a loss function and a metric to judge the performance of your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReHF4llc-QOa"
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def compile_model(model):\n",
        "    \"\"\"\n",
        "    This function takes in the model returned from your get_model function, and compiles it with an optimiser,\n",
        "    loss function and metric.\n",
        "    Compile the model using the Adam optimiser (with learning rate set to 0.0001), \n",
        "    the categorical crossentropy loss function and accuracy as the only metric. \n",
        "    Your function doesn't need to return anything; the model will be compiled in-place.\n",
        "    \"\"\"\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),metrics=['accuracy'],loss='categorical_crossentropy')\n",
        "    \n",
        "    "
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qJOJunW-QOd"
      },
      "source": [
        "# Run your function to compile the model\n",
        "\n",
        "compile_model(model)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWxL16Hk-QOh"
      },
      "source": [
        "#### Fit the model to the training data\n",
        "\n",
        "Now you should train the model on the Iris dataset, using the model's `fit` method. \n",
        "* Run the training for a fixed number of epochs, given by the function's `epochs` argument.\n",
        "* Return the training history to be used for plotting the learning curves.\n",
        "* Set the batch size to 40.\n",
        "* Set the validation set to be 15% of the training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYTwJVXq-QOi"
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def train_model(model, train_data, train_targets, epochs):\n",
        "    \"\"\"\n",
        "    This function should train the model for the given number of epochs on the \n",
        "    train_data and train_targets. \n",
        "    Your function should return the training history, as returned by model.fit.\n",
        "    \"\"\"\n",
        "    training_history=model.fit(train_data,train_targets,validation_split=0.15,epochs=epochs,batch_size=12)\n",
        "    return training_history\n",
        "    "
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOE4iz_w-QOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5997d341-7941-4709-fea4-8b0142d75ac3"
      },
      "source": [
        "# Run your function to train the model\n",
        "\n",
        "history = train_model(model, train_data, train_targets, epochs=800)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0495 - accuracy: 0.9825 - val_loss: 0.0950 - val_accuracy: 1.0000\n",
            "Epoch 2/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9912 - val_loss: 0.1087 - val_accuracy: 0.9524\n",
            "Epoch 3/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9912 - val_loss: 0.1156 - val_accuracy: 0.9048\n",
            "Epoch 4/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9912 - val_loss: 0.1042 - val_accuracy: 0.9524\n",
            "Epoch 5/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9912 - val_loss: 0.0994 - val_accuracy: 0.9524\n",
            "Epoch 6/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0460 - accuracy: 0.9912 - val_loss: 0.1186 - val_accuracy: 0.9048\n",
            "Epoch 7/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9912 - val_loss: 0.1396 - val_accuracy: 0.9048\n",
            "Epoch 8/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9912 - val_loss: 0.1151 - val_accuracy: 0.9048\n",
            "Epoch 9/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9912 - val_loss: 0.1057 - val_accuracy: 0.9524\n",
            "Epoch 10/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9912 - val_loss: 0.1123 - val_accuracy: 0.9524\n",
            "Epoch 11/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9912 - val_loss: 0.1024 - val_accuracy: 0.9524\n",
            "Epoch 12/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9912 - val_loss: 0.1166 - val_accuracy: 0.9524\n",
            "Epoch 13/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9912 - val_loss: 0.1209 - val_accuracy: 0.9048\n",
            "Epoch 14/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0458 - accuracy: 0.9912 - val_loss: 0.1085 - val_accuracy: 0.9524\n",
            "Epoch 15/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.9912 - val_loss: 0.1080 - val_accuracy: 0.9524\n",
            "Epoch 16/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9912 - val_loss: 0.1091 - val_accuracy: 0.9524\n",
            "Epoch 17/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9912 - val_loss: 0.1168 - val_accuracy: 0.9524\n",
            "Epoch 18/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9912 - val_loss: 0.1141 - val_accuracy: 0.9524\n",
            "Epoch 19/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9912 - val_loss: 0.1083 - val_accuracy: 0.9524\n",
            "Epoch 20/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9912 - val_loss: 0.1224 - val_accuracy: 0.9048\n",
            "Epoch 21/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9912 - val_loss: 0.1185 - val_accuracy: 0.9524\n",
            "Epoch 22/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9912 - val_loss: 0.1140 - val_accuracy: 0.9524\n",
            "Epoch 23/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9912 - val_loss: 0.1103 - val_accuracy: 0.9524\n",
            "Epoch 24/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.9912 - val_loss: 0.1294 - val_accuracy: 0.9048\n",
            "Epoch 25/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9649 - val_loss: 0.1600 - val_accuracy: 0.9048\n",
            "Epoch 26/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9912 - val_loss: 0.1165 - val_accuracy: 0.9524\n",
            "Epoch 27/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9912 - val_loss: 0.1098 - val_accuracy: 0.9048\n",
            "Epoch 28/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9912 - val_loss: 0.1140 - val_accuracy: 0.9524\n",
            "Epoch 29/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0444 - accuracy: 0.9912 - val_loss: 0.1201 - val_accuracy: 0.9524\n",
            "Epoch 30/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.9912 - val_loss: 0.1328 - val_accuracy: 0.9048\n",
            "Epoch 31/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9912 - val_loss: 0.1189 - val_accuracy: 0.9524\n",
            "Epoch 32/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.9912 - val_loss: 0.1144 - val_accuracy: 0.9524\n",
            "Epoch 33/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.9912 - val_loss: 0.1213 - val_accuracy: 0.9524\n",
            "Epoch 34/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.9912 - val_loss: 0.1184 - val_accuracy: 0.9524\n",
            "Epoch 35/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0454 - accuracy: 0.9912 - val_loss: 0.1210 - val_accuracy: 0.9524\n",
            "Epoch 36/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0454 - accuracy: 0.9912 - val_loss: 0.1179 - val_accuracy: 0.9524\n",
            "Epoch 37/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9912 - val_loss: 0.1203 - val_accuracy: 0.9524\n",
            "Epoch 38/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9912 - val_loss: 0.1214 - val_accuracy: 0.9524\n",
            "Epoch 39/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0467 - accuracy: 0.9912 - val_loss: 0.1144 - val_accuracy: 0.9524\n",
            "Epoch 40/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9912 - val_loss: 0.1315 - val_accuracy: 0.9048\n",
            "Epoch 41/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0446 - accuracy: 0.9912 - val_loss: 0.1271 - val_accuracy: 0.9048\n",
            "Epoch 42/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 0.9912 - val_loss: 0.1263 - val_accuracy: 0.9048\n",
            "Epoch 43/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 0.9912 - val_loss: 0.1164 - val_accuracy: 0.9524\n",
            "Epoch 44/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.9912 - val_loss: 0.1149 - val_accuracy: 0.9524\n",
            "Epoch 45/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9912 - val_loss: 0.1368 - val_accuracy: 0.9048\n",
            "Epoch 46/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9912 - val_loss: 0.1243 - val_accuracy: 0.9048\n",
            "Epoch 47/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9912 - val_loss: 0.1152 - val_accuracy: 0.9524\n",
            "Epoch 48/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9912 - val_loss: 0.1195 - val_accuracy: 0.9524\n",
            "Epoch 49/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9912 - val_loss: 0.1420 - val_accuracy: 0.9048\n",
            "Epoch 50/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9912 - val_loss: 0.1342 - val_accuracy: 0.9048\n",
            "Epoch 51/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9912 - val_loss: 0.1275 - val_accuracy: 0.9048\n",
            "Epoch 52/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0449 - accuracy: 0.9912 - val_loss: 0.1287 - val_accuracy: 0.9048\n",
            "Epoch 53/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9912 - val_loss: 0.1338 - val_accuracy: 0.9048\n",
            "Epoch 54/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0448 - accuracy: 0.9912 - val_loss: 0.1200 - val_accuracy: 0.9524\n",
            "Epoch 55/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0444 - accuracy: 0.9912 - val_loss: 0.1264 - val_accuracy: 0.9048\n",
            "Epoch 56/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.9912 - val_loss: 0.1289 - val_accuracy: 0.9048\n",
            "Epoch 57/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.9912 - val_loss: 0.1190 - val_accuracy: 0.9524\n",
            "Epoch 58/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.9912 - val_loss: 0.1277 - val_accuracy: 0.9048\n",
            "Epoch 59/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9912 - val_loss: 0.1209 - val_accuracy: 0.9524\n",
            "Epoch 60/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9912 - val_loss: 0.1189 - val_accuracy: 0.9524\n",
            "Epoch 61/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0437 - accuracy: 0.9912 - val_loss: 0.1243 - val_accuracy: 0.9048\n",
            "Epoch 62/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 0.9912 - val_loss: 0.1230 - val_accuracy: 0.9524\n",
            "Epoch 63/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9912 - val_loss: 0.1284 - val_accuracy: 0.9048\n",
            "Epoch 64/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9912 - val_loss: 0.1191 - val_accuracy: 0.9524\n",
            "Epoch 65/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9912 - val_loss: 0.1157 - val_accuracy: 0.9048\n",
            "Epoch 66/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9912 - val_loss: 0.1215 - val_accuracy: 0.9524\n",
            "Epoch 67/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9912 - val_loss: 0.1236 - val_accuracy: 0.9524\n",
            "Epoch 68/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.9912 - val_loss: 0.1382 - val_accuracy: 0.9048\n",
            "Epoch 69/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 0.9912 - val_loss: 0.1330 - val_accuracy: 0.9048\n",
            "Epoch 70/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9912 - val_loss: 0.1205 - val_accuracy: 0.9524\n",
            "Epoch 71/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9912 - val_loss: 0.1176 - val_accuracy: 0.9524\n",
            "Epoch 72/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9912 - val_loss: 0.1227 - val_accuracy: 0.9524\n",
            "Epoch 73/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9912 - val_loss: 0.1430 - val_accuracy: 0.9048\n",
            "Epoch 74/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9912 - val_loss: 0.1336 - val_accuracy: 0.9048\n",
            "Epoch 75/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0434 - accuracy: 0.9912 - val_loss: 0.1324 - val_accuracy: 0.9048\n",
            "Epoch 76/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9912 - val_loss: 0.1270 - val_accuracy: 0.9048\n",
            "Epoch 77/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9912 - val_loss: 0.1232 - val_accuracy: 0.9524\n",
            "Epoch 78/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9912 - val_loss: 0.1331 - val_accuracy: 0.9048\n",
            "Epoch 79/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9912 - val_loss: 0.1247 - val_accuracy: 0.9524\n",
            "Epoch 80/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9912 - val_loss: 0.1238 - val_accuracy: 0.9524\n",
            "Epoch 81/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9912 - val_loss: 0.1342 - val_accuracy: 0.9048\n",
            "Epoch 82/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9912 - val_loss: 0.1335 - val_accuracy: 0.9048\n",
            "Epoch 83/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9912 - val_loss: 0.1198 - val_accuracy: 0.9524\n",
            "Epoch 84/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9912 - val_loss: 0.1358 - val_accuracy: 0.9048\n",
            "Epoch 85/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9912 - val_loss: 0.1356 - val_accuracy: 0.9048\n",
            "Epoch 86/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 0.9912 - val_loss: 0.1349 - val_accuracy: 0.9048\n",
            "Epoch 87/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9912 - val_loss: 0.1187 - val_accuracy: 0.9048\n",
            "Epoch 88/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 0.9912 - val_loss: 0.1213 - val_accuracy: 0.9524\n",
            "Epoch 89/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9912 - val_loss: 0.1709 - val_accuracy: 0.9048\n",
            "Epoch 90/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9825 - val_loss: 0.1357 - val_accuracy: 0.9048\n",
            "Epoch 91/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0488 - accuracy: 0.9825 - val_loss: 0.1176 - val_accuracy: 0.9048\n",
            "Epoch 92/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9912 - val_loss: 0.1317 - val_accuracy: 0.9048\n",
            "Epoch 93/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9912 - val_loss: 0.1376 - val_accuracy: 0.9048\n",
            "Epoch 94/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0428 - accuracy: 0.9912 - val_loss: 0.1345 - val_accuracy: 0.9048\n",
            "Epoch 95/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9912 - val_loss: 0.1258 - val_accuracy: 0.9524\n",
            "Epoch 96/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 0.9912 - val_loss: 0.1429 - val_accuracy: 0.9048\n",
            "Epoch 97/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 0.9912 - val_loss: 0.1289 - val_accuracy: 0.9048\n",
            "Epoch 98/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9912 - val_loss: 0.1381 - val_accuracy: 0.9048\n",
            "Epoch 99/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9912 - val_loss: 0.1255 - val_accuracy: 0.9524\n",
            "Epoch 100/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9912 - val_loss: 0.1336 - val_accuracy: 0.9048\n",
            "Epoch 101/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9912 - val_loss: 0.1277 - val_accuracy: 0.9048\n",
            "Epoch 102/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9912 - val_loss: 0.1346 - val_accuracy: 0.9048\n",
            "Epoch 103/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9912 - val_loss: 0.1347 - val_accuracy: 0.9048\n",
            "Epoch 104/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9912 - val_loss: 0.1319 - val_accuracy: 0.9048\n",
            "Epoch 105/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9912 - val_loss: 0.1338 - val_accuracy: 0.9048\n",
            "Epoch 106/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9912 - val_loss: 0.1258 - val_accuracy: 0.9524\n",
            "Epoch 107/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9912 - val_loss: 0.1315 - val_accuracy: 0.9048\n",
            "Epoch 108/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9912 - val_loss: 0.1393 - val_accuracy: 0.9048\n",
            "Epoch 109/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.9912 - val_loss: 0.1444 - val_accuracy: 0.9048\n",
            "Epoch 110/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9912 - val_loss: 0.1303 - val_accuracy: 0.9048\n",
            "Epoch 111/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9912 - val_loss: 0.1262 - val_accuracy: 0.9524\n",
            "Epoch 112/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.9912 - val_loss: 0.1509 - val_accuracy: 0.9048\n",
            "Epoch 113/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9912 - val_loss: 0.1342 - val_accuracy: 0.9048\n",
            "Epoch 114/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9912 - val_loss: 0.1312 - val_accuracy: 0.9048\n",
            "Epoch 115/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9912 - val_loss: 0.1327 - val_accuracy: 0.9048\n",
            "Epoch 116/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9912 - val_loss: 0.1356 - val_accuracy: 0.9048\n",
            "Epoch 117/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.9912 - val_loss: 0.1543 - val_accuracy: 0.9048\n",
            "Epoch 118/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9912 - val_loss: 0.1300 - val_accuracy: 0.9048\n",
            "Epoch 119/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9912 - val_loss: 0.1294 - val_accuracy: 0.9048\n",
            "Epoch 120/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9912 - val_loss: 0.1317 - val_accuracy: 0.9048\n",
            "Epoch 121/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9912 - val_loss: 0.1335 - val_accuracy: 0.9048\n",
            "Epoch 122/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9912 - val_loss: 0.1472 - val_accuracy: 0.9048\n",
            "Epoch 123/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9912 - val_loss: 0.1754 - val_accuracy: 0.9048\n",
            "Epoch 124/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0444 - accuracy: 0.9912 - val_loss: 0.1489 - val_accuracy: 0.9048\n",
            "Epoch 125/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9912 - val_loss: 0.1372 - val_accuracy: 0.9048\n",
            "Epoch 126/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9912 - val_loss: 0.1434 - val_accuracy: 0.9048\n",
            "Epoch 127/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9912 - val_loss: 0.1327 - val_accuracy: 0.9048\n",
            "Epoch 128/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9912 - val_loss: 0.1326 - val_accuracy: 0.9048\n",
            "Epoch 129/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9912 - val_loss: 0.1499 - val_accuracy: 0.9048\n",
            "Epoch 130/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9912 - val_loss: 0.1505 - val_accuracy: 0.9048\n",
            "Epoch 131/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.9912 - val_loss: 0.1262 - val_accuracy: 0.9524\n",
            "Epoch 132/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9912 - val_loss: 0.1293 - val_accuracy: 0.9524\n",
            "Epoch 133/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 0.9825 - val_loss: 0.1873 - val_accuracy: 0.9048\n",
            "Epoch 134/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0420 - accuracy: 0.9912 - val_loss: 0.1481 - val_accuracy: 0.9048\n",
            "Epoch 135/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9912 - val_loss: 0.1286 - val_accuracy: 0.9524\n",
            "Epoch 136/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9912 - val_loss: 0.1259 - val_accuracy: 0.9524\n",
            "Epoch 137/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 0.9912 - val_loss: 0.1607 - val_accuracy: 0.9048\n",
            "Epoch 138/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9825 - val_loss: 0.1801 - val_accuracy: 0.9048\n",
            "Epoch 139/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9912 - val_loss: 0.1416 - val_accuracy: 0.9048\n",
            "Epoch 140/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9912 - val_loss: 0.1296 - val_accuracy: 0.9524\n",
            "Epoch 141/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9912 - val_loss: 0.1335 - val_accuracy: 0.9048\n",
            "Epoch 142/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0444 - accuracy: 0.9912 - val_loss: 0.1512 - val_accuracy: 0.9048\n",
            "Epoch 143/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9912 - val_loss: 0.1231 - val_accuracy: 0.9048\n",
            "Epoch 144/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9912 - val_loss: 0.1802 - val_accuracy: 0.9048\n",
            "Epoch 145/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9912 - val_loss: 0.1541 - val_accuracy: 0.9048\n",
            "Epoch 146/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0412 - accuracy: 0.9912 - val_loss: 0.1444 - val_accuracy: 0.9048\n",
            "Epoch 147/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9912 - val_loss: 0.1427 - val_accuracy: 0.9048\n",
            "Epoch 148/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9912 - val_loss: 0.1402 - val_accuracy: 0.9048\n",
            "Epoch 149/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9912 - val_loss: 0.1377 - val_accuracy: 0.9048\n",
            "Epoch 150/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9912 - val_loss: 0.1453 - val_accuracy: 0.9048\n",
            "Epoch 151/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9912 - val_loss: 0.1456 - val_accuracy: 0.9048\n",
            "Epoch 152/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9912 - val_loss: 0.1505 - val_accuracy: 0.9048\n",
            "Epoch 153/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9912 - val_loss: 0.1372 - val_accuracy: 0.9048\n",
            "Epoch 154/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9912 - val_loss: 0.1318 - val_accuracy: 0.9048\n",
            "Epoch 155/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0414 - accuracy: 0.9912 - val_loss: 0.1504 - val_accuracy: 0.9048\n",
            "Epoch 156/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9912 - val_loss: 0.1452 - val_accuracy: 0.9048\n",
            "Epoch 157/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9912 - val_loss: 0.1277 - val_accuracy: 0.9048\n",
            "Epoch 158/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9912 - val_loss: 0.1559 - val_accuracy: 0.9048\n",
            "Epoch 159/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.9825 - val_loss: 0.1794 - val_accuracy: 0.9048\n",
            "Epoch 160/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9912 - val_loss: 0.1400 - val_accuracy: 0.9048\n",
            "Epoch 161/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9912 - val_loss: 0.1546 - val_accuracy: 0.9048\n",
            "Epoch 162/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9912 - val_loss: 0.1362 - val_accuracy: 0.9048\n",
            "Epoch 163/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9912 - val_loss: 0.1422 - val_accuracy: 0.9048\n",
            "Epoch 164/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 0.9912 - val_loss: 0.1556 - val_accuracy: 0.9048\n",
            "Epoch 165/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9912 - val_loss: 0.1592 - val_accuracy: 0.9048\n",
            "Epoch 166/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9912 - val_loss: 0.1313 - val_accuracy: 0.9524\n",
            "Epoch 167/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9912 - val_loss: 0.1592 - val_accuracy: 0.9048\n",
            "Epoch 168/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9912 - val_loss: 0.1392 - val_accuracy: 0.9048\n",
            "Epoch 169/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9912 - val_loss: 0.1437 - val_accuracy: 0.9048\n",
            "Epoch 170/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0414 - accuracy: 0.9912 - val_loss: 0.1443 - val_accuracy: 0.9048\n",
            "Epoch 171/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9912 - val_loss: 0.1426 - val_accuracy: 0.9048\n",
            "Epoch 172/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9912 - val_loss: 0.1875 - val_accuracy: 0.9048\n",
            "Epoch 173/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9912 - val_loss: 0.1491 - val_accuracy: 0.9048\n",
            "Epoch 174/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9912 - val_loss: 0.1511 - val_accuracy: 0.9048\n",
            "Epoch 175/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 0.9912 - val_loss: 0.1376 - val_accuracy: 0.9048\n",
            "Epoch 176/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9912 - val_loss: 0.1397 - val_accuracy: 0.9048\n",
            "Epoch 177/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9912 - val_loss: 0.1501 - val_accuracy: 0.9048\n",
            "Epoch 178/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0402 - accuracy: 0.9912 - val_loss: 0.1634 - val_accuracy: 0.9048\n",
            "Epoch 179/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 0.1379 - val_accuracy: 0.9048\n",
            "Epoch 180/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9912 - val_loss: 0.1362 - val_accuracy: 0.9048\n",
            "Epoch 181/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9912 - val_loss: 0.1588 - val_accuracy: 0.9048\n",
            "Epoch 182/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9912 - val_loss: 0.1548 - val_accuracy: 0.9048\n",
            "Epoch 183/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9912 - val_loss: 0.1512 - val_accuracy: 0.9048\n",
            "Epoch 184/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9912 - val_loss: 0.1278 - val_accuracy: 0.9048\n",
            "Epoch 185/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9912 - val_loss: 0.1462 - val_accuracy: 0.9048\n",
            "Epoch 186/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9912 - val_loss: 0.1620 - val_accuracy: 0.9048\n",
            "Epoch 187/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9912 - val_loss: 0.1435 - val_accuracy: 0.9048\n",
            "Epoch 188/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 0.9912 - val_loss: 0.1655 - val_accuracy: 0.9048\n",
            "Epoch 189/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0396 - accuracy: 0.9912 - val_loss: 0.1646 - val_accuracy: 0.9048\n",
            "Epoch 190/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9912 - val_loss: 0.1562 - val_accuracy: 0.9048\n",
            "Epoch 191/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9912 - val_loss: 0.1378 - val_accuracy: 0.9048\n",
            "Epoch 192/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9912 - val_loss: 0.1556 - val_accuracy: 0.9048\n",
            "Epoch 193/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9912 - val_loss: 0.1480 - val_accuracy: 0.9048\n",
            "Epoch 194/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 0.1505 - val_accuracy: 0.9048\n",
            "Epoch 195/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 0.1523 - val_accuracy: 0.9048\n",
            "Epoch 196/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9912 - val_loss: 0.1684 - val_accuracy: 0.9048\n",
            "Epoch 197/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9912 - val_loss: 0.1565 - val_accuracy: 0.9048\n",
            "Epoch 198/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9912 - val_loss: 0.1425 - val_accuracy: 0.9048\n",
            "Epoch 199/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9912 - val_loss: 0.1625 - val_accuracy: 0.9048\n",
            "Epoch 200/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9912 - val_loss: 0.1530 - val_accuracy: 0.9048\n",
            "Epoch 201/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 0.1592 - val_accuracy: 0.9048\n",
            "Epoch 202/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.9912 - val_loss: 0.1519 - val_accuracy: 0.9048\n",
            "Epoch 203/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9912 - val_loss: 0.1553 - val_accuracy: 0.9048\n",
            "Epoch 204/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9912 - val_loss: 0.1498 - val_accuracy: 0.9048\n",
            "Epoch 205/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9912 - val_loss: 0.1662 - val_accuracy: 0.9048\n",
            "Epoch 206/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9912 - val_loss: 0.1629 - val_accuracy: 0.9048\n",
            "Epoch 207/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9912 - val_loss: 0.1436 - val_accuracy: 0.9048\n",
            "Epoch 208/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9912 - val_loss: 0.1544 - val_accuracy: 0.9048\n",
            "Epoch 209/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 0.1532 - val_accuracy: 0.9048\n",
            "Epoch 210/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0404 - accuracy: 0.9912 - val_loss: 0.1440 - val_accuracy: 0.9048\n",
            "Epoch 211/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.9912 - val_loss: 0.1615 - val_accuracy: 0.9048\n",
            "Epoch 212/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0391 - accuracy: 0.9912 - val_loss: 0.1505 - val_accuracy: 0.9048\n",
            "Epoch 213/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 0.9912 - val_loss: 0.1547 - val_accuracy: 0.9048\n",
            "Epoch 214/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 0.9912 - val_loss: 0.1606 - val_accuracy: 0.9048\n",
            "Epoch 215/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0389 - accuracy: 0.9912 - val_loss: 0.1618 - val_accuracy: 0.9048\n",
            "Epoch 216/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9912 - val_loss: 0.1579 - val_accuracy: 0.9048\n",
            "Epoch 217/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0402 - accuracy: 0.9912 - val_loss: 0.1633 - val_accuracy: 0.9048\n",
            "Epoch 218/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0389 - accuracy: 0.9912 - val_loss: 0.1573 - val_accuracy: 0.9048\n",
            "Epoch 219/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9912 - val_loss: 0.1462 - val_accuracy: 0.9048\n",
            "Epoch 220/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9912 - val_loss: 0.1696 - val_accuracy: 0.9048\n",
            "Epoch 221/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 0.1587 - val_accuracy: 0.9048\n",
            "Epoch 222/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.9912 - val_loss: 0.1658 - val_accuracy: 0.9048\n",
            "Epoch 223/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9912 - val_loss: 0.1533 - val_accuracy: 0.9048\n",
            "Epoch 224/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 0.1573 - val_accuracy: 0.9048\n",
            "Epoch 225/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9912 - val_loss: 0.1598 - val_accuracy: 0.9048\n",
            "Epoch 226/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 0.1578 - val_accuracy: 0.9048\n",
            "Epoch 227/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0387 - accuracy: 0.9912 - val_loss: 0.1652 - val_accuracy: 0.9048\n",
            "Epoch 228/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.9912 - val_loss: 0.1868 - val_accuracy: 0.9048\n",
            "Epoch 229/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9912 - val_loss: 0.1585 - val_accuracy: 0.9048\n",
            "Epoch 230/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 0.9912 - val_loss: 0.1760 - val_accuracy: 0.9048\n",
            "Epoch 231/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9912 - val_loss: 0.1717 - val_accuracy: 0.9048\n",
            "Epoch 232/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0415 - accuracy: 0.9912 - val_loss: 0.1482 - val_accuracy: 0.9048\n",
            "Epoch 233/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9912 - val_loss: 0.1586 - val_accuracy: 0.9048\n",
            "Epoch 234/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9912 - val_loss: 0.1843 - val_accuracy: 0.9048\n",
            "Epoch 235/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0374 - accuracy: 0.9912 - val_loss: 0.1584 - val_accuracy: 0.9048\n",
            "Epoch 236/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0378 - accuracy: 0.9912 - val_loss: 0.1503 - val_accuracy: 0.9048\n",
            "Epoch 237/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0404 - accuracy: 0.9912 - val_loss: 0.1601 - val_accuracy: 0.9048\n",
            "Epoch 238/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.9912 - val_loss: 0.1611 - val_accuracy: 0.9048\n",
            "Epoch 239/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9912 - val_loss: 0.1588 - val_accuracy: 0.9048\n",
            "Epoch 240/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 0.9912 - val_loss: 0.1650 - val_accuracy: 0.9048\n",
            "Epoch 241/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9912 - val_loss: 0.1460 - val_accuracy: 0.9048\n",
            "Epoch 242/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9912 - val_loss: 0.1764 - val_accuracy: 0.9048\n",
            "Epoch 243/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9912 - val_loss: 0.1549 - val_accuracy: 0.9048\n",
            "Epoch 244/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0378 - accuracy: 0.9912 - val_loss: 0.1792 - val_accuracy: 0.9048\n",
            "Epoch 245/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 0.1852 - val_accuracy: 0.9048\n",
            "Epoch 246/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.9912 - val_loss: 0.1625 - val_accuracy: 0.9048\n",
            "Epoch 247/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9912 - val_loss: 0.1656 - val_accuracy: 0.9048\n",
            "Epoch 248/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 0.1668 - val_accuracy: 0.9048\n",
            "Epoch 249/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 0.9912 - val_loss: 0.1501 - val_accuracy: 0.9048\n",
            "Epoch 250/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9912 - val_loss: 0.1586 - val_accuracy: 0.9048\n",
            "Epoch 251/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 0.9912 - val_loss: 0.1716 - val_accuracy: 0.9048\n",
            "Epoch 252/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0389 - accuracy: 0.9912 - val_loss: 0.1784 - val_accuracy: 0.9048\n",
            "Epoch 253/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9912 - val_loss: 0.1533 - val_accuracy: 0.9048\n",
            "Epoch 254/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 0.1463 - val_accuracy: 0.9048\n",
            "Epoch 255/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0371 - accuracy: 0.9912 - val_loss: 0.1674 - val_accuracy: 0.9048\n",
            "Epoch 256/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 0.1853 - val_accuracy: 0.9048\n",
            "Epoch 257/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 0.1646 - val_accuracy: 0.9048\n",
            "Epoch 258/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9912 - val_loss: 0.1442 - val_accuracy: 0.9048\n",
            "Epoch 259/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0370 - accuracy: 0.9912 - val_loss: 0.1655 - val_accuracy: 0.9048\n",
            "Epoch 260/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9912 - val_loss: 0.2019 - val_accuracy: 0.9048\n",
            "Epoch 261/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0373 - accuracy: 0.9912 - val_loss: 0.1729 - val_accuracy: 0.9048\n",
            "Epoch 262/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0397 - accuracy: 0.9912 - val_loss: 0.1480 - val_accuracy: 0.9048\n",
            "Epoch 263/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0392 - accuracy: 0.9912 - val_loss: 0.1689 - val_accuracy: 0.9048\n",
            "Epoch 264/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 0.1926 - val_accuracy: 0.9048\n",
            "Epoch 265/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9912 - val_loss: 0.1680 - val_accuracy: 0.9048\n",
            "Epoch 266/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9912 - val_loss: 0.1620 - val_accuracy: 0.9048\n",
            "Epoch 267/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0379 - accuracy: 0.9912 - val_loss: 0.1620 - val_accuracy: 0.9048\n",
            "Epoch 268/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 0.1654 - val_accuracy: 0.9048\n",
            "Epoch 269/800\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0368 - accuracy: 0.9912 - val_loss: 0.1878 - val_accuracy: 0.9048\n",
            "Epoch 270/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9912 - val_loss: 0.1766 - val_accuracy: 0.9048\n",
            "Epoch 271/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9912 - val_loss: 0.1718 - val_accuracy: 0.9048\n",
            "Epoch 272/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0376 - accuracy: 0.9912 - val_loss: 0.1745 - val_accuracy: 0.9048\n",
            "Epoch 273/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9912 - val_loss: 0.1640 - val_accuracy: 0.9048\n",
            "Epoch 274/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9912 - val_loss: 0.1694 - val_accuracy: 0.9048\n",
            "Epoch 275/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 0.9912 - val_loss: 0.2004 - val_accuracy: 0.9048\n",
            "Epoch 276/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.9912 - val_loss: 0.1469 - val_accuracy: 0.9048\n",
            "Epoch 277/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0433 - accuracy: 0.9912 - val_loss: 0.2154 - val_accuracy: 0.9048\n",
            "Epoch 278/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 0.1808 - val_accuracy: 0.9048\n",
            "Epoch 279/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9912 - val_loss: 0.1656 - val_accuracy: 0.9048\n",
            "Epoch 280/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 0.9912 - val_loss: 0.1963 - val_accuracy: 0.9048\n",
            "Epoch 281/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0373 - accuracy: 0.9912 - val_loss: 0.1673 - val_accuracy: 0.9048\n",
            "Epoch 282/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 0.1748 - val_accuracy: 0.9048\n",
            "Epoch 283/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0376 - accuracy: 0.9912 - val_loss: 0.1689 - val_accuracy: 0.9048\n",
            "Epoch 284/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 0.1825 - val_accuracy: 0.9048\n",
            "Epoch 285/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0374 - accuracy: 0.9912 - val_loss: 0.1682 - val_accuracy: 0.9048\n",
            "Epoch 286/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.9912 - val_loss: 0.1920 - val_accuracy: 0.9048\n",
            "Epoch 287/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.1762 - val_accuracy: 0.9048\n",
            "Epoch 288/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 0.1680 - val_accuracy: 0.9048\n",
            "Epoch 289/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0390 - accuracy: 0.9912 - val_loss: 0.1905 - val_accuracy: 0.9048\n",
            "Epoch 290/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.1732 - val_accuracy: 0.9048\n",
            "Epoch 291/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9912 - val_loss: 0.1513 - val_accuracy: 0.9048\n",
            "Epoch 292/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 0.1716 - val_accuracy: 0.9048\n",
            "Epoch 293/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9912 - val_loss: 0.2143 - val_accuracy: 0.9048\n",
            "Epoch 294/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.1777 - val_accuracy: 0.9048\n",
            "Epoch 295/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9912 - val_loss: 0.1604 - val_accuracy: 0.9048\n",
            "Epoch 296/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9912 - val_loss: 0.1979 - val_accuracy: 0.9048\n",
            "Epoch 297/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0370 - accuracy: 0.9912 - val_loss: 0.1711 - val_accuracy: 0.9048\n",
            "Epoch 298/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9912 - val_loss: 0.1642 - val_accuracy: 0.9048\n",
            "Epoch 299/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9912 - val_loss: 0.2119 - val_accuracy: 0.9048\n",
            "Epoch 300/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 0.1866 - val_accuracy: 0.9048\n",
            "Epoch 301/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.1832 - val_accuracy: 0.9048\n",
            "Epoch 302/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 0.9912 - val_loss: 0.1665 - val_accuracy: 0.9048\n",
            "Epoch 303/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9912 - val_loss: 0.1940 - val_accuracy: 0.9048\n",
            "Epoch 304/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0368 - accuracy: 0.9912 - val_loss: 0.1785 - val_accuracy: 0.9048\n",
            "Epoch 305/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0385 - accuracy: 0.9912 - val_loss: 0.1675 - val_accuracy: 0.9048\n",
            "Epoch 306/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 0.2033 - val_accuracy: 0.9048\n",
            "Epoch 307/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0372 - accuracy: 0.9912 - val_loss: 0.1923 - val_accuracy: 0.9048\n",
            "Epoch 308/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.1728 - val_accuracy: 0.9048\n",
            "Epoch 309/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9912 - val_loss: 0.1549 - val_accuracy: 0.9048\n",
            "Epoch 310/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 0.1984 - val_accuracy: 0.9048\n",
            "Epoch 311/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.1906 - val_accuracy: 0.9048\n",
            "Epoch 312/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 0.1909 - val_accuracy: 0.9048\n",
            "Epoch 313/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.1859 - val_accuracy: 0.9048\n",
            "Epoch 314/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0392 - accuracy: 0.9912 - val_loss: 0.1629 - val_accuracy: 0.9048\n",
            "Epoch 315/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 0.9912 - val_loss: 0.1853 - val_accuracy: 0.9048\n",
            "Epoch 316/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0434 - accuracy: 0.9912 - val_loss: 0.2351 - val_accuracy: 0.9048\n",
            "Epoch 317/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9912 - val_loss: 0.1744 - val_accuracy: 0.9048\n",
            "Epoch 318/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0398 - accuracy: 0.9912 - val_loss: 0.2113 - val_accuracy: 0.9048\n",
            "Epoch 319/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 0.2078 - val_accuracy: 0.9048\n",
            "Epoch 320/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.9912 - val_loss: 0.1814 - val_accuracy: 0.9048\n",
            "Epoch 321/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 0.1686 - val_accuracy: 0.9048\n",
            "Epoch 322/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9912 - val_loss: 0.2273 - val_accuracy: 0.9048\n",
            "Epoch 323/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9912 - val_loss: 0.2135 - val_accuracy: 0.9048\n",
            "Epoch 324/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 0.1776 - val_accuracy: 0.9048\n",
            "Epoch 325/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.1775 - val_accuracy: 0.9048\n",
            "Epoch 326/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 0.2122 - val_accuracy: 0.9048\n",
            "Epoch 327/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.1824 - val_accuracy: 0.9048\n",
            "Epoch 328/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.1843 - val_accuracy: 0.9048\n",
            "Epoch 329/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9912 - val_loss: 0.1973 - val_accuracy: 0.9048\n",
            "Epoch 330/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.1702 - val_accuracy: 0.9048\n",
            "Epoch 331/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0372 - accuracy: 0.9912 - val_loss: 0.1899 - val_accuracy: 0.9048\n",
            "Epoch 332/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9912 - val_loss: 0.1861 - val_accuracy: 0.9048\n",
            "Epoch 333/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.1854 - val_accuracy: 0.9048\n",
            "Epoch 334/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 0.1855 - val_accuracy: 0.9048\n",
            "Epoch 335/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9912 - val_loss: 0.2239 - val_accuracy: 0.9048\n",
            "Epoch 336/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 0.9912 - val_loss: 0.1852 - val_accuracy: 0.9048\n",
            "Epoch 337/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0414 - accuracy: 0.9825 - val_loss: 0.1607 - val_accuracy: 0.9048\n",
            "Epoch 338/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 0.1950 - val_accuracy: 0.9048\n",
            "Epoch 339/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0374 - accuracy: 0.9912 - val_loss: 0.2763 - val_accuracy: 0.9048\n",
            "Epoch 340/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0401 - accuracy: 0.9825 - val_loss: 0.1992 - val_accuracy: 0.9048\n",
            "Epoch 341/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 0.9912 - val_loss: 0.1635 - val_accuracy: 0.9048\n",
            "Epoch 342/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 0.1927 - val_accuracy: 0.9048\n",
            "Epoch 343/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9912 - val_loss: 0.1665 - val_accuracy: 0.9048\n",
            "Epoch 344/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.2062 - val_accuracy: 0.9048\n",
            "Epoch 345/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.2041 - val_accuracy: 0.9048\n",
            "Epoch 346/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.1972 - val_accuracy: 0.9048\n",
            "Epoch 347/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 0.1790 - val_accuracy: 0.9048\n",
            "Epoch 348/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9825 - val_loss: 0.2553 - val_accuracy: 0.9048\n",
            "Epoch 349/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 0.1839 - val_accuracy: 0.9048\n",
            "Epoch 350/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.1870 - val_accuracy: 0.9048\n",
            "Epoch 351/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9912 - val_loss: 0.2050 - val_accuracy: 0.9048\n",
            "Epoch 352/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.1871 - val_accuracy: 0.9048\n",
            "Epoch 353/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.2040 - val_accuracy: 0.9048\n",
            "Epoch 354/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0397 - accuracy: 0.9912 - val_loss: 0.2286 - val_accuracy: 0.9048\n",
            "Epoch 355/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9912 - val_loss: 0.1713 - val_accuracy: 0.9048\n",
            "Epoch 356/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.1900 - val_accuracy: 0.9048\n",
            "Epoch 357/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.1913 - val_accuracy: 0.9048\n",
            "Epoch 358/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 0.1991 - val_accuracy: 0.9048\n",
            "Epoch 359/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9912 - val_loss: 0.2224 - val_accuracy: 0.9048\n",
            "Epoch 360/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9912 - val_loss: 0.1883 - val_accuracy: 0.9048\n",
            "Epoch 361/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.1746 - val_accuracy: 0.9048\n",
            "Epoch 362/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.1979 - val_accuracy: 0.9048\n",
            "Epoch 363/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.2018 - val_accuracy: 0.9048\n",
            "Epoch 364/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.2062 - val_accuracy: 0.9048\n",
            "Epoch 365/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.2071 - val_accuracy: 0.9048\n",
            "Epoch 366/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 0.1950 - val_accuracy: 0.9048\n",
            "Epoch 367/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.2042 - val_accuracy: 0.9048\n",
            "Epoch 368/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 0.2142 - val_accuracy: 0.9048\n",
            "Epoch 369/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 0.1676 - val_accuracy: 0.9048\n",
            "Epoch 370/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.1895 - val_accuracy: 0.9048\n",
            "Epoch 371/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.2096 - val_accuracy: 0.9048\n",
            "Epoch 372/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 0.2122 - val_accuracy: 0.9048\n",
            "Epoch 373/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.2173 - val_accuracy: 0.9048\n",
            "Epoch 374/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9912 - val_loss: 0.2134 - val_accuracy: 0.9048\n",
            "Epoch 375/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.1981 - val_accuracy: 0.9048\n",
            "Epoch 376/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9912 - val_loss: 0.1734 - val_accuracy: 0.9048\n",
            "Epoch 377/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9912 - val_loss: 0.2094 - val_accuracy: 0.9048\n",
            "Epoch 378/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 0.2269 - val_accuracy: 0.9048\n",
            "Epoch 379/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 0.2018 - val_accuracy: 0.9048\n",
            "Epoch 380/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.1962 - val_accuracy: 0.9048\n",
            "Epoch 381/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.1950 - val_accuracy: 0.9048\n",
            "Epoch 382/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.2398 - val_accuracy: 0.9048\n",
            "Epoch 383/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0413 - accuracy: 0.9912 - val_loss: 0.1743 - val_accuracy: 0.9048\n",
            "Epoch 384/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.2045 - val_accuracy: 0.9048\n",
            "Epoch 385/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.2062 - val_accuracy: 0.9048\n",
            "Epoch 386/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.2247 - val_accuracy: 0.9048\n",
            "Epoch 387/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9912 - val_loss: 0.2159 - val_accuracy: 0.9048\n",
            "Epoch 388/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.2008 - val_accuracy: 0.9048\n",
            "Epoch 389/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9912 - val_loss: 0.2247 - val_accuracy: 0.9048\n",
            "Epoch 390/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.2267 - val_accuracy: 0.9048\n",
            "Epoch 391/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.1801 - val_accuracy: 0.9048\n",
            "Epoch 392/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9912 - val_loss: 0.1682 - val_accuracy: 0.9048\n",
            "Epoch 393/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0326 - accuracy: 0.9912 - val_loss: 0.2120 - val_accuracy: 0.9048\n",
            "Epoch 394/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 0.2495 - val_accuracy: 0.9048\n",
            "Epoch 395/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0401 - accuracy: 0.9912 - val_loss: 0.1804 - val_accuracy: 0.9048\n",
            "Epoch 396/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 0.1991 - val_accuracy: 0.9048\n",
            "Epoch 397/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9912 - val_loss: 0.2453 - val_accuracy: 0.9048\n",
            "Epoch 398/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9912 - val_loss: 0.2072 - val_accuracy: 0.9048\n",
            "Epoch 399/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 0.1956 - val_accuracy: 0.9048\n",
            "Epoch 400/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9912 - val_loss: 0.2016 - val_accuracy: 0.9048\n",
            "Epoch 401/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 0.2135 - val_accuracy: 0.9048\n",
            "Epoch 402/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 0.2295 - val_accuracy: 0.9048\n",
            "Epoch 403/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9912 - val_loss: 0.2347 - val_accuracy: 0.9048\n",
            "Epoch 404/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.1820 - val_accuracy: 0.9048\n",
            "Epoch 405/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9912 - val_loss: 0.1869 - val_accuracy: 0.9048\n",
            "Epoch 406/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 0.9912 - val_loss: 0.2482 - val_accuracy: 0.9048\n",
            "Epoch 407/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.2179 - val_accuracy: 0.9048\n",
            "Epoch 408/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0331 - accuracy: 0.9912 - val_loss: 0.2054 - val_accuracy: 0.9048\n",
            "Epoch 409/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 0.2046 - val_accuracy: 0.9048\n",
            "Epoch 410/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9912 - val_loss: 0.2111 - val_accuracy: 0.9048\n",
            "Epoch 411/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.2302 - val_accuracy: 0.9048\n",
            "Epoch 412/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 0.9912 - val_loss: 0.1765 - val_accuracy: 0.9048\n",
            "Epoch 413/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.2277 - val_accuracy: 0.9048\n",
            "Epoch 414/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9912 - val_loss: 0.1868 - val_accuracy: 0.9048\n",
            "Epoch 415/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 0.9912 - val_loss: 0.2744 - val_accuracy: 0.9048\n",
            "Epoch 416/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 0.2061 - val_accuracy: 0.9048\n",
            "Epoch 417/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 0.2228 - val_accuracy: 0.9048\n",
            "Epoch 418/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 0.2042 - val_accuracy: 0.9048\n",
            "Epoch 419/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 0.1827 - val_accuracy: 0.9048\n",
            "Epoch 420/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.2710 - val_accuracy: 0.9048\n",
            "Epoch 421/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.2489 - val_accuracy: 0.9048\n",
            "Epoch 422/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.2080 - val_accuracy: 0.9048\n",
            "Epoch 423/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.2000 - val_accuracy: 0.9048\n",
            "Epoch 424/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.9912 - val_loss: 0.2143 - val_accuracy: 0.9048\n",
            "Epoch 425/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 0.2289 - val_accuracy: 0.9048\n",
            "Epoch 426/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9912 - val_loss: 0.1982 - val_accuracy: 0.9048\n",
            "Epoch 427/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0361 - accuracy: 0.9912 - val_loss: 0.2355 - val_accuracy: 0.9048\n",
            "Epoch 428/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.2238 - val_accuracy: 0.9048\n",
            "Epoch 429/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.1858 - val_accuracy: 0.9048\n",
            "Epoch 430/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 0.2090 - val_accuracy: 0.9048\n",
            "Epoch 431/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.2662 - val_accuracy: 0.9048\n",
            "Epoch 432/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.2453 - val_accuracy: 0.9048\n",
            "Epoch 433/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9912 - val_loss: 0.1932 - val_accuracy: 0.9048\n",
            "Epoch 434/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.2288 - val_accuracy: 0.9048\n",
            "Epoch 435/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0331 - accuracy: 0.9912 - val_loss: 0.2072 - val_accuracy: 0.9048\n",
            "Epoch 436/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0322 - accuracy: 0.9912 - val_loss: 0.2148 - val_accuracy: 0.9048\n",
            "Epoch 437/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 0.2287 - val_accuracy: 0.9048\n",
            "Epoch 438/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9912 - val_loss: 0.2166 - val_accuracy: 0.9048\n",
            "Epoch 439/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9912 - val_loss: 0.2162 - val_accuracy: 0.9048\n",
            "Epoch 440/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.2231 - val_accuracy: 0.9048\n",
            "Epoch 441/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.2069 - val_accuracy: 0.9048\n",
            "Epoch 442/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9912 - val_loss: 0.2583 - val_accuracy: 0.9048\n",
            "Epoch 443/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 0.1911 - val_accuracy: 0.9048\n",
            "Epoch 444/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9825 - val_loss: 0.1834 - val_accuracy: 0.9048\n",
            "Epoch 445/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 0.2549 - val_accuracy: 0.9048\n",
            "Epoch 446/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9825 - val_loss: 0.2680 - val_accuracy: 0.9048\n",
            "Epoch 447/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.1891 - val_accuracy: 0.9048\n",
            "Epoch 448/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.2104 - val_accuracy: 0.9048\n",
            "Epoch 449/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 0.2337 - val_accuracy: 0.9048\n",
            "Epoch 450/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 0.1980 - val_accuracy: 0.9048\n",
            "Epoch 451/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0313 - accuracy: 0.9912 - val_loss: 0.2451 - val_accuracy: 0.9048\n",
            "Epoch 452/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 0.2468 - val_accuracy: 0.9048\n",
            "Epoch 453/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.2329 - val_accuracy: 0.9048\n",
            "Epoch 454/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 0.2148 - val_accuracy: 0.9048\n",
            "Epoch 455/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 0.2270 - val_accuracy: 0.9048\n",
            "Epoch 456/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9912 - val_loss: 0.2437 - val_accuracy: 0.9048\n",
            "Epoch 457/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.2110 - val_accuracy: 0.9048\n",
            "Epoch 458/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 0.2299 - val_accuracy: 0.9048\n",
            "Epoch 459/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 0.2028 - val_accuracy: 0.9048\n",
            "Epoch 460/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.2275 - val_accuracy: 0.9048\n",
            "Epoch 461/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.2555 - val_accuracy: 0.9048\n",
            "Epoch 462/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9912 - val_loss: 0.2277 - val_accuracy: 0.9048\n",
            "Epoch 463/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.9912 - val_loss: 0.1922 - val_accuracy: 0.9048\n",
            "Epoch 464/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.2310 - val_accuracy: 0.9048\n",
            "Epoch 465/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.2497 - val_accuracy: 0.9048\n",
            "Epoch 466/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 0.2352 - val_accuracy: 0.9048\n",
            "Epoch 467/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 0.2062 - val_accuracy: 0.9048\n",
            "Epoch 468/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.2359 - val_accuracy: 0.9048\n",
            "Epoch 469/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.2211 - val_accuracy: 0.9048\n",
            "Epoch 470/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.2311 - val_accuracy: 0.9048\n",
            "Epoch 471/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 0.9912 - val_loss: 0.2012 - val_accuracy: 0.9048\n",
            "Epoch 472/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9912 - val_loss: 0.3181 - val_accuracy: 0.9048\n",
            "Epoch 473/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.2217 - val_accuracy: 0.9048\n",
            "Epoch 474/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.2194 - val_accuracy: 0.9048\n",
            "Epoch 475/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0328 - accuracy: 0.9912 - val_loss: 0.2258 - val_accuracy: 0.9048\n",
            "Epoch 476/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 0.2093 - val_accuracy: 0.9048\n",
            "Epoch 477/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 0.2406 - val_accuracy: 0.9048\n",
            "Epoch 478/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.2202 - val_accuracy: 0.9048\n",
            "Epoch 479/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 0.3088 - val_accuracy: 0.9048\n",
            "Epoch 480/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 0.2350 - val_accuracy: 0.9048\n",
            "Epoch 481/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 0.2152 - val_accuracy: 0.9048\n",
            "Epoch 482/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 0.2071 - val_accuracy: 0.9048\n",
            "Epoch 483/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 0.9912 - val_loss: 0.2639 - val_accuracy: 0.9048\n",
            "Epoch 484/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 0.2682 - val_accuracy: 0.9048\n",
            "Epoch 485/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.1895 - val_accuracy: 0.9048\n",
            "Epoch 486/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.2147 - val_accuracy: 0.9048\n",
            "Epoch 487/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 0.9912 - val_loss: 0.2434 - val_accuracy: 0.9048\n",
            "Epoch 488/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 0.2414 - val_accuracy: 0.9048\n",
            "Epoch 489/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 0.2949 - val_accuracy: 0.9048\n",
            "Epoch 490/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 0.2524 - val_accuracy: 0.9048\n",
            "Epoch 491/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9912 - val_loss: 0.2005 - val_accuracy: 0.9048\n",
            "Epoch 492/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0313 - accuracy: 0.9912 - val_loss: 0.2573 - val_accuracy: 0.9048\n",
            "Epoch 493/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.2676 - val_accuracy: 0.9048\n",
            "Epoch 494/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 0.2537 - val_accuracy: 0.9048\n",
            "Epoch 495/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9912 - val_loss: 0.2192 - val_accuracy: 0.9048\n",
            "Epoch 496/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.2268 - val_accuracy: 0.9048\n",
            "Epoch 497/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.2963 - val_accuracy: 0.9048\n",
            "Epoch 498/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9912 - val_loss: 0.2438 - val_accuracy: 0.9048\n",
            "Epoch 499/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.2395 - val_accuracy: 0.9048\n",
            "Epoch 500/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 0.9912 - val_loss: 0.2384 - val_accuracy: 0.9048\n",
            "Epoch 501/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 0.2184 - val_accuracy: 0.9048\n",
            "Epoch 502/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.2847 - val_accuracy: 0.9048\n",
            "Epoch 503/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0373 - accuracy: 0.9912 - val_loss: 0.1934 - val_accuracy: 0.9048\n",
            "Epoch 504/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 0.2237 - val_accuracy: 0.9048\n",
            "Epoch 505/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 0.2865 - val_accuracy: 0.9048\n",
            "Epoch 506/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.2659 - val_accuracy: 0.9048\n",
            "Epoch 507/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 0.9912 - val_loss: 0.2266 - val_accuracy: 0.9048\n",
            "Epoch 508/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 0.2182 - val_accuracy: 0.9048\n",
            "Epoch 509/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9912 - val_loss: 0.2581 - val_accuracy: 0.9048\n",
            "Epoch 510/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 0.9912 - val_loss: 0.2512 - val_accuracy: 0.9048\n",
            "Epoch 511/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 0.2162 - val_accuracy: 0.9048\n",
            "Epoch 512/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 0.2399 - val_accuracy: 0.9048\n",
            "Epoch 513/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 0.2790 - val_accuracy: 0.9048\n",
            "Epoch 514/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.2223 - val_accuracy: 0.9048\n",
            "Epoch 515/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9912 - val_loss: 0.2313 - val_accuracy: 0.9048\n",
            "Epoch 516/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 0.2611 - val_accuracy: 0.9048\n",
            "Epoch 517/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 0.2542 - val_accuracy: 0.9048\n",
            "Epoch 518/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.2924 - val_accuracy: 0.9048\n",
            "Epoch 519/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 0.2385 - val_accuracy: 0.9048\n",
            "Epoch 520/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.2381 - val_accuracy: 0.9048\n",
            "Epoch 521/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 0.2312 - val_accuracy: 0.9048\n",
            "Epoch 522/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 0.2682 - val_accuracy: 0.9048\n",
            "Epoch 523/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9912 - val_loss: 0.2222 - val_accuracy: 0.9048\n",
            "Epoch 524/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9912 - val_loss: 0.2601 - val_accuracy: 0.9048\n",
            "Epoch 525/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.2700 - val_accuracy: 0.9048\n",
            "Epoch 526/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.2325 - val_accuracy: 0.9048\n",
            "Epoch 527/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9912 - val_loss: 0.2650 - val_accuracy: 0.9048\n",
            "Epoch 528/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 0.2473 - val_accuracy: 0.9048\n",
            "Epoch 529/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 0.2494 - val_accuracy: 0.9048\n",
            "Epoch 530/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 0.2679 - val_accuracy: 0.9048\n",
            "Epoch 531/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.2621 - val_accuracy: 0.9048\n",
            "Epoch 532/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 0.2590 - val_accuracy: 0.9048\n",
            "Epoch 533/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9912 - val_loss: 0.2219 - val_accuracy: 0.9048\n",
            "Epoch 534/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.2541 - val_accuracy: 0.9048\n",
            "Epoch 535/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.2568 - val_accuracy: 0.9048\n",
            "Epoch 536/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 0.3285 - val_accuracy: 0.9048\n",
            "Epoch 537/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.2633 - val_accuracy: 0.9048\n",
            "Epoch 538/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.2242 - val_accuracy: 0.9048\n",
            "Epoch 539/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.2197 - val_accuracy: 0.9048\n",
            "Epoch 540/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9912 - val_loss: 0.3273 - val_accuracy: 0.9048\n",
            "Epoch 541/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.2590 - val_accuracy: 0.9048\n",
            "Epoch 542/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.2473 - val_accuracy: 0.9048\n",
            "Epoch 543/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.2535 - val_accuracy: 0.9048\n",
            "Epoch 544/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.2619 - val_accuracy: 0.9048\n",
            "Epoch 545/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.2418 - val_accuracy: 0.9048\n",
            "Epoch 546/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.2381 - val_accuracy: 0.9048\n",
            "Epoch 547/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.2311 - val_accuracy: 0.9048\n",
            "Epoch 548/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.2734 - val_accuracy: 0.9048\n",
            "Epoch 549/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.3146 - val_accuracy: 0.9048\n",
            "Epoch 550/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9912 - val_loss: 0.2008 - val_accuracy: 0.9048\n",
            "Epoch 551/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9912 - val_loss: 0.2272 - val_accuracy: 0.9048\n",
            "Epoch 552/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.2900 - val_accuracy: 0.9048\n",
            "Epoch 553/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0406 - accuracy: 0.9737 - val_loss: 0.3435 - val_accuracy: 0.9048\n",
            "Epoch 554/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.1884 - val_accuracy: 0.9048\n",
            "Epoch 555/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9825 - val_loss: 0.1952 - val_accuracy: 0.9048\n",
            "Epoch 556/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0390 - accuracy: 0.9912 - val_loss: 0.3251 - val_accuracy: 0.9048\n",
            "Epoch 557/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0317 - accuracy: 0.9912 - val_loss: 0.2724 - val_accuracy: 0.9048\n",
            "Epoch 558/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 0.2074 - val_accuracy: 0.9048\n",
            "Epoch 559/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.2268 - val_accuracy: 0.9048\n",
            "Epoch 560/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.3294 - val_accuracy: 0.9048\n",
            "Epoch 561/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.2380 - val_accuracy: 0.9048\n",
            "Epoch 562/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.3034 - val_accuracy: 0.9048\n",
            "Epoch 563/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 0.2883 - val_accuracy: 0.9048\n",
            "Epoch 564/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9912 - val_loss: 0.2339 - val_accuracy: 0.9048\n",
            "Epoch 565/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.2770 - val_accuracy: 0.9048\n",
            "Epoch 566/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.2713 - val_accuracy: 0.9048\n",
            "Epoch 567/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0291 - accuracy: 0.9912 - val_loss: 0.2693 - val_accuracy: 0.9048\n",
            "Epoch 568/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.2489 - val_accuracy: 0.9048\n",
            "Epoch 569/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.2674 - val_accuracy: 0.9048\n",
            "Epoch 570/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.2744 - val_accuracy: 0.9048\n",
            "Epoch 571/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.2699 - val_accuracy: 0.9048\n",
            "Epoch 572/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.2285 - val_accuracy: 0.9048\n",
            "Epoch 573/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.2240 - val_accuracy: 0.9048\n",
            "Epoch 574/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.2741 - val_accuracy: 0.9048\n",
            "Epoch 575/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 0.9912 - val_loss: 0.3381 - val_accuracy: 0.9048\n",
            "Epoch 576/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.2276 - val_accuracy: 0.9048\n",
            "Epoch 577/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9912 - val_loss: 0.2446 - val_accuracy: 0.9048\n",
            "Epoch 578/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.2670 - val_accuracy: 0.9048\n",
            "Epoch 579/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 0.2841 - val_accuracy: 0.9048\n",
            "Epoch 580/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.2402 - val_accuracy: 0.9048\n",
            "Epoch 581/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.2502 - val_accuracy: 0.9048\n",
            "Epoch 582/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 0.2706 - val_accuracy: 0.9048\n",
            "Epoch 583/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.2839 - val_accuracy: 0.9048\n",
            "Epoch 584/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.2541 - val_accuracy: 0.9048\n",
            "Epoch 585/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.2607 - val_accuracy: 0.9048\n",
            "Epoch 586/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 0.2844 - val_accuracy: 0.9048\n",
            "Epoch 587/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.2432 - val_accuracy: 0.9048\n",
            "Epoch 588/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.3000 - val_accuracy: 0.9048\n",
            "Epoch 589/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.2931 - val_accuracy: 0.9048\n",
            "Epoch 590/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.2614 - val_accuracy: 0.9048\n",
            "Epoch 591/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0328 - accuracy: 0.9912 - val_loss: 0.2282 - val_accuracy: 0.9048\n",
            "Epoch 592/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.2968 - val_accuracy: 0.9048\n",
            "Epoch 593/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 0.2737 - val_accuracy: 0.9048\n",
            "Epoch 594/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.2556 - val_accuracy: 0.9048\n",
            "Epoch 595/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 0.2822 - val_accuracy: 0.9048\n",
            "Epoch 596/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.2558 - val_accuracy: 0.9048\n",
            "Epoch 597/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.2518 - val_accuracy: 0.9048\n",
            "Epoch 598/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.2880 - val_accuracy: 0.9048\n",
            "Epoch 599/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.2870 - val_accuracy: 0.9048\n",
            "Epoch 600/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.2506 - val_accuracy: 0.9048\n",
            "Epoch 601/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 0.2631 - val_accuracy: 0.9048\n",
            "Epoch 602/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.2789 - val_accuracy: 0.9048\n",
            "Epoch 603/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.3029 - val_accuracy: 0.9048\n",
            "Epoch 604/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.2727 - val_accuracy: 0.9048\n",
            "Epoch 605/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.2749 - val_accuracy: 0.9048\n",
            "Epoch 606/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0313 - accuracy: 0.9912 - val_loss: 0.2442 - val_accuracy: 0.9048\n",
            "Epoch 607/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 0.3136 - val_accuracy: 0.9048\n",
            "Epoch 608/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 0.9912 - val_loss: 0.2452 - val_accuracy: 0.9048\n",
            "Epoch 609/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.2590 - val_accuracy: 0.9048\n",
            "Epoch 610/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.2786 - val_accuracy: 0.9048\n",
            "Epoch 611/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.2819 - val_accuracy: 0.9048\n",
            "Epoch 612/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.2891 - val_accuracy: 0.9048\n",
            "Epoch 613/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.2623 - val_accuracy: 0.9048\n",
            "Epoch 614/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.2462 - val_accuracy: 0.9048\n",
            "Epoch 615/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.3017 - val_accuracy: 0.9048\n",
            "Epoch 616/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.2717 - val_accuracy: 0.9048\n",
            "Epoch 617/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.2962 - val_accuracy: 0.9048\n",
            "Epoch 618/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.2513 - val_accuracy: 0.9048\n",
            "Epoch 619/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.3102 - val_accuracy: 0.9048\n",
            "Epoch 620/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.2650 - val_accuracy: 0.9048\n",
            "Epoch 621/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 0.2554 - val_accuracy: 0.9048\n",
            "Epoch 622/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.3165 - val_accuracy: 0.9048\n",
            "Epoch 623/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.2965 - val_accuracy: 0.9048\n",
            "Epoch 624/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.2478 - val_accuracy: 0.9048\n",
            "Epoch 625/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9912 - val_loss: 0.3954 - val_accuracy: 0.8571\n",
            "Epoch 626/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0317 - accuracy: 0.9825 - val_loss: 0.2249 - val_accuracy: 0.9048\n",
            "Epoch 627/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0317 - accuracy: 0.9912 - val_loss: 0.2572 - val_accuracy: 0.9048\n",
            "Epoch 628/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.2719 - val_accuracy: 0.9048\n",
            "Epoch 629/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.3083 - val_accuracy: 0.9048\n",
            "Epoch 630/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.2602 - val_accuracy: 0.9048\n",
            "Epoch 631/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.2661 - val_accuracy: 0.9048\n",
            "Epoch 632/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 0.3594 - val_accuracy: 0.8571\n",
            "Epoch 633/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.2781 - val_accuracy: 0.9048\n",
            "Epoch 634/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.2748 - val_accuracy: 0.9048\n",
            "Epoch 635/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.2698 - val_accuracy: 0.9048\n",
            "Epoch 636/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.2915 - val_accuracy: 0.9048\n",
            "Epoch 637/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.2872 - val_accuracy: 0.9048\n",
            "Epoch 638/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9912 - val_loss: 0.2760 - val_accuracy: 0.9048\n",
            "Epoch 639/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0317 - accuracy: 0.9912 - val_loss: 0.2513 - val_accuracy: 0.9048\n",
            "Epoch 640/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.2879 - val_accuracy: 0.9048\n",
            "Epoch 641/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9912 - val_loss: 0.3711 - val_accuracy: 0.8571\n",
            "Epoch 642/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.2772 - val_accuracy: 0.9048\n",
            "Epoch 643/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.2951 - val_accuracy: 0.9048\n",
            "Epoch 644/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.3085 - val_accuracy: 0.9048\n",
            "Epoch 645/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.3025 - val_accuracy: 0.9048\n",
            "Epoch 646/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.2734 - val_accuracy: 0.9048\n",
            "Epoch 647/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 0.2435 - val_accuracy: 0.9048\n",
            "Epoch 648/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.3355 - val_accuracy: 0.9048\n",
            "Epoch 649/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.3024 - val_accuracy: 0.9048\n",
            "Epoch 650/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.2482 - val_accuracy: 0.9048\n",
            "Epoch 651/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.3038 - val_accuracy: 0.9048\n",
            "Epoch 652/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.3129 - val_accuracy: 0.9048\n",
            "Epoch 653/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.2868 - val_accuracy: 0.9048\n",
            "Epoch 654/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.2350 - val_accuracy: 0.9048\n",
            "Epoch 655/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9912 - val_loss: 0.3631 - val_accuracy: 0.8571\n",
            "Epoch 656/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0316 - accuracy: 0.9912 - val_loss: 0.3471 - val_accuracy: 0.8571\n",
            "Epoch 657/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.2354 - val_accuracy: 0.9048\n",
            "Epoch 658/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0338 - accuracy: 0.9912 - val_loss: 0.3285 - val_accuracy: 0.9048\n",
            "Epoch 659/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.2868 - val_accuracy: 0.9048\n",
            "Epoch 660/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.3017 - val_accuracy: 0.9048\n",
            "Epoch 661/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.3380 - val_accuracy: 0.9048\n",
            "Epoch 662/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.2965 - val_accuracy: 0.9048\n",
            "Epoch 663/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.2785 - val_accuracy: 0.9048\n",
            "Epoch 664/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.2918 - val_accuracy: 0.9048\n",
            "Epoch 665/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.3071 - val_accuracy: 0.9048\n",
            "Epoch 666/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.3757 - val_accuracy: 0.8571\n",
            "Epoch 667/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.2561 - val_accuracy: 0.9048\n",
            "Epoch 668/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.2777 - val_accuracy: 0.9048\n",
            "Epoch 669/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.3342 - val_accuracy: 0.9048\n",
            "Epoch 670/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.2975 - val_accuracy: 0.9048\n",
            "Epoch 671/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.2998 - val_accuracy: 0.9048\n",
            "Epoch 672/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.2845 - val_accuracy: 0.9048\n",
            "Epoch 673/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 0.3097 - val_accuracy: 0.9048\n",
            "Epoch 674/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.3417 - val_accuracy: 0.8571\n",
            "Epoch 675/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 0.2712 - val_accuracy: 0.9048\n",
            "Epoch 676/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.2450 - val_accuracy: 0.9048\n",
            "Epoch 677/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 0.3489 - val_accuracy: 0.8571\n",
            "Epoch 678/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.2581 - val_accuracy: 0.9048\n",
            "Epoch 679/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.2648 - val_accuracy: 0.9048\n",
            "Epoch 680/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.3109 - val_accuracy: 0.9048\n",
            "Epoch 681/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.2789 - val_accuracy: 0.9048\n",
            "Epoch 682/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.2953 - val_accuracy: 0.9048\n",
            "Epoch 683/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9912 - val_loss: 0.3401 - val_accuracy: 0.8571\n",
            "Epoch 684/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.3117 - val_accuracy: 0.9048\n",
            "Epoch 685/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.2632 - val_accuracy: 0.9048\n",
            "Epoch 686/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.2704 - val_accuracy: 0.9048\n",
            "Epoch 687/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.3555 - val_accuracy: 0.8571\n",
            "Epoch 688/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.3153 - val_accuracy: 0.9048\n",
            "Epoch 689/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.3077 - val_accuracy: 0.9048\n",
            "Epoch 690/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.2977 - val_accuracy: 0.9048\n",
            "Epoch 691/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.3179 - val_accuracy: 0.9048\n",
            "Epoch 692/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.2927 - val_accuracy: 0.9048\n",
            "Epoch 693/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.3210 - val_accuracy: 0.9048\n",
            "Epoch 694/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.2795 - val_accuracy: 0.9048\n",
            "Epoch 695/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.3050 - val_accuracy: 0.9048\n",
            "Epoch 696/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.3034 - val_accuracy: 0.9048\n",
            "Epoch 697/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.3043 - val_accuracy: 0.9048\n",
            "Epoch 698/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.3012 - val_accuracy: 0.9048\n",
            "Epoch 699/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.3323 - val_accuracy: 0.9048\n",
            "Epoch 700/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.3026 - val_accuracy: 0.9048\n",
            "Epoch 701/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.2937 - val_accuracy: 0.9048\n",
            "Epoch 702/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.3091 - val_accuracy: 0.9048\n",
            "Epoch 703/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.2829 - val_accuracy: 0.9048\n",
            "Epoch 704/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.3092 - val_accuracy: 0.9048\n",
            "Epoch 705/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.2690 - val_accuracy: 0.9048\n",
            "Epoch 706/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 0.3360 - val_accuracy: 0.8571\n",
            "Epoch 707/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.3165 - val_accuracy: 0.9048\n",
            "Epoch 708/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 0.3580 - val_accuracy: 0.8571\n",
            "Epoch 709/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 0.9912 - val_loss: 0.2953 - val_accuracy: 0.9048\n",
            "Epoch 710/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.2809 - val_accuracy: 0.9048\n",
            "Epoch 711/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.3117 - val_accuracy: 0.9048\n",
            "Epoch 712/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.3507 - val_accuracy: 0.8571\n",
            "Epoch 713/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.2776 - val_accuracy: 0.9048\n",
            "Epoch 714/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 0.3657 - val_accuracy: 0.8571\n",
            "Epoch 715/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.3623 - val_accuracy: 0.8571\n",
            "Epoch 716/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.2892 - val_accuracy: 0.9048\n",
            "Epoch 717/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.3229 - val_accuracy: 0.9048\n",
            "Epoch 718/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.3187 - val_accuracy: 0.9048\n",
            "Epoch 719/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.2740 - val_accuracy: 0.9048\n",
            "Epoch 720/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.3233 - val_accuracy: 0.9048\n",
            "Epoch 721/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 0.3047 - val_accuracy: 0.9048\n",
            "Epoch 722/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.2929 - val_accuracy: 0.9048\n",
            "Epoch 723/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.3498 - val_accuracy: 0.8571\n",
            "Epoch 724/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.3474 - val_accuracy: 0.8571\n",
            "Epoch 725/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.2500 - val_accuracy: 0.9048\n",
            "Epoch 726/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.3656 - val_accuracy: 0.8571\n",
            "Epoch 727/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.3557 - val_accuracy: 0.8571\n",
            "Epoch 728/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.3070 - val_accuracy: 0.9048\n",
            "Epoch 729/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.2884 - val_accuracy: 0.9048\n",
            "Epoch 730/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.3612 - val_accuracy: 0.8571\n",
            "Epoch 731/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.3312 - val_accuracy: 0.8571\n",
            "Epoch 732/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.2799 - val_accuracy: 0.9048\n",
            "Epoch 733/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.3079 - val_accuracy: 0.9048\n",
            "Epoch 734/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.2825 - val_accuracy: 0.9048\n",
            "Epoch 735/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.3238 - val_accuracy: 0.9048\n",
            "Epoch 736/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.3098 - val_accuracy: 0.9048\n",
            "Epoch 737/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.3391 - val_accuracy: 0.8571\n",
            "Epoch 738/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.3042 - val_accuracy: 0.9048\n",
            "Epoch 739/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 0.2716 - val_accuracy: 0.9048\n",
            "Epoch 740/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.3433 - val_accuracy: 0.8571\n",
            "Epoch 741/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.3335 - val_accuracy: 0.8571\n",
            "Epoch 742/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 0.3017 - val_accuracy: 0.9048\n",
            "Epoch 743/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.3325 - val_accuracy: 0.8571\n",
            "Epoch 744/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 0.3095 - val_accuracy: 0.9048\n",
            "Epoch 745/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.2992 - val_accuracy: 0.9048\n",
            "Epoch 746/800\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.3341 - val_accuracy: 0.8571\n",
            "Epoch 747/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 0.3099 - val_accuracy: 0.9048\n",
            "Epoch 748/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.3281 - val_accuracy: 0.8571\n",
            "Epoch 749/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.2922 - val_accuracy: 0.9048\n",
            "Epoch 750/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.3677 - val_accuracy: 0.8571\n",
            "Epoch 751/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 0.2308 - val_accuracy: 0.9048\n",
            "Epoch 752/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 0.2548 - val_accuracy: 0.9048\n",
            "Epoch 753/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.4601 - val_accuracy: 0.8571\n",
            "Epoch 754/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9825 - val_loss: 0.3152 - val_accuracy: 0.9048\n",
            "Epoch 755/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.3192 - val_accuracy: 0.9048\n",
            "Epoch 756/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.3388 - val_accuracy: 0.8571\n",
            "Epoch 757/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.3083 - val_accuracy: 0.9048\n",
            "Epoch 758/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 0.3385 - val_accuracy: 0.8571\n",
            "Epoch 759/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.2951 - val_accuracy: 0.9048\n",
            "Epoch 760/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.2748 - val_accuracy: 0.9048\n",
            "Epoch 761/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.3448 - val_accuracy: 0.8571\n",
            "Epoch 762/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.3579 - val_accuracy: 0.8571\n",
            "Epoch 763/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.3122 - val_accuracy: 0.9048\n",
            "Epoch 764/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.3019 - val_accuracy: 0.9048\n",
            "Epoch 765/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.3660 - val_accuracy: 0.8571\n",
            "Epoch 766/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.3509 - val_accuracy: 0.8571\n",
            "Epoch 767/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 0.2814 - val_accuracy: 0.9048\n",
            "Epoch 768/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.3706 - val_accuracy: 0.8571\n",
            "Epoch 769/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.3522 - val_accuracy: 0.8571\n",
            "Epoch 770/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 0.3189 - val_accuracy: 0.9048\n",
            "Epoch 771/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.3194 - val_accuracy: 0.9048\n",
            "Epoch 772/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.3022 - val_accuracy: 0.9048\n",
            "Epoch 773/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 0.3833 - val_accuracy: 0.8571\n",
            "Epoch 774/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.2264 - val_accuracy: 0.9048\n",
            "Epoch 775/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.3454 - val_accuracy: 0.8571\n",
            "Epoch 776/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.3285 - val_accuracy: 0.8571\n",
            "Epoch 777/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 0.2349 - val_accuracy: 0.9048\n",
            "Epoch 778/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0217 - accuracy: 0.9912 - val_loss: 0.3723 - val_accuracy: 0.8571\n",
            "Epoch 779/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9825 - val_loss: 0.4158 - val_accuracy: 0.8571\n",
            "Epoch 780/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0190 - accuracy: 0.9912 - val_loss: 0.2466 - val_accuracy: 0.9048\n",
            "Epoch 781/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.2749 - val_accuracy: 0.9048\n",
            "Epoch 782/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.3142 - val_accuracy: 0.9048\n",
            "Epoch 783/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 0.3698 - val_accuracy: 0.8571\n",
            "Epoch 784/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.3575 - val_accuracy: 0.8571\n",
            "Epoch 785/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 0.3167 - val_accuracy: 0.9048\n",
            "Epoch 786/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 0.9912 - val_loss: 0.2988 - val_accuracy: 0.9048\n",
            "Epoch 787/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.3509 - val_accuracy: 0.8571\n",
            "Epoch 788/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.4612 - val_accuracy: 0.8571\n",
            "Epoch 789/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.3431 - val_accuracy: 0.8571\n",
            "Epoch 790/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 0.3285 - val_accuracy: 0.8571\n",
            "Epoch 791/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.2871 - val_accuracy: 0.9048\n",
            "Epoch 792/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.3447 - val_accuracy: 0.8571\n",
            "Epoch 793/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.3687 - val_accuracy: 0.8571\n",
            "Epoch 794/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.3097 - val_accuracy: 0.9048\n",
            "Epoch 795/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.3559 - val_accuracy: 0.8571\n",
            "Epoch 796/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9912 - val_loss: 0.3039 - val_accuracy: 0.9048\n",
            "Epoch 797/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9912 - val_loss: 0.3115 - val_accuracy: 0.9048\n",
            "Epoch 798/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.3520 - val_accuracy: 0.8571\n",
            "Epoch 799/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.3319 - val_accuracy: 0.8571\n",
            "Epoch 800/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 0.9912 - val_loss: 0.4210 - val_accuracy: 0.8571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['accuracy']"
      ],
      "metadata": {
        "id": "xJgkAw983lZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssIHu5cM-QOn"
      },
      "source": [
        "#### Plot the learning curves\n",
        "\n",
        "We will now plot two graphs:\n",
        "* Epoch vs accuracy\n",
        "* Epoch vs loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRFBWnUX-QOo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "34e594bb-04a7-4d1e-9f25-737c9389a607"
      },
      "source": [
        "#Run this cell to plot the epoch vs accuracy graph\n",
        "\n",
        "try:\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show() "
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj0Ir6Sr-QOq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5e7e3702-073a-49bd-e35a-e1f64278c179"
      },
      "source": [
        "#Run this cell to plot the epoch vs loss graph\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrsUWJwj-QOr"
      },
      "source": [
        "Oh no! We have overfit our dataset. You should now try to now try to mitigate this overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6N_uo6m-QOs"
      },
      "source": [
        "#### Reducing overfitting in the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGME_x9a-QOs"
      },
      "source": [
        "You should now define a new regularised model.\n",
        "The specs for the regularised model are the same as our original model, with the addition of two dropout layers, weight decay, and a batch normalisation layer. \n",
        "\n",
        "In particular:\n",
        "\n",
        "* Add a dropout layer after the 3rd Dense layer\n",
        "* Then there should be two more Dense layers with 128 units before a batch normalisation layer\n",
        "* Following this, two more Dense layers with 64 units and then another Dropout layer\n",
        "* Two more Dense layers with 64 units and then the final 3-way softmax layer\n",
        "* Add weight decay (l2 kernel regularisation) in all Dense layers except the final softmax layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYytfpmm-QOv"
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_regularised_model(input_shape, dropout_rate, weight_decay):\n",
        "    \"\"\"\n",
        "    This function should build a regularised Sequential model according to the above specification. \n",
        "    The dropout_rate argument in the function should be used to set the Dropout rate for all Dropout layers.\n",
        "    L2 kernel regularisation (weight decay) should be added using the weight_decay argument to \n",
        "    set the weight decay coefficient in all Dense layers that use L2 regularisation.\n",
        "    Ensure the weights are initialised by providing the input_shape argument in the first layer, given by the\n",
        "    function argument input_shape.\n",
        "    Your function should return the model.\n",
        "    \"\"\"\n",
        "    model= tf.keras.Sequential([tf.keras.layers.Dense(128,kernel_regularizer=tf.keras.regularizers.L2(weight_decay),activation='relu',input_shape=input_shape),\n",
        "                                tf.keras.layers.Dense(100,kernel_regularizer=tf.keras.regularizers.L2(weight_decay),activation='relu'),\n",
        "                                tf.keras.layers.Dropout(dropout_rate),\n",
        "                                tf.keras.layers.Dense(100,kernel_regularizer=tf.keras.regularizers.L2(weight_decay),activation='relu'),\n",
        "\n",
        "                                tf.keras.layers.Dense(3,activation='softmax')\n",
        "\n",
        "     ])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw79AOPy-QOx"
      },
      "source": [
        "#### Instantiate, compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO8JYVXB-QOz"
      },
      "source": [
        "# Instantiate the model, using a dropout rate of 0.3 and weight decay coefficient of 0.001\n",
        "\n",
        "reg_model = get_regularised_model(train_data[0].shape, 0.3, 0.001)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOEqCQ3I-QO2"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "compile_model(reg_model)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Eg83stX-QO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82598a75-639d-494c-96c1-cfa8d645a359"
      },
      "source": [
        "# Train the model\n",
        "\n",
        "reg_history = train_model(reg_model, train_data, train_targets, epochs=800)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "10/10 [==============================] - 1s 23ms/step - loss: 1.4165 - accuracy: 0.3158 - val_loss: 1.2242 - val_accuracy: 0.4762\n",
            "Epoch 2/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3261 - accuracy: 0.3860 - val_loss: 1.1970 - val_accuracy: 0.6190\n",
            "Epoch 3/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2149 - accuracy: 0.4825 - val_loss: 1.1870 - val_accuracy: 0.4762\n",
            "Epoch 4/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2156 - accuracy: 0.4211 - val_loss: 1.1818 - val_accuracy: 0.4286\n",
            "Epoch 5/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1729 - accuracy: 0.5877 - val_loss: 1.1656 - val_accuracy: 0.5238\n",
            "Epoch 6/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1602 - accuracy: 0.5526 - val_loss: 1.1389 - val_accuracy: 0.5238\n",
            "Epoch 7/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1833 - accuracy: 0.5526 - val_loss: 1.1148 - val_accuracy: 0.5238\n",
            "Epoch 8/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0771 - accuracy: 0.6316 - val_loss: 1.0941 - val_accuracy: 0.5238\n",
            "Epoch 9/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0900 - accuracy: 0.6579 - val_loss: 1.0778 - val_accuracy: 0.5238\n",
            "Epoch 10/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0942 - accuracy: 0.6842 - val_loss: 1.0568 - val_accuracy: 0.5238\n",
            "Epoch 11/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0360 - accuracy: 0.6842 - val_loss: 1.0423 - val_accuracy: 0.5238\n",
            "Epoch 12/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9972 - accuracy: 0.7193 - val_loss: 1.0259 - val_accuracy: 0.5238\n",
            "Epoch 13/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9892 - accuracy: 0.7281 - val_loss: 1.0126 - val_accuracy: 0.5238\n",
            "Epoch 14/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9174 - accuracy: 0.7632 - val_loss: 0.9996 - val_accuracy: 0.5238\n",
            "Epoch 15/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9483 - accuracy: 0.7193 - val_loss: 0.9786 - val_accuracy: 0.5238\n",
            "Epoch 16/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9154 - accuracy: 0.7105 - val_loss: 0.9571 - val_accuracy: 0.5238\n",
            "Epoch 17/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9172 - accuracy: 0.7281 - val_loss: 0.9423 - val_accuracy: 0.5238\n",
            "Epoch 18/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8728 - accuracy: 0.7193 - val_loss: 0.9248 - val_accuracy: 0.5238\n",
            "Epoch 19/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8588 - accuracy: 0.7456 - val_loss: 0.9091 - val_accuracy: 0.5238\n",
            "Epoch 20/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8142 - accuracy: 0.7368 - val_loss: 0.8740 - val_accuracy: 0.5238\n",
            "Epoch 21/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7952 - accuracy: 0.7719 - val_loss: 0.8556 - val_accuracy: 0.5238\n",
            "Epoch 22/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7642 - accuracy: 0.7807 - val_loss: 0.8320 - val_accuracy: 0.5714\n",
            "Epoch 23/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7604 - accuracy: 0.7982 - val_loss: 0.8035 - val_accuracy: 0.7143\n",
            "Epoch 24/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7362 - accuracy: 0.8246 - val_loss: 0.7917 - val_accuracy: 0.6190\n",
            "Epoch 25/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7182 - accuracy: 0.7807 - val_loss: 0.7701 - val_accuracy: 0.7143\n",
            "Epoch 26/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7167 - accuracy: 0.7719 - val_loss: 0.7466 - val_accuracy: 0.7619\n",
            "Epoch 27/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6880 - accuracy: 0.8158 - val_loss: 0.7357 - val_accuracy: 0.7143\n",
            "Epoch 28/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.7807 - val_loss: 0.7181 - val_accuracy: 0.8095\n",
            "Epoch 29/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.8509 - val_loss: 0.7169 - val_accuracy: 0.7143\n",
            "Epoch 30/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6293 - accuracy: 0.8246 - val_loss: 0.6985 - val_accuracy: 0.7619\n",
            "Epoch 31/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6365 - accuracy: 0.7982 - val_loss: 0.6764 - val_accuracy: 0.8571\n",
            "Epoch 32/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6049 - accuracy: 0.8684 - val_loss: 0.6620 - val_accuracy: 0.8571\n",
            "Epoch 33/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5951 - accuracy: 0.8421 - val_loss: 0.6430 - val_accuracy: 0.8571\n",
            "Epoch 34/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.8421 - val_loss: 0.6336 - val_accuracy: 0.8571\n",
            "Epoch 35/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.9211 - val_loss: 0.6210 - val_accuracy: 0.8571\n",
            "Epoch 36/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6065 - accuracy: 0.8158 - val_loss: 0.6130 - val_accuracy: 0.8571\n",
            "Epoch 37/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7982 - val_loss: 0.6126 - val_accuracy: 0.8571\n",
            "Epoch 38/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5560 - accuracy: 0.8421 - val_loss: 0.5927 - val_accuracy: 0.8571\n",
            "Epoch 39/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.8772 - val_loss: 0.5684 - val_accuracy: 0.9048\n",
            "Epoch 40/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5574 - accuracy: 0.8333 - val_loss: 0.5553 - val_accuracy: 0.9048\n",
            "Epoch 41/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.8860 - val_loss: 0.5602 - val_accuracy: 0.8571\n",
            "Epoch 42/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5260 - accuracy: 0.9035 - val_loss: 0.5531 - val_accuracy: 0.8571\n",
            "Epoch 43/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5325 - accuracy: 0.8333 - val_loss: 0.5383 - val_accuracy: 0.9048\n",
            "Epoch 44/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.8421 - val_loss: 0.5328 - val_accuracy: 0.9048\n",
            "Epoch 45/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5212 - accuracy: 0.8333 - val_loss: 0.5360 - val_accuracy: 0.8571\n",
            "Epoch 46/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5006 - accuracy: 0.8860 - val_loss: 0.5314 - val_accuracy: 0.8571\n",
            "Epoch 47/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.9474 - val_loss: 0.5148 - val_accuracy: 0.9048\n",
            "Epoch 48/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.9211 - val_loss: 0.5011 - val_accuracy: 0.9048\n",
            "Epoch 49/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.9211 - val_loss: 0.4890 - val_accuracy: 0.9048\n",
            "Epoch 50/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.9298 - val_loss: 0.4826 - val_accuracy: 0.9048\n",
            "Epoch 51/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.9298 - val_loss: 0.4780 - val_accuracy: 0.9048\n",
            "Epoch 52/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.8860 - val_loss: 0.4711 - val_accuracy: 0.9048\n",
            "Epoch 53/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.9123 - val_loss: 0.4616 - val_accuracy: 0.9048\n",
            "Epoch 54/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.9649 - val_loss: 0.4595 - val_accuracy: 0.9048\n",
            "Epoch 55/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.9035 - val_loss: 0.4673 - val_accuracy: 0.9048\n",
            "Epoch 56/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.9035 - val_loss: 0.4574 - val_accuracy: 0.9048\n",
            "Epoch 57/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.9211 - val_loss: 0.4383 - val_accuracy: 0.9524\n",
            "Epoch 58/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.9211 - val_loss: 0.4328 - val_accuracy: 0.9524\n",
            "Epoch 59/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.9386 - val_loss: 0.4271 - val_accuracy: 0.9048\n",
            "Epoch 60/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.9035 - val_loss: 0.4270 - val_accuracy: 0.9048\n",
            "Epoch 61/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.9386 - val_loss: 0.4247 - val_accuracy: 0.9048\n",
            "Epoch 62/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.9123 - val_loss: 0.4080 - val_accuracy: 0.9524\n",
            "Epoch 63/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.9298 - val_loss: 0.4026 - val_accuracy: 0.9524\n",
            "Epoch 64/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3695 - accuracy: 0.9561 - val_loss: 0.3988 - val_accuracy: 0.9524\n",
            "Epoch 65/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.9561 - val_loss: 0.3931 - val_accuracy: 0.9524\n",
            "Epoch 66/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.9561 - val_loss: 0.3891 - val_accuracy: 0.9524\n",
            "Epoch 67/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.9561 - val_loss: 0.3862 - val_accuracy: 0.9048\n",
            "Epoch 68/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.9386 - val_loss: 0.3794 - val_accuracy: 0.9524\n",
            "Epoch 69/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.9298 - val_loss: 0.3753 - val_accuracy: 0.9524\n",
            "Epoch 70/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.9386 - val_loss: 0.3715 - val_accuracy: 0.9524\n",
            "Epoch 71/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.9561 - val_loss: 0.3714 - val_accuracy: 0.9048\n",
            "Epoch 72/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.9386 - val_loss: 0.3650 - val_accuracy: 0.9524\n",
            "Epoch 73/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3476 - accuracy: 0.9474 - val_loss: 0.3591 - val_accuracy: 0.9524\n",
            "Epoch 74/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.9561 - val_loss: 0.3562 - val_accuracy: 0.9524\n",
            "Epoch 75/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3375 - accuracy: 0.9737 - val_loss: 0.3519 - val_accuracy: 0.9524\n",
            "Epoch 76/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3150 - accuracy: 0.9474 - val_loss: 0.3479 - val_accuracy: 0.9524\n",
            "Epoch 77/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.9561 - val_loss: 0.3493 - val_accuracy: 0.9048\n",
            "Epoch 78/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.9298 - val_loss: 0.3437 - val_accuracy: 0.9524\n",
            "Epoch 79/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.9211 - val_loss: 0.3392 - val_accuracy: 0.9524\n",
            "Epoch 80/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.9474 - val_loss: 0.3380 - val_accuracy: 0.9524\n",
            "Epoch 81/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.9123 - val_loss: 0.3481 - val_accuracy: 0.9048\n",
            "Epoch 82/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.9649 - val_loss: 0.3313 - val_accuracy: 0.9524\n",
            "Epoch 83/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2864 - accuracy: 0.9825 - val_loss: 0.3284 - val_accuracy: 0.9524\n",
            "Epoch 84/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3051 - accuracy: 0.9825 - val_loss: 0.3246 - val_accuracy: 0.9524\n",
            "Epoch 85/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3083 - accuracy: 0.9737 - val_loss: 0.3220 - val_accuracy: 0.9524\n",
            "Epoch 86/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2925 - accuracy: 0.9649 - val_loss: 0.3370 - val_accuracy: 0.9048\n",
            "Epoch 87/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3112 - accuracy: 0.9474 - val_loss: 0.3162 - val_accuracy: 0.9524\n",
            "Epoch 88/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3038 - accuracy: 0.9561 - val_loss: 0.3134 - val_accuracy: 0.9524\n",
            "Epoch 89/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2747 - accuracy: 0.9649 - val_loss: 0.3123 - val_accuracy: 0.9524\n",
            "Epoch 90/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3042 - accuracy: 0.9211 - val_loss: 0.3103 - val_accuracy: 0.9524\n",
            "Epoch 91/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2945 - accuracy: 0.9561 - val_loss: 0.3077 - val_accuracy: 0.9524\n",
            "Epoch 92/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2694 - accuracy: 0.9825 - val_loss: 0.3047 - val_accuracy: 0.9524\n",
            "Epoch 93/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2855 - accuracy: 0.9474 - val_loss: 0.3025 - val_accuracy: 0.9524\n",
            "Epoch 94/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2963 - accuracy: 0.9561 - val_loss: 0.3004 - val_accuracy: 0.9524\n",
            "Epoch 95/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2918 - accuracy: 0.9561 - val_loss: 0.3002 - val_accuracy: 0.9524\n",
            "Epoch 96/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2735 - accuracy: 0.9737 - val_loss: 0.2991 - val_accuracy: 0.9048\n",
            "Epoch 97/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2879 - accuracy: 0.9474 - val_loss: 0.2952 - val_accuracy: 0.9524\n",
            "Epoch 98/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2635 - accuracy: 0.9649 - val_loss: 0.2950 - val_accuracy: 0.9524\n",
            "Epoch 99/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2452 - accuracy: 0.9825 - val_loss: 0.2916 - val_accuracy: 0.9524\n",
            "Epoch 100/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.9386 - val_loss: 0.2907 - val_accuracy: 0.9524\n",
            "Epoch 101/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2767 - accuracy: 0.9474 - val_loss: 0.2922 - val_accuracy: 0.9048\n",
            "Epoch 102/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2467 - accuracy: 0.9825 - val_loss: 0.2884 - val_accuracy: 0.9524\n",
            "Epoch 103/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.9737 - val_loss: 0.2858 - val_accuracy: 0.9524\n",
            "Epoch 104/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2463 - accuracy: 0.9561 - val_loss: 0.2869 - val_accuracy: 0.9048\n",
            "Epoch 105/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2594 - accuracy: 0.9649 - val_loss: 0.2855 - val_accuracy: 0.9048\n",
            "Epoch 106/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2852 - accuracy: 0.9386 - val_loss: 0.2800 - val_accuracy: 0.9524\n",
            "Epoch 107/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2565 - accuracy: 0.9737 - val_loss: 0.2820 - val_accuracy: 0.9048\n",
            "Epoch 108/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2625 - accuracy: 0.9737 - val_loss: 0.2774 - val_accuracy: 0.9524\n",
            "Epoch 109/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2456 - accuracy: 0.9649 - val_loss: 0.2764 - val_accuracy: 0.9524\n",
            "Epoch 110/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2458 - accuracy: 0.9561 - val_loss: 0.2760 - val_accuracy: 0.9524\n",
            "Epoch 111/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2615 - accuracy: 0.9561 - val_loss: 0.2776 - val_accuracy: 0.9048\n",
            "Epoch 112/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2532 - accuracy: 0.9561 - val_loss: 0.2751 - val_accuracy: 0.9048\n",
            "Epoch 113/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2307 - accuracy: 0.9825 - val_loss: 0.2717 - val_accuracy: 0.9524\n",
            "Epoch 114/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2235 - accuracy: 0.9737 - val_loss: 0.2699 - val_accuracy: 0.9524\n",
            "Epoch 115/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2503 - accuracy: 0.9561 - val_loss: 0.2706 - val_accuracy: 0.9048\n",
            "Epoch 116/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2297 - accuracy: 0.9825 - val_loss: 0.2690 - val_accuracy: 0.9524\n",
            "Epoch 117/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2555 - accuracy: 0.9561 - val_loss: 0.2676 - val_accuracy: 0.9524\n",
            "Epoch 118/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2339 - accuracy: 0.9649 - val_loss: 0.2670 - val_accuracy: 0.9524\n",
            "Epoch 119/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2229 - accuracy: 0.9737 - val_loss: 0.2656 - val_accuracy: 0.9524\n",
            "Epoch 120/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2481 - accuracy: 0.9825 - val_loss: 0.2645 - val_accuracy: 0.9524\n",
            "Epoch 121/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2239 - accuracy: 0.9737 - val_loss: 0.2640 - val_accuracy: 0.9524\n",
            "Epoch 122/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2347 - accuracy: 0.9737 - val_loss: 0.2631 - val_accuracy: 0.9524\n",
            "Epoch 123/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2282 - accuracy: 0.9649 - val_loss: 0.2634 - val_accuracy: 0.9524\n",
            "Epoch 124/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2552 - accuracy: 0.9561 - val_loss: 0.2665 - val_accuracy: 0.9048\n",
            "Epoch 125/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2210 - accuracy: 0.9912 - val_loss: 0.2682 - val_accuracy: 0.9048\n",
            "Epoch 126/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2127 - accuracy: 0.9737 - val_loss: 0.2597 - val_accuracy: 0.9524\n",
            "Epoch 127/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2081 - accuracy: 0.9825 - val_loss: 0.2580 - val_accuracy: 0.9524\n",
            "Epoch 128/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2223 - accuracy: 0.9737 - val_loss: 0.2585 - val_accuracy: 0.9524\n",
            "Epoch 129/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2141 - accuracy: 0.9912 - val_loss: 0.2575 - val_accuracy: 0.9524\n",
            "Epoch 130/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2258 - accuracy: 0.9474 - val_loss: 0.2594 - val_accuracy: 0.9048\n",
            "Epoch 131/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2010 - accuracy: 0.9825 - val_loss: 0.2564 - val_accuracy: 0.9048\n",
            "Epoch 132/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2358 - accuracy: 0.9561 - val_loss: 0.2570 - val_accuracy: 0.9048\n",
            "Epoch 133/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2160 - accuracy: 0.9649 - val_loss: 0.2618 - val_accuracy: 0.9048\n",
            "Epoch 134/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2073 - accuracy: 0.9737 - val_loss: 0.2533 - val_accuracy: 0.9524\n",
            "Epoch 135/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2322 - accuracy: 0.9386 - val_loss: 0.2540 - val_accuracy: 0.9048\n",
            "Epoch 136/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1979 - accuracy: 0.9737 - val_loss: 0.2523 - val_accuracy: 0.9524\n",
            "Epoch 137/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2225 - accuracy: 0.9474 - val_loss: 0.2519 - val_accuracy: 0.9524\n",
            "Epoch 138/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2247 - accuracy: 0.9649 - val_loss: 0.2510 - val_accuracy: 0.9524\n",
            "Epoch 139/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2183 - accuracy: 0.9825 - val_loss: 0.2522 - val_accuracy: 0.9524\n",
            "Epoch 140/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2044 - accuracy: 0.9737 - val_loss: 0.2501 - val_accuracy: 0.9048\n",
            "Epoch 141/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1924 - accuracy: 0.9912 - val_loss: 0.2496 - val_accuracy: 0.9048\n",
            "Epoch 142/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1875 - accuracy: 0.9825 - val_loss: 0.2489 - val_accuracy: 0.9524\n",
            "Epoch 143/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2038 - accuracy: 0.9737 - val_loss: 0.2488 - val_accuracy: 0.9524\n",
            "Epoch 144/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2302 - accuracy: 0.9474 - val_loss: 0.2480 - val_accuracy: 0.9524\n",
            "Epoch 145/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2134 - accuracy: 0.9737 - val_loss: 0.2482 - val_accuracy: 0.9048\n",
            "Epoch 146/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2119 - accuracy: 0.9561 - val_loss: 0.2473 - val_accuracy: 0.9524\n",
            "Epoch 147/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2239 - accuracy: 0.9825 - val_loss: 0.2485 - val_accuracy: 0.9524\n",
            "Epoch 148/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2112 - accuracy: 0.9737 - val_loss: 0.2471 - val_accuracy: 0.9524\n",
            "Epoch 149/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2014 - accuracy: 0.9737 - val_loss: 0.2488 - val_accuracy: 0.9048\n",
            "Epoch 150/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2057 - accuracy: 0.9825 - val_loss: 0.2462 - val_accuracy: 0.9048\n",
            "Epoch 151/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1894 - accuracy: 0.9825 - val_loss: 0.2460 - val_accuracy: 0.9048\n",
            "Epoch 152/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1975 - accuracy: 0.9649 - val_loss: 0.2449 - val_accuracy: 0.9524\n",
            "Epoch 153/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1947 - accuracy: 0.9649 - val_loss: 0.2446 - val_accuracy: 0.9048\n",
            "Epoch 154/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2003 - accuracy: 0.9649 - val_loss: 0.2441 - val_accuracy: 0.9524\n",
            "Epoch 155/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2017 - accuracy: 0.9737 - val_loss: 0.2463 - val_accuracy: 0.9048\n",
            "Epoch 156/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1980 - accuracy: 0.9649 - val_loss: 0.2432 - val_accuracy: 0.9048\n",
            "Epoch 157/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1958 - accuracy: 0.9825 - val_loss: 0.2433 - val_accuracy: 0.9048\n",
            "Epoch 158/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1726 - accuracy: 0.9825 - val_loss: 0.2426 - val_accuracy: 0.9524\n",
            "Epoch 159/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2058 - accuracy: 0.9649 - val_loss: 0.2423 - val_accuracy: 0.9048\n",
            "Epoch 160/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1925 - accuracy: 0.9825 - val_loss: 0.2445 - val_accuracy: 0.9048\n",
            "Epoch 161/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2077 - accuracy: 0.9649 - val_loss: 0.2457 - val_accuracy: 0.9048\n",
            "Epoch 162/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1962 - accuracy: 0.9737 - val_loss: 0.2558 - val_accuracy: 0.9048\n",
            "Epoch 163/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1935 - accuracy: 0.9737 - val_loss: 0.2467 - val_accuracy: 0.9048\n",
            "Epoch 164/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1784 - accuracy: 0.9912 - val_loss: 0.2463 - val_accuracy: 0.9048\n",
            "Epoch 165/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1855 - accuracy: 0.9825 - val_loss: 0.2441 - val_accuracy: 0.9048\n",
            "Epoch 166/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1944 - accuracy: 0.9912 - val_loss: 0.2404 - val_accuracy: 0.9048\n",
            "Epoch 167/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1752 - accuracy: 0.9737 - val_loss: 0.2410 - val_accuracy: 0.9524\n",
            "Epoch 168/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1788 - accuracy: 0.9912 - val_loss: 0.2395 - val_accuracy: 0.9524\n",
            "Epoch 169/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1996 - accuracy: 0.9649 - val_loss: 0.2411 - val_accuracy: 0.9524\n",
            "Epoch 170/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1978 - accuracy: 0.9737 - val_loss: 0.2386 - val_accuracy: 0.9524\n",
            "Epoch 171/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1719 - accuracy: 0.9737 - val_loss: 0.2390 - val_accuracy: 0.9048\n",
            "Epoch 172/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1813 - accuracy: 0.9737 - val_loss: 0.2385 - val_accuracy: 0.9048\n",
            "Epoch 173/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1861 - accuracy: 0.9825 - val_loss: 0.2380 - val_accuracy: 0.9524\n",
            "Epoch 174/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1766 - accuracy: 0.9825 - val_loss: 0.2418 - val_accuracy: 0.9524\n",
            "Epoch 175/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1947 - accuracy: 0.9737 - val_loss: 0.2399 - val_accuracy: 0.9048\n",
            "Epoch 176/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1657 - accuracy: 0.9825 - val_loss: 0.2371 - val_accuracy: 0.9048\n",
            "Epoch 177/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1784 - accuracy: 0.9825 - val_loss: 0.2366 - val_accuracy: 0.9524\n",
            "Epoch 178/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1933 - accuracy: 0.9737 - val_loss: 0.2365 - val_accuracy: 0.9524\n",
            "Epoch 179/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1843 - accuracy: 0.9649 - val_loss: 0.2373 - val_accuracy: 0.9524\n",
            "Epoch 180/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1754 - accuracy: 0.9825 - val_loss: 0.2369 - val_accuracy: 0.9524\n",
            "Epoch 181/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1922 - accuracy: 0.9737 - val_loss: 0.2373 - val_accuracy: 0.9048\n",
            "Epoch 182/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2057 - accuracy: 0.9737 - val_loss: 0.2369 - val_accuracy: 0.9048\n",
            "Epoch 183/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1865 - accuracy: 0.9737 - val_loss: 0.2364 - val_accuracy: 0.9048\n",
            "Epoch 184/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1896 - accuracy: 0.9737 - val_loss: 0.2366 - val_accuracy: 0.9048\n",
            "Epoch 185/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1839 - accuracy: 0.9825 - val_loss: 0.2367 - val_accuracy: 0.9524\n",
            "Epoch 186/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1832 - accuracy: 0.9737 - val_loss: 0.2364 - val_accuracy: 0.9524\n",
            "Epoch 187/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1849 - accuracy: 0.9825 - val_loss: 0.2360 - val_accuracy: 0.9048\n",
            "Epoch 188/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1938 - accuracy: 0.9737 - val_loss: 0.2381 - val_accuracy: 0.9048\n",
            "Epoch 189/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1720 - accuracy: 0.9825 - val_loss: 0.2378 - val_accuracy: 0.9048\n",
            "Epoch 190/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1938 - accuracy: 0.9737 - val_loss: 0.2406 - val_accuracy: 0.9048\n",
            "Epoch 191/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1828 - accuracy: 0.9825 - val_loss: 0.2350 - val_accuracy: 0.9524\n",
            "Epoch 192/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1838 - accuracy: 0.9649 - val_loss: 0.2345 - val_accuracy: 0.9048\n",
            "Epoch 193/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1845 - accuracy: 0.9649 - val_loss: 0.2346 - val_accuracy: 0.9524\n",
            "Epoch 194/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1825 - accuracy: 0.9825 - val_loss: 0.2360 - val_accuracy: 0.9048\n",
            "Epoch 195/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.9825 - val_loss: 0.2384 - val_accuracy: 0.9524\n",
            "Epoch 196/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1734 - accuracy: 0.9737 - val_loss: 0.2345 - val_accuracy: 0.9524\n",
            "Epoch 197/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1741 - accuracy: 0.9912 - val_loss: 0.2399 - val_accuracy: 0.9048\n",
            "Epoch 198/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1911 - accuracy: 0.9649 - val_loss: 0.2350 - val_accuracy: 0.9048\n",
            "Epoch 199/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1698 - accuracy: 0.9912 - val_loss: 0.2367 - val_accuracy: 0.9048\n",
            "Epoch 200/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1832 - accuracy: 0.9737 - val_loss: 0.2338 - val_accuracy: 0.9524\n",
            "Epoch 201/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1844 - accuracy: 0.9737 - val_loss: 0.2346 - val_accuracy: 0.9048\n",
            "Epoch 202/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1722 - accuracy: 0.9825 - val_loss: 0.2362 - val_accuracy: 0.9048\n",
            "Epoch 203/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1669 - accuracy: 0.9825 - val_loss: 0.2360 - val_accuracy: 0.9048\n",
            "Epoch 204/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1876 - accuracy: 0.9737 - val_loss: 0.2328 - val_accuracy: 0.9048\n",
            "Epoch 205/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1774 - accuracy: 0.9825 - val_loss: 0.2351 - val_accuracy: 0.9048\n",
            "Epoch 206/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1732 - accuracy: 0.9825 - val_loss: 0.2359 - val_accuracy: 0.9048\n",
            "Epoch 207/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1725 - accuracy: 0.9737 - val_loss: 0.2327 - val_accuracy: 0.9524\n",
            "Epoch 208/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1846 - accuracy: 0.9825 - val_loss: 0.2327 - val_accuracy: 0.9048\n",
            "Epoch 209/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1662 - accuracy: 0.9825 - val_loss: 0.2327 - val_accuracy: 0.9048\n",
            "Epoch 210/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1858 - accuracy: 0.9825 - val_loss: 0.2341 - val_accuracy: 0.9048\n",
            "Epoch 211/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.9912 - val_loss: 0.2325 - val_accuracy: 0.9048\n",
            "Epoch 212/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1832 - accuracy: 0.9649 - val_loss: 0.2320 - val_accuracy: 0.9048\n",
            "Epoch 213/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1648 - accuracy: 0.9912 - val_loss: 0.2320 - val_accuracy: 0.9048\n",
            "Epoch 214/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1675 - accuracy: 0.9825 - val_loss: 0.2320 - val_accuracy: 0.9524\n",
            "Epoch 215/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1775 - accuracy: 0.9825 - val_loss: 0.2321 - val_accuracy: 0.9048\n",
            "Epoch 216/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1772 - accuracy: 0.9561 - val_loss: 0.2408 - val_accuracy: 0.9048\n",
            "Epoch 217/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1825 - accuracy: 0.9649 - val_loss: 0.2331 - val_accuracy: 0.9048\n",
            "Epoch 218/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1596 - accuracy: 0.9825 - val_loss: 0.2323 - val_accuracy: 0.9524\n",
            "Epoch 219/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1598 - accuracy: 0.9912 - val_loss: 0.2320 - val_accuracy: 0.9524\n",
            "Epoch 220/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1685 - accuracy: 0.9825 - val_loss: 0.2315 - val_accuracy: 0.9524\n",
            "Epoch 221/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1656 - accuracy: 0.9737 - val_loss: 0.2334 - val_accuracy: 0.9524\n",
            "Epoch 222/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1639 - accuracy: 0.9649 - val_loss: 0.2336 - val_accuracy: 0.9048\n",
            "Epoch 223/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1769 - accuracy: 0.9649 - val_loss: 0.2358 - val_accuracy: 0.9524\n",
            "Epoch 224/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1708 - accuracy: 0.9825 - val_loss: 0.2317 - val_accuracy: 0.9524\n",
            "Epoch 225/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1735 - accuracy: 0.9737 - val_loss: 0.2315 - val_accuracy: 0.9048\n",
            "Epoch 226/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1609 - accuracy: 0.9825 - val_loss: 0.2315 - val_accuracy: 0.9524\n",
            "Epoch 227/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1565 - accuracy: 0.9825 - val_loss: 0.2369 - val_accuracy: 0.9048\n",
            "Epoch 228/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1733 - accuracy: 0.9912 - val_loss: 0.2339 - val_accuracy: 0.9048\n",
            "Epoch 229/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1911 - accuracy: 0.9649 - val_loss: 0.2314 - val_accuracy: 0.9524\n",
            "Epoch 230/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1598 - accuracy: 0.9912 - val_loss: 0.2334 - val_accuracy: 0.9048\n",
            "Epoch 231/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1799 - accuracy: 0.9825 - val_loss: 0.2318 - val_accuracy: 0.9048\n",
            "Epoch 232/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1774 - accuracy: 0.9825 - val_loss: 0.2310 - val_accuracy: 0.9524\n",
            "Epoch 233/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1563 - accuracy: 0.9825 - val_loss: 0.2311 - val_accuracy: 0.9524\n",
            "Epoch 234/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1695 - accuracy: 0.9825 - val_loss: 0.2309 - val_accuracy: 0.9048\n",
            "Epoch 235/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1639 - accuracy: 0.9825 - val_loss: 0.2308 - val_accuracy: 0.9048\n",
            "Epoch 236/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1731 - accuracy: 0.9825 - val_loss: 0.2333 - val_accuracy: 0.9048\n",
            "Epoch 237/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1912 - accuracy: 0.9737 - val_loss: 0.2315 - val_accuracy: 0.9524\n",
            "Epoch 238/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1595 - accuracy: 0.9825 - val_loss: 0.2310 - val_accuracy: 0.9524\n",
            "Epoch 239/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1554 - accuracy: 0.9737 - val_loss: 0.2310 - val_accuracy: 0.9048\n",
            "Epoch 240/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1598 - accuracy: 0.9737 - val_loss: 0.2320 - val_accuracy: 0.9048\n",
            "Epoch 241/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1666 - accuracy: 0.9825 - val_loss: 0.2346 - val_accuracy: 0.9048\n",
            "Epoch 242/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1723 - accuracy: 0.9825 - val_loss: 0.2319 - val_accuracy: 0.9524\n",
            "Epoch 243/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1635 - accuracy: 0.9737 - val_loss: 0.2305 - val_accuracy: 0.9048\n",
            "Epoch 244/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 0.9912 - val_loss: 0.2309 - val_accuracy: 0.9524\n",
            "Epoch 245/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1737 - accuracy: 0.9912 - val_loss: 0.2335 - val_accuracy: 0.9048\n",
            "Epoch 246/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1613 - accuracy: 0.9825 - val_loss: 0.2343 - val_accuracy: 0.9048\n",
            "Epoch 247/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1521 - accuracy: 0.9737 - val_loss: 0.2305 - val_accuracy: 0.9524\n",
            "Epoch 248/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1548 - accuracy: 0.9912 - val_loss: 0.2297 - val_accuracy: 0.9048\n",
            "Epoch 249/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1762 - accuracy: 0.9737 - val_loss: 0.2296 - val_accuracy: 0.9048\n",
            "Epoch 250/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1696 - accuracy: 0.9825 - val_loss: 0.2300 - val_accuracy: 0.9524\n",
            "Epoch 251/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1577 - accuracy: 0.9825 - val_loss: 0.2296 - val_accuracy: 0.9524\n",
            "Epoch 252/800\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1467 - accuracy: 0.9825 - val_loss: 0.2296 - val_accuracy: 0.9048\n",
            "Epoch 253/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1699 - accuracy: 0.9825 - val_loss: 0.2334 - val_accuracy: 0.9048\n",
            "Epoch 254/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1519 - accuracy: 0.9825 - val_loss: 0.2298 - val_accuracy: 0.9048\n",
            "Epoch 255/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1678 - accuracy: 0.9649 - val_loss: 0.2359 - val_accuracy: 0.9048\n",
            "Epoch 256/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1468 - accuracy: 0.9912 - val_loss: 0.2333 - val_accuracy: 0.9048\n",
            "Epoch 257/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1440 - accuracy: 0.9825 - val_loss: 0.2295 - val_accuracy: 0.9048\n",
            "Epoch 258/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1671 - accuracy: 0.9825 - val_loss: 0.2295 - val_accuracy: 0.9048\n",
            "Epoch 259/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1553 - accuracy: 0.9825 - val_loss: 0.2314 - val_accuracy: 0.9048\n",
            "Epoch 260/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.9825 - val_loss: 0.2342 - val_accuracy: 0.9048\n",
            "Epoch 261/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1660 - accuracy: 0.9737 - val_loss: 0.2326 - val_accuracy: 0.9048\n",
            "Epoch 262/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1645 - accuracy: 0.9649 - val_loss: 0.2325 - val_accuracy: 0.9048\n",
            "Epoch 263/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1587 - accuracy: 0.9825 - val_loss: 0.2312 - val_accuracy: 0.9048\n",
            "Epoch 264/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1588 - accuracy: 0.9825 - val_loss: 0.2322 - val_accuracy: 0.9048\n",
            "Epoch 265/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1527 - accuracy: 0.9912 - val_loss: 0.2296 - val_accuracy: 0.9048\n",
            "Epoch 266/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1601 - accuracy: 0.9649 - val_loss: 0.2296 - val_accuracy: 0.9048\n",
            "Epoch 267/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1607 - accuracy: 0.9825 - val_loss: 0.2295 - val_accuracy: 0.9048\n",
            "Epoch 268/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1642 - accuracy: 0.9825 - val_loss: 0.2316 - val_accuracy: 0.9048\n",
            "Epoch 269/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1578 - accuracy: 0.9825 - val_loss: 0.2326 - val_accuracy: 0.9048\n",
            "Epoch 270/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1680 - accuracy: 0.9825 - val_loss: 0.2296 - val_accuracy: 0.9048\n",
            "Epoch 271/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1487 - accuracy: 0.9825 - val_loss: 0.2300 - val_accuracy: 0.9048\n",
            "Epoch 272/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1636 - accuracy: 0.9825 - val_loss: 0.2295 - val_accuracy: 0.9524\n",
            "Epoch 273/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1632 - accuracy: 0.9825 - val_loss: 0.2319 - val_accuracy: 0.9048\n",
            "Epoch 274/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1652 - accuracy: 0.9737 - val_loss: 0.2365 - val_accuracy: 0.9048\n",
            "Epoch 275/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1637 - accuracy: 0.9825 - val_loss: 0.2348 - val_accuracy: 0.9048\n",
            "Epoch 276/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1616 - accuracy: 0.9737 - val_loss: 0.2305 - val_accuracy: 0.9524\n",
            "Epoch 277/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1612 - accuracy: 0.9825 - val_loss: 0.2317 - val_accuracy: 0.9048\n",
            "Epoch 278/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1509 - accuracy: 0.9825 - val_loss: 0.2361 - val_accuracy: 0.9048\n",
            "Epoch 279/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1585 - accuracy: 0.9912 - val_loss: 0.2305 - val_accuracy: 0.9524\n",
            "Epoch 280/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1650 - accuracy: 0.9825 - val_loss: 0.2362 - val_accuracy: 0.9048\n",
            "Epoch 281/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 0.9912 - val_loss: 0.2330 - val_accuracy: 0.9048\n",
            "Epoch 282/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1632 - accuracy: 0.9737 - val_loss: 0.2308 - val_accuracy: 0.9048\n",
            "Epoch 283/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1583 - accuracy: 0.9825 - val_loss: 0.2310 - val_accuracy: 0.9048\n",
            "Epoch 284/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1619 - accuracy: 0.9825 - val_loss: 0.2297 - val_accuracy: 0.9048\n",
            "Epoch 285/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1527 - accuracy: 0.9912 - val_loss: 0.2448 - val_accuracy: 0.9048\n",
            "Epoch 286/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.9649 - val_loss: 0.2338 - val_accuracy: 0.9048\n",
            "Epoch 287/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1387 - accuracy: 0.9912 - val_loss: 0.2297 - val_accuracy: 0.9524\n",
            "Epoch 288/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1571 - accuracy: 0.9912 - val_loss: 0.2294 - val_accuracy: 0.9048\n",
            "Epoch 289/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1471 - accuracy: 0.9912 - val_loss: 0.2303 - val_accuracy: 0.9048\n",
            "Epoch 290/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1582 - accuracy: 0.9737 - val_loss: 0.2307 - val_accuracy: 0.9048\n",
            "Epoch 291/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1506 - accuracy: 0.9912 - val_loss: 0.2324 - val_accuracy: 0.9048\n",
            "Epoch 292/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1548 - accuracy: 0.9912 - val_loss: 0.2324 - val_accuracy: 0.9048\n",
            "Epoch 293/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1540 - accuracy: 0.9912 - val_loss: 0.2317 - val_accuracy: 0.9048\n",
            "Epoch 294/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1486 - accuracy: 0.9737 - val_loss: 0.2297 - val_accuracy: 0.9048\n",
            "Epoch 295/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1486 - accuracy: 0.9825 - val_loss: 0.2312 - val_accuracy: 0.9048\n",
            "Epoch 296/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9737 - val_loss: 0.2303 - val_accuracy: 0.9048\n",
            "Epoch 297/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1561 - accuracy: 0.9737 - val_loss: 0.2308 - val_accuracy: 0.9524\n",
            "Epoch 298/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1528 - accuracy: 0.9912 - val_loss: 0.2307 - val_accuracy: 0.9048\n",
            "Epoch 299/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1512 - accuracy: 0.9825 - val_loss: 0.2304 - val_accuracy: 0.9048\n",
            "Epoch 300/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1648 - accuracy: 0.9737 - val_loss: 0.2423 - val_accuracy: 0.9048\n",
            "Epoch 301/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1470 - accuracy: 0.9912 - val_loss: 0.2324 - val_accuracy: 0.9048\n",
            "Epoch 302/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1379 - accuracy: 0.9912 - val_loss: 0.2306 - val_accuracy: 0.9048\n",
            "Epoch 303/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1490 - accuracy: 0.9912 - val_loss: 0.2309 - val_accuracy: 0.9524\n",
            "Epoch 304/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1480 - accuracy: 0.9825 - val_loss: 0.2315 - val_accuracy: 0.9048\n",
            "Epoch 305/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1677 - accuracy: 0.9737 - val_loss: 0.2306 - val_accuracy: 0.9048\n",
            "Epoch 306/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1625 - accuracy: 0.9825 - val_loss: 0.2339 - val_accuracy: 0.9048\n",
            "Epoch 307/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1650 - accuracy: 0.9737 - val_loss: 0.2326 - val_accuracy: 0.9048\n",
            "Epoch 308/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9825 - val_loss: 0.2317 - val_accuracy: 0.9048\n",
            "Epoch 309/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1717 - accuracy: 0.9561 - val_loss: 0.2406 - val_accuracy: 0.9048\n",
            "Epoch 310/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1525 - accuracy: 0.9825 - val_loss: 0.2373 - val_accuracy: 0.9048\n",
            "Epoch 311/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1411 - accuracy: 0.9912 - val_loss: 0.2357 - val_accuracy: 0.9048\n",
            "Epoch 312/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1456 - accuracy: 0.9912 - val_loss: 0.2333 - val_accuracy: 0.9048\n",
            "Epoch 313/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1732 - accuracy: 0.9737 - val_loss: 0.2314 - val_accuracy: 0.9524\n",
            "Epoch 314/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1499 - accuracy: 0.9825 - val_loss: 0.2312 - val_accuracy: 0.9524\n",
            "Epoch 315/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1627 - accuracy: 0.9825 - val_loss: 0.2348 - val_accuracy: 0.9048\n",
            "Epoch 316/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1488 - accuracy: 0.9737 - val_loss: 0.2501 - val_accuracy: 0.9048\n",
            "Epoch 317/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1485 - accuracy: 0.9825 - val_loss: 0.2328 - val_accuracy: 0.9048\n",
            "Epoch 318/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1492 - accuracy: 0.9825 - val_loss: 0.2314 - val_accuracy: 0.9048\n",
            "Epoch 319/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1563 - accuracy: 0.9825 - val_loss: 0.2406 - val_accuracy: 0.9048\n",
            "Epoch 320/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1682 - accuracy: 0.9825 - val_loss: 0.2306 - val_accuracy: 0.9048\n",
            "Epoch 321/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1560 - accuracy: 0.9825 - val_loss: 0.2302 - val_accuracy: 0.9048\n",
            "Epoch 322/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1478 - accuracy: 0.9912 - val_loss: 0.2306 - val_accuracy: 0.9048\n",
            "Epoch 323/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1454 - accuracy: 0.9737 - val_loss: 0.2356 - val_accuracy: 0.8571\n",
            "Epoch 324/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1654 - accuracy: 0.9825 - val_loss: 0.2390 - val_accuracy: 0.9048\n",
            "Epoch 325/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1422 - accuracy: 0.9825 - val_loss: 0.2395 - val_accuracy: 0.9048\n",
            "Epoch 326/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1613 - accuracy: 0.9825 - val_loss: 0.2334 - val_accuracy: 0.9048\n",
            "Epoch 327/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1401 - accuracy: 0.9912 - val_loss: 0.2309 - val_accuracy: 0.9048\n",
            "Epoch 328/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1507 - accuracy: 0.9825 - val_loss: 0.2329 - val_accuracy: 0.9048\n",
            "Epoch 329/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1612 - accuracy: 0.9649 - val_loss: 0.2307 - val_accuracy: 0.9048\n",
            "Epoch 330/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1627 - accuracy: 0.9825 - val_loss: 0.2310 - val_accuracy: 0.9048\n",
            "Epoch 331/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.9912 - val_loss: 0.2312 - val_accuracy: 0.9048\n",
            "Epoch 332/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1574 - accuracy: 0.9912 - val_loss: 0.2349 - val_accuracy: 0.9048\n",
            "Epoch 333/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1590 - accuracy: 0.9912 - val_loss: 0.2314 - val_accuracy: 0.9048\n",
            "Epoch 334/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1563 - accuracy: 0.9825 - val_loss: 0.2310 - val_accuracy: 0.9048\n",
            "Epoch 335/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1477 - accuracy: 0.9825 - val_loss: 0.2310 - val_accuracy: 0.9048\n",
            "Epoch 336/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1452 - accuracy: 0.9825 - val_loss: 0.2472 - val_accuracy: 0.9048\n",
            "Epoch 337/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1563 - accuracy: 0.9737 - val_loss: 0.2391 - val_accuracy: 0.9048\n",
            "Epoch 338/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1321 - accuracy: 0.9912 - val_loss: 0.2358 - val_accuracy: 0.8571\n",
            "Epoch 339/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1430 - accuracy: 0.9825 - val_loss: 0.2316 - val_accuracy: 0.9048\n",
            "Epoch 340/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1426 - accuracy: 0.9825 - val_loss: 0.2315 - val_accuracy: 0.9048\n",
            "Epoch 341/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1360 - accuracy: 0.9912 - val_loss: 0.2480 - val_accuracy: 0.9048\n",
            "Epoch 342/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9737 - val_loss: 0.2313 - val_accuracy: 0.9048\n",
            "Epoch 343/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1394 - accuracy: 0.9825 - val_loss: 0.2309 - val_accuracy: 0.9048\n",
            "Epoch 344/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1460 - accuracy: 0.9825 - val_loss: 0.2311 - val_accuracy: 0.8571\n",
            "Epoch 345/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1337 - accuracy: 0.9912 - val_loss: 0.2310 - val_accuracy: 0.9048\n",
            "Epoch 346/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1493 - accuracy: 0.9825 - val_loss: 0.2317 - val_accuracy: 0.9048\n",
            "Epoch 347/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1332 - accuracy: 0.9912 - val_loss: 0.2333 - val_accuracy: 0.9048\n",
            "Epoch 348/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1418 - accuracy: 0.9825 - val_loss: 0.2320 - val_accuracy: 0.9048\n",
            "Epoch 349/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1426 - accuracy: 0.9825 - val_loss: 0.2349 - val_accuracy: 0.9048\n",
            "Epoch 350/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1425 - accuracy: 0.9825 - val_loss: 0.2310 - val_accuracy: 0.9048\n",
            "Epoch 351/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1610 - accuracy: 0.9737 - val_loss: 0.2315 - val_accuracy: 0.8571\n",
            "Epoch 352/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1518 - accuracy: 0.9825 - val_loss: 0.2322 - val_accuracy: 0.9048\n",
            "Epoch 353/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1472 - accuracy: 0.9737 - val_loss: 0.2484 - val_accuracy: 0.9048\n",
            "Epoch 354/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1473 - accuracy: 0.9912 - val_loss: 0.2316 - val_accuracy: 0.9048\n",
            "Epoch 355/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1467 - accuracy: 0.9825 - val_loss: 0.2322 - val_accuracy: 0.9048\n",
            "Epoch 356/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1455 - accuracy: 0.9825 - val_loss: 0.2321 - val_accuracy: 0.9048\n",
            "Epoch 357/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1457 - accuracy: 0.9825 - val_loss: 0.2321 - val_accuracy: 0.9048\n",
            "Epoch 358/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1492 - accuracy: 0.9825 - val_loss: 0.2336 - val_accuracy: 0.9048\n",
            "Epoch 359/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1590 - accuracy: 0.9737 - val_loss: 0.2323 - val_accuracy: 0.9048\n",
            "Epoch 360/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1380 - accuracy: 0.9912 - val_loss: 0.2327 - val_accuracy: 0.8571\n",
            "Epoch 361/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1462 - accuracy: 0.9825 - val_loss: 0.2352 - val_accuracy: 0.9048\n",
            "Epoch 362/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1576 - accuracy: 0.9825 - val_loss: 0.2352 - val_accuracy: 0.9048\n",
            "Epoch 363/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1374 - accuracy: 0.9912 - val_loss: 0.2321 - val_accuracy: 0.9048\n",
            "Epoch 364/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1534 - accuracy: 0.9825 - val_loss: 0.2325 - val_accuracy: 0.9048\n",
            "Epoch 365/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.9912 - val_loss: 0.2333 - val_accuracy: 0.9048\n",
            "Epoch 366/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1418 - accuracy: 0.9912 - val_loss: 0.2327 - val_accuracy: 0.9048\n",
            "Epoch 367/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1420 - accuracy: 0.9912 - val_loss: 0.2357 - val_accuracy: 0.8571\n",
            "Epoch 368/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.9825 - val_loss: 0.2322 - val_accuracy: 0.9048\n",
            "Epoch 369/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1313 - accuracy: 0.9912 - val_loss: 0.2308 - val_accuracy: 0.9048\n",
            "Epoch 370/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1396 - accuracy: 0.9825 - val_loss: 0.2313 - val_accuracy: 0.9048\n",
            "Epoch 371/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1550 - accuracy: 0.9825 - val_loss: 0.2312 - val_accuracy: 0.9048\n",
            "Epoch 372/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1377 - accuracy: 0.9825 - val_loss: 0.2450 - val_accuracy: 0.9048\n",
            "Epoch 373/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1649 - accuracy: 0.9649 - val_loss: 0.2328 - val_accuracy: 0.9048\n",
            "Epoch 374/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1588 - accuracy: 0.9825 - val_loss: 0.2309 - val_accuracy: 0.9048\n",
            "Epoch 375/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1427 - accuracy: 0.9825 - val_loss: 0.2327 - val_accuracy: 0.9048\n",
            "Epoch 376/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9912 - val_loss: 0.2456 - val_accuracy: 0.9048\n",
            "Epoch 377/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1479 - accuracy: 0.9912 - val_loss: 0.2379 - val_accuracy: 0.8571\n",
            "Epoch 378/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1320 - accuracy: 0.9912 - val_loss: 0.2399 - val_accuracy: 0.9048\n",
            "Epoch 379/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9912 - val_loss: 0.2351 - val_accuracy: 0.8571\n",
            "Epoch 380/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1362 - accuracy: 0.9912 - val_loss: 0.2321 - val_accuracy: 0.9048\n",
            "Epoch 381/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1443 - accuracy: 0.9825 - val_loss: 0.2313 - val_accuracy: 0.9048\n",
            "Epoch 382/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1256 - accuracy: 0.9912 - val_loss: 0.2337 - val_accuracy: 0.9048\n",
            "Epoch 383/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1340 - accuracy: 0.9825 - val_loss: 0.2326 - val_accuracy: 0.9048\n",
            "Epoch 384/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1397 - accuracy: 0.9912 - val_loss: 0.2397 - val_accuracy: 0.9048\n",
            "Epoch 385/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1359 - accuracy: 0.9825 - val_loss: 0.2372 - val_accuracy: 0.8571\n",
            "Epoch 386/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1303 - accuracy: 0.9912 - val_loss: 0.2385 - val_accuracy: 0.8571\n",
            "Epoch 387/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1427 - accuracy: 0.9912 - val_loss: 0.2339 - val_accuracy: 0.9048\n",
            "Epoch 388/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1396 - accuracy: 0.9825 - val_loss: 0.2320 - val_accuracy: 0.8571\n",
            "Epoch 389/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1404 - accuracy: 0.9825 - val_loss: 0.2322 - val_accuracy: 0.9048\n",
            "Epoch 390/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1548 - accuracy: 0.9737 - val_loss: 0.2451 - val_accuracy: 0.9048\n",
            "Epoch 391/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1521 - accuracy: 0.9825 - val_loss: 0.2347 - val_accuracy: 0.9048\n",
            "Epoch 392/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1420 - accuracy: 0.9912 - val_loss: 0.2340 - val_accuracy: 0.9048\n",
            "Epoch 393/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1537 - accuracy: 0.9912 - val_loss: 0.2336 - val_accuracy: 0.9048\n",
            "Epoch 394/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1363 - accuracy: 0.9912 - val_loss: 0.2321 - val_accuracy: 0.9048\n",
            "Epoch 395/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1450 - accuracy: 0.9912 - val_loss: 0.2321 - val_accuracy: 0.9048\n",
            "Epoch 396/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1354 - accuracy: 0.9825 - val_loss: 0.2317 - val_accuracy: 0.9048\n",
            "Epoch 397/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1297 - accuracy: 0.9912 - val_loss: 0.2340 - val_accuracy: 0.9048\n",
            "Epoch 398/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1244 - accuracy: 0.9912 - val_loss: 0.2335 - val_accuracy: 0.9048\n",
            "Epoch 399/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1483 - accuracy: 0.9825 - val_loss: 0.2368 - val_accuracy: 0.8571\n",
            "Epoch 400/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1279 - accuracy: 0.9825 - val_loss: 0.2331 - val_accuracy: 0.9048\n",
            "Epoch 401/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1352 - accuracy: 0.9912 - val_loss: 0.2319 - val_accuracy: 0.8571\n",
            "Epoch 402/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1418 - accuracy: 0.9912 - val_loss: 0.2320 - val_accuracy: 0.8571\n",
            "Epoch 403/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1313 - accuracy: 0.9912 - val_loss: 0.2323 - val_accuracy: 0.9048\n",
            "Epoch 404/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1459 - accuracy: 0.9825 - val_loss: 0.2368 - val_accuracy: 0.8571\n",
            "Epoch 405/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1497 - accuracy: 0.9737 - val_loss: 0.2340 - val_accuracy: 0.9048\n",
            "Epoch 406/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1408 - accuracy: 0.9825 - val_loss: 0.2367 - val_accuracy: 0.9048\n",
            "Epoch 407/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1497 - accuracy: 0.9825 - val_loss: 0.2336 - val_accuracy: 0.9048\n",
            "Epoch 408/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1312 - accuracy: 0.9912 - val_loss: 0.2575 - val_accuracy: 0.9048\n",
            "Epoch 409/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1355 - accuracy: 0.9825 - val_loss: 0.2502 - val_accuracy: 0.9048\n",
            "Epoch 410/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1546 - accuracy: 0.9737 - val_loss: 0.2327 - val_accuracy: 0.8571\n",
            "Epoch 411/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1360 - accuracy: 0.9825 - val_loss: 0.2330 - val_accuracy: 0.9048\n",
            "Epoch 412/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1419 - accuracy: 0.9912 - val_loss: 0.2316 - val_accuracy: 0.9048\n",
            "Epoch 413/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1285 - accuracy: 0.9912 - val_loss: 0.2337 - val_accuracy: 0.9048\n",
            "Epoch 414/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1399 - accuracy: 0.9912 - val_loss: 0.2328 - val_accuracy: 0.9048\n",
            "Epoch 415/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1409 - accuracy: 0.9825 - val_loss: 0.2320 - val_accuracy: 0.9048\n",
            "Epoch 416/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1288 - accuracy: 0.9912 - val_loss: 0.2327 - val_accuracy: 0.9048\n",
            "Epoch 417/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1359 - accuracy: 0.9825 - val_loss: 0.2335 - val_accuracy: 0.9048\n",
            "Epoch 418/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.9912 - val_loss: 0.2405 - val_accuracy: 0.9048\n",
            "Epoch 419/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1536 - accuracy: 0.9737 - val_loss: 0.2335 - val_accuracy: 0.9048\n",
            "Epoch 420/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1309 - accuracy: 0.9912 - val_loss: 0.2439 - val_accuracy: 0.9048\n",
            "Epoch 421/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1361 - accuracy: 0.9912 - val_loss: 0.2319 - val_accuracy: 0.9048\n",
            "Epoch 422/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1461 - accuracy: 0.9737 - val_loss: 0.2348 - val_accuracy: 0.9048\n",
            "Epoch 423/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1252 - accuracy: 0.9912 - val_loss: 0.2318 - val_accuracy: 0.9048\n",
            "Epoch 424/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1345 - accuracy: 0.9825 - val_loss: 0.2320 - val_accuracy: 0.9048\n",
            "Epoch 425/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1370 - accuracy: 0.9912 - val_loss: 0.2321 - val_accuracy: 0.9048\n",
            "Epoch 426/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1276 - accuracy: 0.9912 - val_loss: 0.2350 - val_accuracy: 0.9048\n",
            "Epoch 427/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1246 - accuracy: 0.9912 - val_loss: 0.2329 - val_accuracy: 0.9048\n",
            "Epoch 428/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1379 - accuracy: 0.9912 - val_loss: 0.2358 - val_accuracy: 0.9048\n",
            "Epoch 429/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1561 - accuracy: 0.9825 - val_loss: 0.2329 - val_accuracy: 0.9048\n",
            "Epoch 430/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1277 - accuracy: 0.9912 - val_loss: 0.2499 - val_accuracy: 0.9048\n",
            "Epoch 431/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1383 - accuracy: 0.9912 - val_loss: 0.2456 - val_accuracy: 0.9048\n",
            "Epoch 432/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1297 - accuracy: 0.9825 - val_loss: 0.2319 - val_accuracy: 0.9048\n",
            "Epoch 433/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1551 - accuracy: 0.9649 - val_loss: 0.2323 - val_accuracy: 0.8571\n",
            "Epoch 434/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1322 - accuracy: 0.9912 - val_loss: 0.2344 - val_accuracy: 0.9048\n",
            "Epoch 435/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1519 - accuracy: 0.9737 - val_loss: 0.2411 - val_accuracy: 0.9048\n",
            "Epoch 436/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1382 - accuracy: 0.9912 - val_loss: 0.2398 - val_accuracy: 0.9048\n",
            "Epoch 437/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1402 - accuracy: 0.9825 - val_loss: 0.2341 - val_accuracy: 0.9048\n",
            "Epoch 438/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.9912 - val_loss: 0.2398 - val_accuracy: 0.8571\n",
            "Epoch 439/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9912 - val_loss: 0.2384 - val_accuracy: 0.8571\n",
            "Epoch 440/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1323 - accuracy: 0.9912 - val_loss: 0.2339 - val_accuracy: 0.9048\n",
            "Epoch 441/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1265 - accuracy: 0.9912 - val_loss: 0.2356 - val_accuracy: 0.9048\n",
            "Epoch 442/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1415 - accuracy: 0.9912 - val_loss: 0.2397 - val_accuracy: 0.8571\n",
            "Epoch 443/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.9912 - val_loss: 0.2341 - val_accuracy: 0.9048\n",
            "Epoch 444/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1368 - accuracy: 0.9825 - val_loss: 0.2339 - val_accuracy: 0.9048\n",
            "Epoch 445/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1309 - accuracy: 0.9912 - val_loss: 0.2375 - val_accuracy: 0.8571\n",
            "Epoch 446/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1517 - accuracy: 0.9825 - val_loss: 0.2343 - val_accuracy: 0.9048\n",
            "Epoch 447/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1269 - accuracy: 0.9912 - val_loss: 0.2361 - val_accuracy: 0.9048\n",
            "Epoch 448/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1347 - accuracy: 0.9912 - val_loss: 0.2359 - val_accuracy: 0.9048\n",
            "Epoch 449/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1407 - accuracy: 0.9825 - val_loss: 0.2338 - val_accuracy: 0.9048\n",
            "Epoch 450/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1410 - accuracy: 0.9825 - val_loss: 0.2332 - val_accuracy: 0.8571\n",
            "Epoch 451/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1362 - accuracy: 0.9825 - val_loss: 0.2332 - val_accuracy: 0.9048\n",
            "Epoch 452/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1299 - accuracy: 0.9912 - val_loss: 0.2416 - val_accuracy: 0.9048\n",
            "Epoch 453/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1261 - accuracy: 0.9912 - val_loss: 0.2326 - val_accuracy: 0.8571\n",
            "Epoch 454/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1272 - accuracy: 0.9825 - val_loss: 0.2348 - val_accuracy: 0.9048\n",
            "Epoch 455/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1396 - accuracy: 0.9912 - val_loss: 0.2339 - val_accuracy: 0.9048\n",
            "Epoch 456/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.9912 - val_loss: 0.2364 - val_accuracy: 0.8571\n",
            "Epoch 457/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9912 - val_loss: 0.2469 - val_accuracy: 0.9048\n",
            "Epoch 458/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1243 - accuracy: 0.9825 - val_loss: 0.2338 - val_accuracy: 0.8571\n",
            "Epoch 459/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1311 - accuracy: 0.9825 - val_loss: 0.2338 - val_accuracy: 0.8571\n",
            "Epoch 460/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.9825 - val_loss: 0.2358 - val_accuracy: 0.9048\n",
            "Epoch 461/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1339 - accuracy: 0.9912 - val_loss: 0.2349 - val_accuracy: 0.9048\n",
            "Epoch 462/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1369 - accuracy: 0.9825 - val_loss: 0.2419 - val_accuracy: 0.8571\n",
            "Epoch 463/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1417 - accuracy: 0.9737 - val_loss: 0.2360 - val_accuracy: 0.9048\n",
            "Epoch 464/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1330 - accuracy: 0.9825 - val_loss: 0.2428 - val_accuracy: 0.8571\n",
            "Epoch 465/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1387 - accuracy: 0.9737 - val_loss: 0.2353 - val_accuracy: 0.9048\n",
            "Epoch 466/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1245 - accuracy: 0.9912 - val_loss: 0.2356 - val_accuracy: 0.9048\n",
            "Epoch 467/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1397 - accuracy: 0.9825 - val_loss: 0.2384 - val_accuracy: 0.8571\n",
            "Epoch 468/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1380 - accuracy: 0.9912 - val_loss: 0.2363 - val_accuracy: 0.8571\n",
            "Epoch 469/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.9912 - val_loss: 0.2437 - val_accuracy: 0.9048\n",
            "Epoch 470/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1338 - accuracy: 0.9912 - val_loss: 0.2366 - val_accuracy: 0.8571\n",
            "Epoch 471/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1296 - accuracy: 0.9912 - val_loss: 0.2401 - val_accuracy: 0.8571\n",
            "Epoch 472/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1286 - accuracy: 0.9825 - val_loss: 0.2342 - val_accuracy: 0.8571\n",
            "Epoch 473/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1310 - accuracy: 0.9825 - val_loss: 0.2361 - val_accuracy: 0.8571\n",
            "Epoch 474/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1293 - accuracy: 0.9912 - val_loss: 0.2467 - val_accuracy: 0.9048\n",
            "Epoch 475/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1304 - accuracy: 0.9912 - val_loss: 0.2360 - val_accuracy: 0.8571\n",
            "Epoch 476/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1212 - accuracy: 0.9912 - val_loss: 0.2360 - val_accuracy: 0.8571\n",
            "Epoch 477/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1386 - accuracy: 0.9825 - val_loss: 0.2340 - val_accuracy: 0.9048\n",
            "Epoch 478/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.9825 - val_loss: 0.2334 - val_accuracy: 0.8571\n",
            "Epoch 479/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1261 - accuracy: 0.9912 - val_loss: 0.2338 - val_accuracy: 0.8571\n",
            "Epoch 480/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1186 - accuracy: 0.9912 - val_loss: 0.2427 - val_accuracy: 0.9048\n",
            "Epoch 481/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1291 - accuracy: 0.9912 - val_loss: 0.2379 - val_accuracy: 0.8571\n",
            "Epoch 482/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 0.9912 - val_loss: 0.2424 - val_accuracy: 0.8571\n",
            "Epoch 483/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1182 - accuracy: 0.9912 - val_loss: 0.2364 - val_accuracy: 0.9048\n",
            "Epoch 484/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1290 - accuracy: 0.9912 - val_loss: 0.2349 - val_accuracy: 0.9048\n",
            "Epoch 485/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1209 - accuracy: 0.9825 - val_loss: 0.2328 - val_accuracy: 0.8571\n",
            "Epoch 486/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1288 - accuracy: 0.9912 - val_loss: 0.2348 - val_accuracy: 0.9048\n",
            "Epoch 487/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9912 - val_loss: 0.2509 - val_accuracy: 0.9048\n",
            "Epoch 488/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1260 - accuracy: 0.9912 - val_loss: 0.2355 - val_accuracy: 0.9048\n",
            "Epoch 489/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.9825 - val_loss: 0.2333 - val_accuracy: 0.8571\n",
            "Epoch 490/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1375 - accuracy: 0.9825 - val_loss: 0.2613 - val_accuracy: 0.9048\n",
            "Epoch 491/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1449 - accuracy: 0.9737 - val_loss: 0.2541 - val_accuracy: 0.9048\n",
            "Epoch 492/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1230 - accuracy: 0.9912 - val_loss: 0.2370 - val_accuracy: 0.8571\n",
            "Epoch 493/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1248 - accuracy: 0.9825 - val_loss: 0.2357 - val_accuracy: 0.9048\n",
            "Epoch 494/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1232 - accuracy: 0.9825 - val_loss: 0.2328 - val_accuracy: 0.8571\n",
            "Epoch 495/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1378 - accuracy: 0.9912 - val_loss: 0.2347 - val_accuracy: 0.9048\n",
            "Epoch 496/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1217 - accuracy: 0.9912 - val_loss: 0.2338 - val_accuracy: 0.9048\n",
            "Epoch 497/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1290 - accuracy: 0.9825 - val_loss: 0.2370 - val_accuracy: 0.8571\n",
            "Epoch 498/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.9912 - val_loss: 0.2394 - val_accuracy: 0.8571\n",
            "Epoch 499/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.9912 - val_loss: 0.2376 - val_accuracy: 0.8571\n",
            "Epoch 500/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1231 - accuracy: 0.9912 - val_loss: 0.2359 - val_accuracy: 0.8571\n",
            "Epoch 501/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1250 - accuracy: 0.9825 - val_loss: 0.2331 - val_accuracy: 0.8571\n",
            "Epoch 502/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1300 - accuracy: 0.9825 - val_loss: 0.2337 - val_accuracy: 0.8571\n",
            "Epoch 503/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.9912 - val_loss: 0.2352 - val_accuracy: 0.9048\n",
            "Epoch 504/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 0.9912 - val_loss: 0.2357 - val_accuracy: 0.8571\n",
            "Epoch 505/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.9825 - val_loss: 0.2368 - val_accuracy: 0.8571\n",
            "Epoch 506/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1273 - accuracy: 0.9825 - val_loss: 0.2344 - val_accuracy: 0.9048\n",
            "Epoch 507/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 0.9912 - val_loss: 0.2365 - val_accuracy: 0.8571\n",
            "Epoch 508/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1380 - accuracy: 0.9737 - val_loss: 0.2443 - val_accuracy: 0.9048\n",
            "Epoch 509/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1335 - accuracy: 0.9825 - val_loss: 0.2345 - val_accuracy: 0.9048\n",
            "Epoch 510/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1165 - accuracy: 0.9912 - val_loss: 0.2377 - val_accuracy: 0.8571\n",
            "Epoch 511/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1134 - accuracy: 0.9912 - val_loss: 0.2388 - val_accuracy: 0.8571\n",
            "Epoch 512/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1381 - accuracy: 0.9825 - val_loss: 0.2345 - val_accuracy: 0.8571\n",
            "Epoch 513/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1294 - accuracy: 0.9912 - val_loss: 0.2458 - val_accuracy: 0.9048\n",
            "Epoch 514/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.9912 - val_loss: 0.2461 - val_accuracy: 0.9048\n",
            "Epoch 515/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.9912 - val_loss: 0.2365 - val_accuracy: 0.9048\n",
            "Epoch 516/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1270 - accuracy: 0.9912 - val_loss: 0.2365 - val_accuracy: 0.9048\n",
            "Epoch 517/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1074 - accuracy: 0.9912 - val_loss: 0.2365 - val_accuracy: 0.8571\n",
            "Epoch 518/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1194 - accuracy: 0.9912 - val_loss: 0.2385 - val_accuracy: 0.8571\n",
            "Epoch 519/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.9912 - val_loss: 0.2343 - val_accuracy: 0.8571\n",
            "Epoch 520/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1314 - accuracy: 0.9912 - val_loss: 0.2387 - val_accuracy: 0.8571\n",
            "Epoch 521/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1157 - accuracy: 0.9912 - val_loss: 0.2411 - val_accuracy: 0.8571\n",
            "Epoch 522/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1253 - accuracy: 0.9912 - val_loss: 0.2504 - val_accuracy: 0.9048\n",
            "Epoch 523/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1330 - accuracy: 0.9825 - val_loss: 0.2391 - val_accuracy: 0.8571\n",
            "Epoch 524/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1368 - accuracy: 0.9825 - val_loss: 0.2350 - val_accuracy: 0.8571\n",
            "Epoch 525/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1215 - accuracy: 0.9912 - val_loss: 0.2440 - val_accuracy: 0.8571\n",
            "Epoch 526/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1294 - accuracy: 0.9912 - val_loss: 0.2388 - val_accuracy: 0.8571\n",
            "Epoch 527/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1222 - accuracy: 0.9912 - val_loss: 0.2358 - val_accuracy: 0.9048\n",
            "Epoch 528/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1314 - accuracy: 0.9825 - val_loss: 0.2360 - val_accuracy: 0.8571\n",
            "Epoch 529/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1254 - accuracy: 0.9912 - val_loss: 0.2364 - val_accuracy: 0.8571\n",
            "Epoch 530/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1231 - accuracy: 0.9825 - val_loss: 0.2459 - val_accuracy: 0.9048\n",
            "Epoch 531/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1255 - accuracy: 0.9825 - val_loss: 0.2469 - val_accuracy: 0.9048\n",
            "Epoch 532/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9912 - val_loss: 0.2433 - val_accuracy: 0.8571\n",
            "Epoch 533/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1324 - accuracy: 0.9825 - val_loss: 0.2362 - val_accuracy: 0.9048\n",
            "Epoch 534/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1203 - accuracy: 0.9825 - val_loss: 0.2422 - val_accuracy: 0.8571\n",
            "Epoch 535/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.9912 - val_loss: 0.2348 - val_accuracy: 0.8571\n",
            "Epoch 536/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1276 - accuracy: 0.9825 - val_loss: 0.2365 - val_accuracy: 0.9048\n",
            "Epoch 537/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1259 - accuracy: 0.9912 - val_loss: 0.2454 - val_accuracy: 0.9048\n",
            "Epoch 538/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1352 - accuracy: 0.9737 - val_loss: 0.2434 - val_accuracy: 0.8571\n",
            "Epoch 539/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1272 - accuracy: 0.9912 - val_loss: 0.2521 - val_accuracy: 0.9048\n",
            "Epoch 540/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1367 - accuracy: 0.9912 - val_loss: 0.2350 - val_accuracy: 0.9048\n",
            "Epoch 541/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1256 - accuracy: 0.9912 - val_loss: 0.2526 - val_accuracy: 0.9048\n",
            "Epoch 542/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1345 - accuracy: 0.9737 - val_loss: 0.2346 - val_accuracy: 0.8571\n",
            "Epoch 543/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1310 - accuracy: 0.9825 - val_loss: 0.2443 - val_accuracy: 0.8571\n",
            "Epoch 544/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.9912 - val_loss: 0.2380 - val_accuracy: 0.8571\n",
            "Epoch 545/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1358 - accuracy: 0.9737 - val_loss: 0.2350 - val_accuracy: 0.8571\n",
            "Epoch 546/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1363 - accuracy: 0.9737 - val_loss: 0.2528 - val_accuracy: 0.9048\n",
            "Epoch 547/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.9912 - val_loss: 0.2390 - val_accuracy: 0.8571\n",
            "Epoch 548/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1295 - accuracy: 0.9912 - val_loss: 0.2407 - val_accuracy: 0.8571\n",
            "Epoch 549/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1202 - accuracy: 0.9825 - val_loss: 0.2443 - val_accuracy: 0.8571\n",
            "Epoch 550/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1187 - accuracy: 0.9912 - val_loss: 0.2508 - val_accuracy: 0.9048\n",
            "Epoch 551/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.9912 - val_loss: 0.2419 - val_accuracy: 0.8571\n",
            "Epoch 552/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1130 - accuracy: 0.9912 - val_loss: 0.2393 - val_accuracy: 0.8571\n",
            "Epoch 553/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1341 - accuracy: 0.9912 - val_loss: 0.2351 - val_accuracy: 0.8571\n",
            "Epoch 554/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.9912 - val_loss: 0.2396 - val_accuracy: 0.8571\n",
            "Epoch 555/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1202 - accuracy: 0.9912 - val_loss: 0.2437 - val_accuracy: 0.8571\n",
            "Epoch 556/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1128 - accuracy: 0.9912 - val_loss: 0.2504 - val_accuracy: 0.9048\n",
            "Epoch 557/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1336 - accuracy: 0.9825 - val_loss: 0.2510 - val_accuracy: 0.9048\n",
            "Epoch 558/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1226 - accuracy: 0.9912 - val_loss: 0.2469 - val_accuracy: 0.9048\n",
            "Epoch 559/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1334 - accuracy: 0.9825 - val_loss: 0.2396 - val_accuracy: 0.8571\n",
            "Epoch 560/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1226 - accuracy: 0.9912 - val_loss: 0.2429 - val_accuracy: 0.8571\n",
            "Epoch 561/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9912 - val_loss: 0.2411 - val_accuracy: 0.8571\n",
            "Epoch 562/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.9912 - val_loss: 0.2418 - val_accuracy: 0.8571\n",
            "Epoch 563/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1048 - accuracy: 0.9912 - val_loss: 0.2348 - val_accuracy: 0.8571\n",
            "Epoch 564/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1359 - accuracy: 0.9825 - val_loss: 0.2348 - val_accuracy: 0.8571\n",
            "Epoch 565/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1207 - accuracy: 0.9912 - val_loss: 0.2404 - val_accuracy: 0.8571\n",
            "Epoch 566/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.9825 - val_loss: 0.2454 - val_accuracy: 0.9048\n",
            "Epoch 567/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9912 - val_loss: 0.2466 - val_accuracy: 0.9048\n",
            "Epoch 568/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1274 - accuracy: 0.9912 - val_loss: 0.2538 - val_accuracy: 0.9048\n",
            "Epoch 569/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1176 - accuracy: 0.9912 - val_loss: 0.2408 - val_accuracy: 0.8571\n",
            "Epoch 570/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1248 - accuracy: 0.9912 - val_loss: 0.2365 - val_accuracy: 0.8571\n",
            "Epoch 571/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1276 - accuracy: 0.9825 - val_loss: 0.2377 - val_accuracy: 0.8571\n",
            "Epoch 572/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1119 - accuracy: 0.9912 - val_loss: 0.2585 - val_accuracy: 0.9048\n",
            "Epoch 573/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1243 - accuracy: 0.9912 - val_loss: 0.2464 - val_accuracy: 0.9048\n",
            "Epoch 574/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1158 - accuracy: 0.9912 - val_loss: 0.2530 - val_accuracy: 0.9048\n",
            "Epoch 575/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1204 - accuracy: 0.9825 - val_loss: 0.2396 - val_accuracy: 0.8571\n",
            "Epoch 576/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1210 - accuracy: 0.9825 - val_loss: 0.2517 - val_accuracy: 0.9048\n",
            "Epoch 577/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1176 - accuracy: 0.9825 - val_loss: 0.2658 - val_accuracy: 0.9048\n",
            "Epoch 578/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1353 - accuracy: 0.9737 - val_loss: 0.2350 - val_accuracy: 0.8571\n",
            "Epoch 579/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9825 - val_loss: 0.2521 - val_accuracy: 0.9048\n",
            "Epoch 580/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1155 - accuracy: 0.9825 - val_loss: 0.2381 - val_accuracy: 0.8571\n",
            "Epoch 581/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1250 - accuracy: 0.9825 - val_loss: 0.2838 - val_accuracy: 0.9048\n",
            "Epoch 582/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1232 - accuracy: 0.9825 - val_loss: 0.2453 - val_accuracy: 0.8571\n",
            "Epoch 583/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1227 - accuracy: 0.9912 - val_loss: 0.2364 - val_accuracy: 0.8571\n",
            "Epoch 584/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1270 - accuracy: 0.9912 - val_loss: 0.2450 - val_accuracy: 0.8571\n",
            "Epoch 585/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1206 - accuracy: 0.9825 - val_loss: 0.2449 - val_accuracy: 0.8571\n",
            "Epoch 586/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.9912 - val_loss: 0.2384 - val_accuracy: 0.8571\n",
            "Epoch 587/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.9912 - val_loss: 0.2379 - val_accuracy: 0.8571\n",
            "Epoch 588/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1240 - accuracy: 0.9825 - val_loss: 0.2429 - val_accuracy: 0.8571\n",
            "Epoch 589/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1214 - accuracy: 0.9912 - val_loss: 0.2501 - val_accuracy: 0.9048\n",
            "Epoch 590/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9912 - val_loss: 0.2516 - val_accuracy: 0.9048\n",
            "Epoch 591/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1225 - accuracy: 0.9912 - val_loss: 0.2417 - val_accuracy: 0.8571\n",
            "Epoch 592/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.9912 - val_loss: 0.2417 - val_accuracy: 0.8571\n",
            "Epoch 593/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1162 - accuracy: 0.9912 - val_loss: 0.2423 - val_accuracy: 0.8571\n",
            "Epoch 594/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.9912 - val_loss: 0.2396 - val_accuracy: 0.8095\n",
            "Epoch 595/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1204 - accuracy: 0.9912 - val_loss: 0.2677 - val_accuracy: 0.9048\n",
            "Epoch 596/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.9825 - val_loss: 0.2504 - val_accuracy: 0.9048\n",
            "Epoch 597/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1206 - accuracy: 0.9825 - val_loss: 0.2375 - val_accuracy: 0.8571\n",
            "Epoch 598/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1181 - accuracy: 0.9825 - val_loss: 0.2704 - val_accuracy: 0.9048\n",
            "Epoch 599/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1181 - accuracy: 0.9912 - val_loss: 0.2522 - val_accuracy: 0.9048\n",
            "Epoch 600/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 0.9825 - val_loss: 0.2510 - val_accuracy: 0.9048\n",
            "Epoch 601/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1112 - accuracy: 0.9825 - val_loss: 0.2387 - val_accuracy: 0.8571\n",
            "Epoch 602/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.9912 - val_loss: 0.2445 - val_accuracy: 0.8571\n",
            "Epoch 603/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.9912 - val_loss: 0.2462 - val_accuracy: 0.8571\n",
            "Epoch 604/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1256 - accuracy: 0.9825 - val_loss: 0.2396 - val_accuracy: 0.8571\n",
            "Epoch 605/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1249 - accuracy: 0.9912 - val_loss: 0.2614 - val_accuracy: 0.9048\n",
            "Epoch 606/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.9912 - val_loss: 0.2400 - val_accuracy: 0.8095\n",
            "Epoch 607/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1255 - accuracy: 0.9912 - val_loss: 0.2400 - val_accuracy: 0.8095\n",
            "Epoch 608/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1076 - accuracy: 0.9912 - val_loss: 0.2413 - val_accuracy: 0.8571\n",
            "Epoch 609/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.9825 - val_loss: 0.2517 - val_accuracy: 0.9048\n",
            "Epoch 610/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1167 - accuracy: 0.9912 - val_loss: 0.2592 - val_accuracy: 0.9048\n",
            "Epoch 611/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1197 - accuracy: 0.9825 - val_loss: 0.2522 - val_accuracy: 0.9048\n",
            "Epoch 612/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1254 - accuracy: 0.9912 - val_loss: 0.2523 - val_accuracy: 0.9048\n",
            "Epoch 613/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1155 - accuracy: 0.9912 - val_loss: 0.2381 - val_accuracy: 0.8571\n",
            "Epoch 614/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1223 - accuracy: 0.9912 - val_loss: 0.2373 - val_accuracy: 0.8571\n",
            "Epoch 615/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.9825 - val_loss: 0.2899 - val_accuracy: 0.9048\n",
            "Epoch 616/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.9825 - val_loss: 0.2764 - val_accuracy: 0.9048\n",
            "Epoch 617/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 0.9825 - val_loss: 0.2459 - val_accuracy: 0.8571\n",
            "Epoch 618/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1205 - accuracy: 0.9912 - val_loss: 0.2372 - val_accuracy: 0.8571\n",
            "Epoch 619/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.9912 - val_loss: 0.2379 - val_accuracy: 0.8571\n",
            "Epoch 620/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1254 - accuracy: 0.9912 - val_loss: 0.2394 - val_accuracy: 0.8095\n",
            "Epoch 621/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.9825 - val_loss: 0.2504 - val_accuracy: 0.9048\n",
            "Epoch 622/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1179 - accuracy: 0.9912 - val_loss: 0.2417 - val_accuracy: 0.8571\n",
            "Epoch 623/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1138 - accuracy: 0.9912 - val_loss: 0.2580 - val_accuracy: 0.9048\n",
            "Epoch 624/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1260 - accuracy: 0.9825 - val_loss: 0.2378 - val_accuracy: 0.8571\n",
            "Epoch 625/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.9825 - val_loss: 0.2446 - val_accuracy: 0.8571\n",
            "Epoch 626/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1218 - accuracy: 0.9825 - val_loss: 0.2491 - val_accuracy: 0.9048\n",
            "Epoch 627/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1107 - accuracy: 0.9912 - val_loss: 0.2519 - val_accuracy: 0.9048\n",
            "Epoch 628/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1133 - accuracy: 0.9912 - val_loss: 0.2406 - val_accuracy: 0.8095\n",
            "Epoch 629/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1331 - accuracy: 0.9825 - val_loss: 0.2388 - val_accuracy: 0.8571\n",
            "Epoch 630/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1125 - accuracy: 0.9825 - val_loss: 0.2448 - val_accuracy: 0.8571\n",
            "Epoch 631/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1262 - accuracy: 0.9912 - val_loss: 0.2450 - val_accuracy: 0.8571\n",
            "Epoch 632/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1259 - accuracy: 0.9825 - val_loss: 0.2510 - val_accuracy: 0.9048\n",
            "Epoch 633/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9912 - val_loss: 0.2575 - val_accuracy: 0.9048\n",
            "Epoch 634/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 0.9912 - val_loss: 0.2461 - val_accuracy: 0.8571\n",
            "Epoch 635/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1097 - accuracy: 0.9912 - val_loss: 0.2386 - val_accuracy: 0.8571\n",
            "Epoch 636/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1256 - accuracy: 0.9912 - val_loss: 0.2493 - val_accuracy: 0.8571\n",
            "Epoch 637/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1228 - accuracy: 0.9912 - val_loss: 0.2603 - val_accuracy: 0.9048\n",
            "Epoch 638/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1123 - accuracy: 0.9912 - val_loss: 0.2513 - val_accuracy: 0.9048\n",
            "Epoch 639/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.9912 - val_loss: 0.2464 - val_accuracy: 0.8571\n",
            "Epoch 640/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.9912 - val_loss: 0.2526 - val_accuracy: 0.9048\n",
            "Epoch 641/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1149 - accuracy: 0.9825 - val_loss: 0.2444 - val_accuracy: 0.8571\n",
            "Epoch 642/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1138 - accuracy: 0.9912 - val_loss: 0.2389 - val_accuracy: 0.8571\n",
            "Epoch 643/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1118 - accuracy: 0.9825 - val_loss: 0.2381 - val_accuracy: 0.8571\n",
            "Epoch 644/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 0.9912 - val_loss: 0.2512 - val_accuracy: 0.9048\n",
            "Epoch 645/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.9912 - val_loss: 0.2659 - val_accuracy: 0.9048\n",
            "Epoch 646/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9825 - val_loss: 0.2727 - val_accuracy: 0.9048\n",
            "Epoch 647/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1112 - accuracy: 0.9825 - val_loss: 0.2495 - val_accuracy: 0.8571\n",
            "Epoch 648/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9912 - val_loss: 0.2519 - val_accuracy: 0.9048\n",
            "Epoch 649/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1055 - accuracy: 0.9912 - val_loss: 0.2538 - val_accuracy: 0.9048\n",
            "Epoch 650/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1214 - accuracy: 0.9737 - val_loss: 0.2425 - val_accuracy: 0.8095\n",
            "Epoch 651/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.9912 - val_loss: 0.2438 - val_accuracy: 0.8571\n",
            "Epoch 652/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9912 - val_loss: 0.2418 - val_accuracy: 0.8571\n",
            "Epoch 653/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1130 - accuracy: 0.9912 - val_loss: 0.2398 - val_accuracy: 0.8095\n",
            "Epoch 654/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1090 - accuracy: 0.9825 - val_loss: 0.2436 - val_accuracy: 0.8571\n",
            "Epoch 655/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1121 - accuracy: 0.9912 - val_loss: 0.2407 - val_accuracy: 0.8095\n",
            "Epoch 656/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.9825 - val_loss: 0.2493 - val_accuracy: 0.8571\n",
            "Epoch 657/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.9912 - val_loss: 0.2467 - val_accuracy: 0.8571\n",
            "Epoch 658/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1097 - accuracy: 0.9912 - val_loss: 0.2578 - val_accuracy: 0.9048\n",
            "Epoch 659/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.9912 - val_loss: 0.2507 - val_accuracy: 0.8571\n",
            "Epoch 660/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1206 - accuracy: 0.9912 - val_loss: 0.2585 - val_accuracy: 0.9048\n",
            "Epoch 661/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1138 - accuracy: 0.9825 - val_loss: 0.2920 - val_accuracy: 0.9048\n",
            "Epoch 662/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1269 - accuracy: 0.9825 - val_loss: 0.2553 - val_accuracy: 0.9048\n",
            "Epoch 663/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9912 - val_loss: 0.2563 - val_accuracy: 0.9048\n",
            "Epoch 664/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1280 - accuracy: 0.9912 - val_loss: 0.2503 - val_accuracy: 0.9048\n",
            "Epoch 665/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9912 - val_loss: 0.2420 - val_accuracy: 0.8571\n",
            "Epoch 666/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1101 - accuracy: 0.9912 - val_loss: 0.2468 - val_accuracy: 0.8571\n",
            "Epoch 667/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9912 - val_loss: 0.2420 - val_accuracy: 0.8095\n",
            "Epoch 668/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.9912 - val_loss: 0.2408 - val_accuracy: 0.8095\n",
            "Epoch 669/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9912 - val_loss: 0.2482 - val_accuracy: 0.8571\n",
            "Epoch 670/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1045 - accuracy: 0.9912 - val_loss: 0.2548 - val_accuracy: 0.9048\n",
            "Epoch 671/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1134 - accuracy: 0.9912 - val_loss: 0.2556 - val_accuracy: 0.9048\n",
            "Epoch 672/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9912 - val_loss: 0.2496 - val_accuracy: 0.8571\n",
            "Epoch 673/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1212 - accuracy: 0.9825 - val_loss: 0.2401 - val_accuracy: 0.8571\n",
            "Epoch 674/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1211 - accuracy: 0.9825 - val_loss: 0.2465 - val_accuracy: 0.8571\n",
            "Epoch 675/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.9912 - val_loss: 0.2575 - val_accuracy: 0.9048\n",
            "Epoch 676/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1080 - accuracy: 0.9912 - val_loss: 0.2584 - val_accuracy: 0.9048\n",
            "Epoch 677/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1075 - accuracy: 0.9912 - val_loss: 0.2623 - val_accuracy: 0.9048\n",
            "Epoch 678/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1100 - accuracy: 0.9912 - val_loss: 0.2554 - val_accuracy: 0.9048\n",
            "Epoch 679/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1132 - accuracy: 0.9825 - val_loss: 0.2505 - val_accuracy: 0.8571\n",
            "Epoch 680/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.9825 - val_loss: 0.2479 - val_accuracy: 0.8571\n",
            "Epoch 681/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1104 - accuracy: 0.9912 - val_loss: 0.2702 - val_accuracy: 0.9048\n",
            "Epoch 682/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.9912 - val_loss: 0.2545 - val_accuracy: 0.9048\n",
            "Epoch 683/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1090 - accuracy: 0.9825 - val_loss: 0.2475 - val_accuracy: 0.8571\n",
            "Epoch 684/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1036 - accuracy: 0.9912 - val_loss: 0.2902 - val_accuracy: 0.9048\n",
            "Epoch 685/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9912 - val_loss: 0.2769 - val_accuracy: 0.9048\n",
            "Epoch 686/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1052 - accuracy: 0.9912 - val_loss: 0.2597 - val_accuracy: 0.9048\n",
            "Epoch 687/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.9825 - val_loss: 0.2477 - val_accuracy: 0.8571\n",
            "Epoch 688/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1133 - accuracy: 0.9912 - val_loss: 0.2469 - val_accuracy: 0.8095\n",
            "Epoch 689/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.9912 - val_loss: 0.2460 - val_accuracy: 0.8095\n",
            "Epoch 690/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.9912 - val_loss: 0.2516 - val_accuracy: 0.8571\n",
            "Epoch 691/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.9912 - val_loss: 0.2534 - val_accuracy: 0.9048\n",
            "Epoch 692/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.9825 - val_loss: 0.2461 - val_accuracy: 0.8571\n",
            "Epoch 693/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1003 - accuracy: 0.9912 - val_loss: 0.2503 - val_accuracy: 0.8571\n",
            "Epoch 694/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1063 - accuracy: 0.9912 - val_loss: 0.2559 - val_accuracy: 0.9048\n",
            "Epoch 695/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.9912 - val_loss: 0.2508 - val_accuracy: 0.8571\n",
            "Epoch 696/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1175 - accuracy: 0.9825 - val_loss: 0.2451 - val_accuracy: 0.8095\n",
            "Epoch 697/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9825 - val_loss: 0.2458 - val_accuracy: 0.8571\n",
            "Epoch 698/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1210 - accuracy: 0.9912 - val_loss: 0.2511 - val_accuracy: 0.8571\n",
            "Epoch 699/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1103 - accuracy: 0.9912 - val_loss: 0.2491 - val_accuracy: 0.8571\n",
            "Epoch 700/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1221 - accuracy: 0.9825 - val_loss: 0.2591 - val_accuracy: 0.9048\n",
            "Epoch 701/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.9825 - val_loss: 0.2637 - val_accuracy: 0.9048\n",
            "Epoch 702/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.9912 - val_loss: 0.2701 - val_accuracy: 0.9048\n",
            "Epoch 703/800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9912 - val_loss: 0.2527 - val_accuracy: 0.8571\n",
            "Epoch 704/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1140 - accuracy: 0.9912 - val_loss: 0.2419 - val_accuracy: 0.8095\n",
            "Epoch 705/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1162 - accuracy: 0.9825 - val_loss: 0.2499 - val_accuracy: 0.8571\n",
            "Epoch 706/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1117 - accuracy: 0.9912 - val_loss: 0.2550 - val_accuracy: 0.9048\n",
            "Epoch 707/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.9912 - val_loss: 0.2527 - val_accuracy: 0.8571\n",
            "Epoch 708/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.9912 - val_loss: 0.2513 - val_accuracy: 0.8571\n",
            "Epoch 709/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.9912 - val_loss: 0.2477 - val_accuracy: 0.8095\n",
            "Epoch 710/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9649 - val_loss: 0.2557 - val_accuracy: 0.8571\n",
            "Epoch 711/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1164 - accuracy: 0.9912 - val_loss: 0.2706 - val_accuracy: 0.9048\n",
            "Epoch 712/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1216 - accuracy: 0.9737 - val_loss: 0.2601 - val_accuracy: 0.9048\n",
            "Epoch 713/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1148 - accuracy: 0.9912 - val_loss: 0.2448 - val_accuracy: 0.8095\n",
            "Epoch 714/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1065 - accuracy: 0.9912 - val_loss: 0.2545 - val_accuracy: 0.8571\n",
            "Epoch 715/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.9825 - val_loss: 0.2501 - val_accuracy: 0.8571\n",
            "Epoch 716/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.9912 - val_loss: 0.2538 - val_accuracy: 0.8571\n",
            "Epoch 717/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.9912 - val_loss: 0.2701 - val_accuracy: 0.9048\n",
            "Epoch 718/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1140 - accuracy: 0.9825 - val_loss: 0.2652 - val_accuracy: 0.9048\n",
            "Epoch 719/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1145 - accuracy: 0.9912 - val_loss: 0.2431 - val_accuracy: 0.8095\n",
            "Epoch 720/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1074 - accuracy: 0.9912 - val_loss: 0.2425 - val_accuracy: 0.8095\n",
            "Epoch 721/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1090 - accuracy: 0.9912 - val_loss: 0.2608 - val_accuracy: 0.9048\n",
            "Epoch 722/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.9825 - val_loss: 0.2484 - val_accuracy: 0.8571\n",
            "Epoch 723/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.9825 - val_loss: 0.2429 - val_accuracy: 0.8571\n",
            "Epoch 724/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1095 - accuracy: 0.9912 - val_loss: 0.2583 - val_accuracy: 0.9048\n",
            "Epoch 725/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9912 - val_loss: 0.2644 - val_accuracy: 0.9048\n",
            "Epoch 726/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1018 - accuracy: 0.9912 - val_loss: 0.2447 - val_accuracy: 0.8571\n",
            "Epoch 727/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.9912 - val_loss: 0.2502 - val_accuracy: 0.8095\n",
            "Epoch 728/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.9912 - val_loss: 0.2636 - val_accuracy: 0.9048\n",
            "Epoch 729/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1056 - accuracy: 0.9912 - val_loss: 0.2518 - val_accuracy: 0.8571\n",
            "Epoch 730/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1121 - accuracy: 0.9912 - val_loss: 0.2505 - val_accuracy: 0.8095\n",
            "Epoch 731/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1179 - accuracy: 0.9912 - val_loss: 0.2459 - val_accuracy: 0.8095\n",
            "Epoch 732/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1022 - accuracy: 0.9825 - val_loss: 0.2547 - val_accuracy: 0.8571\n",
            "Epoch 733/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1232 - accuracy: 0.9825 - val_loss: 0.2594 - val_accuracy: 0.9048\n",
            "Epoch 734/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.9912 - val_loss: 0.2544 - val_accuracy: 0.8571\n",
            "Epoch 735/800\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1070 - accuracy: 0.9912 - val_loss: 0.2843 - val_accuracy: 0.9048\n",
            "Epoch 736/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1106 - accuracy: 0.9912 - val_loss: 0.2731 - val_accuracy: 0.9048\n",
            "Epoch 737/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1134 - accuracy: 0.9912 - val_loss: 0.2447 - val_accuracy: 0.8571\n",
            "Epoch 738/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.9737 - val_loss: 0.2690 - val_accuracy: 0.9048\n",
            "Epoch 739/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0981 - accuracy: 0.9912 - val_loss: 0.2602 - val_accuracy: 0.9048\n",
            "Epoch 740/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1116 - accuracy: 0.9912 - val_loss: 0.2541 - val_accuracy: 0.8571\n",
            "Epoch 741/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1159 - accuracy: 0.9912 - val_loss: 0.2523 - val_accuracy: 0.8095\n",
            "Epoch 742/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.9825 - val_loss: 0.2478 - val_accuracy: 0.8095\n",
            "Epoch 743/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1083 - accuracy: 0.9825 - val_loss: 0.2548 - val_accuracy: 0.8571\n",
            "Epoch 744/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9912 - val_loss: 0.2506 - val_accuracy: 0.8095\n",
            "Epoch 745/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1178 - accuracy: 0.9912 - val_loss: 0.2616 - val_accuracy: 0.9048\n",
            "Epoch 746/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0979 - accuracy: 0.9912 - val_loss: 0.2463 - val_accuracy: 0.8571\n",
            "Epoch 747/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1184 - accuracy: 0.9825 - val_loss: 0.2534 - val_accuracy: 0.8571\n",
            "Epoch 748/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1198 - accuracy: 0.9912 - val_loss: 0.2587 - val_accuracy: 0.9048\n",
            "Epoch 749/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1037 - accuracy: 0.9912 - val_loss: 0.2611 - val_accuracy: 0.9048\n",
            "Epoch 750/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.9912 - val_loss: 0.2574 - val_accuracy: 0.9048\n",
            "Epoch 751/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.9912 - val_loss: 0.2500 - val_accuracy: 0.8095\n",
            "Epoch 752/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1082 - accuracy: 0.9912 - val_loss: 0.2512 - val_accuracy: 0.8095\n",
            "Epoch 753/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1235 - accuracy: 0.9825 - val_loss: 0.2590 - val_accuracy: 0.9048\n",
            "Epoch 754/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1225 - accuracy: 0.9737 - val_loss: 0.2838 - val_accuracy: 0.9048\n",
            "Epoch 755/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1132 - accuracy: 0.9912 - val_loss: 0.2952 - val_accuracy: 0.9048\n",
            "Epoch 756/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1041 - accuracy: 0.9912 - val_loss: 0.2596 - val_accuracy: 0.9048\n",
            "Epoch 757/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.9912 - val_loss: 0.2469 - val_accuracy: 0.8095\n",
            "Epoch 758/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1094 - accuracy: 0.9825 - val_loss: 0.2538 - val_accuracy: 0.8095\n",
            "Epoch 759/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1093 - accuracy: 0.9825 - val_loss: 0.2672 - val_accuracy: 0.9048\n",
            "Epoch 760/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0978 - accuracy: 0.9912 - val_loss: 0.2678 - val_accuracy: 0.9048\n",
            "Epoch 761/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.9912 - val_loss: 0.2588 - val_accuracy: 0.8571\n",
            "Epoch 762/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0977 - accuracy: 0.9912 - val_loss: 0.2460 - val_accuracy: 0.8571\n",
            "Epoch 763/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1177 - accuracy: 0.9825 - val_loss: 0.2456 - val_accuracy: 0.8571\n",
            "Epoch 764/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1004 - accuracy: 0.9912 - val_loss: 0.2461 - val_accuracy: 0.8095\n",
            "Epoch 765/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.9825 - val_loss: 0.2770 - val_accuracy: 0.9048\n",
            "Epoch 766/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1048 - accuracy: 0.9912 - val_loss: 0.2531 - val_accuracy: 0.8095\n",
            "Epoch 767/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.9825 - val_loss: 0.2447 - val_accuracy: 0.8571\n",
            "Epoch 768/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1217 - accuracy: 0.9825 - val_loss: 0.2499 - val_accuracy: 0.8095\n",
            "Epoch 769/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1008 - accuracy: 0.9825 - val_loss: 0.2531 - val_accuracy: 0.8571\n",
            "Epoch 770/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1028 - accuracy: 0.9912 - val_loss: 0.2477 - val_accuracy: 0.8095\n",
            "Epoch 771/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1126 - accuracy: 0.9912 - val_loss: 0.2555 - val_accuracy: 0.8571\n",
            "Epoch 772/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1076 - accuracy: 0.9825 - val_loss: 0.2590 - val_accuracy: 0.9048\n",
            "Epoch 773/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1097 - accuracy: 0.9912 - val_loss: 0.2492 - val_accuracy: 0.8095\n",
            "Epoch 774/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1054 - accuracy: 0.9912 - val_loss: 0.2620 - val_accuracy: 0.9048\n",
            "Epoch 775/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1059 - accuracy: 0.9912 - val_loss: 0.2598 - val_accuracy: 0.9048\n",
            "Epoch 776/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1144 - accuracy: 0.9912 - val_loss: 0.2487 - val_accuracy: 0.8095\n",
            "Epoch 777/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1050 - accuracy: 0.9912 - val_loss: 0.2802 - val_accuracy: 0.9048\n",
            "Epoch 778/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0958 - accuracy: 0.9912 - val_loss: 0.2548 - val_accuracy: 0.8095\n",
            "Epoch 779/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.9912 - val_loss: 0.2470 - val_accuracy: 0.8571\n",
            "Epoch 780/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.9912 - val_loss: 0.2474 - val_accuracy: 0.8571\n",
            "Epoch 781/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1073 - accuracy: 0.9912 - val_loss: 0.2856 - val_accuracy: 0.9048\n",
            "Epoch 782/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9825 - val_loss: 0.2554 - val_accuracy: 0.8095\n",
            "Epoch 783/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.9912 - val_loss: 0.2474 - val_accuracy: 0.8095\n",
            "Epoch 784/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0944 - accuracy: 0.9912 - val_loss: 0.2556 - val_accuracy: 0.8571\n",
            "Epoch 785/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1268 - accuracy: 0.9737 - val_loss: 0.2690 - val_accuracy: 0.9048\n",
            "Epoch 786/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1162 - accuracy: 0.9825 - val_loss: 0.2514 - val_accuracy: 0.8095\n",
            "Epoch 787/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1135 - accuracy: 0.9825 - val_loss: 0.2491 - val_accuracy: 0.8095\n",
            "Epoch 788/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1007 - accuracy: 0.9825 - val_loss: 0.2721 - val_accuracy: 0.9048\n",
            "Epoch 789/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1124 - accuracy: 0.9825 - val_loss: 0.2630 - val_accuracy: 0.9048\n",
            "Epoch 790/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0981 - accuracy: 0.9825 - val_loss: 0.2571 - val_accuracy: 0.8571\n",
            "Epoch 791/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1023 - accuracy: 0.9912 - val_loss: 0.2597 - val_accuracy: 0.8571\n",
            "Epoch 792/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1019 - accuracy: 0.9912 - val_loss: 0.2452 - val_accuracy: 0.8571\n",
            "Epoch 793/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1099 - accuracy: 0.9912 - val_loss: 0.2527 - val_accuracy: 0.8095\n",
            "Epoch 794/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0987 - accuracy: 0.9912 - val_loss: 0.2620 - val_accuracy: 0.9048\n",
            "Epoch 795/800\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9912 - val_loss: 0.2472 - val_accuracy: 0.8571\n",
            "Epoch 796/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1108 - accuracy: 0.9825 - val_loss: 0.2514 - val_accuracy: 0.8095\n",
            "Epoch 797/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.9912 - val_loss: 0.2731 - val_accuracy: 0.9048\n",
            "Epoch 798/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.9912 - val_loss: 0.2812 - val_accuracy: 0.9048\n",
            "Epoch 799/800\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1083 - accuracy: 0.9912 - val_loss: 0.2716 - val_accuracy: 0.9048\n",
            "Epoch 800/800\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0920 - accuracy: 0.9912 - val_loss: 0.2508 - val_accuracy: 0.8095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gccWcGCz-QO8"
      },
      "source": [
        "#### Plot the learning curves\n",
        "\n",
        "Let's now plot the loss and accuracy for the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8uieP3K-QO9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1cab505d-d8e6-4ed0-fa16-07b1e657eefe"
      },
      "source": [
        "#Run this cell to plot the new accuracy vs epoch graph\n",
        "\n",
        "try:\n",
        "    plt.plot(reg_history.history['accuracy'])\n",
        "    plt.plot(reg_history.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    plt.plot(reg_history.history['acc'])\n",
        "    plt.plot(reg_history.history['val_acc'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show() "
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpgy4mVP-QO_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0414b4cd-180a-4cd3-ef32-498fe6695be5"
      },
      "source": [
        "#Run this cell to plot the new loss vs epoch graph\n",
        "\n",
        "plt.plot(reg_history.history['loss'])\n",
        "plt.plot(reg_history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na0xiTpm-QPB"
      },
      "source": [
        "We can see that the regularisation has helped to reduce the overfitting of the network.\n",
        "You will now incorporate callbacks into a new training run that implements early stopping and learning rate reduction on plateaux.\n",
        "\n",
        "Fill in the function below so that:\n",
        "\n",
        "* It creates an `EarlyStopping` callback object and a `ReduceLROnPlateau` callback object\n",
        "* The early stopping callback is used and monitors validation loss with the mode set to `\"min\"` and patience of 30.\n",
        "* The learning rate reduction on plateaux is used with a learning rate factor of 0.2 and a patience of 20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18JaoKcd-QPC"
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_callbacks():\n",
        "    \"\"\"\n",
        "    This function should create and return a tuple (early_stopping, learning_rate_reduction) callbacks.\n",
        "    The callbacks should be instantiated according to the above requirements.\n",
        "    \"\"\"\n",
        "    early_stopping=tf.keras.callbacks.EarlyStopping(patience=30,mode='min',monitor='val_loss')\n",
        "    learning_rate_reduction=tf.keras.callbacks.ReduceLROnPlateau(patience=20,factor=0.2)\n",
        "\n",
        "    return (early_stopping,learning_rate_reduction)\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqi6pF-v-QPD"
      },
      "source": [
        "Run the cell below to instantiate and train the regularised model with the callbacks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emW-CYSd-QPE"
      },
      "source": [
        "call_model = get_regularised_model(train_data[0].shape, 0.3, 0.0001)\n",
        "compile_model(call_model)\n",
        "early_stopping, learning_rate_reduction = get_callbacks()\n",
        "call_history = call_model.fit(train_data, train_targets, epochs=800, validation_split=0.15,\n",
        "                         callbacks=[early_stopping, learning_rate_reduction], verbose=0)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtuDazML-QPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e98f0b2-fed1-40c8-d42c-b007db5a1344"
      },
      "source": [
        "learning_rate_reduction.patience"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zhsqvtL-QPJ"
      },
      "source": [
        "Finally, let's replot the accuracy and loss graphs for our new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOPSJT7w-QPJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "27784646-9f39-4a55-d6af-75276146e1f1"
      },
      "source": [
        "try:\n",
        "    plt.plot(call_history.history['accuracy'])\n",
        "    plt.plot(call_history.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    plt.plot(call_history.history['acc'])\n",
        "    plt.plot(call_history.history['val_acc'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show() "
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3gc1bn/P+/uarXqXZZtyb0bG2ObaqrpPYHAhRQgJBASSAghhZSbS7gp3Hv5pZMCBEhCM4FQAqYH0wxu2Bj3IoPVbMtWl1badn5/zOxqV1pJa1sr2ez7eR492pk5c+bMrHS+877vOe8RYwyKoihK6uIY7gYoiqIow4sKgaIoSoqjQqAoipLiqBAoiqKkOCoEiqIoKY4KgaIoSoqjQqAoCgAico2IvD3c7VCGHhUCJemIyBIRaRSR9OFui6IovVEhUJKKiIwDTgIMcNEQX9s1lNdTlMMVFQIl2VwFvAc8CFwdfUBEKkTknyJSLyL7ROT3UceuE5GNItIqIhtEZK6934jIpKhyD4rIT+3Pp4pItYh8T0R2AQ+ISIGIPGdfo9H+XB51fqGIPCAitfbxp+3960TkwqhyaSKyV0SO6nmDdjsviNp22debKyIeEXnIvr8mEVkhIiMSeXAicpyILLXP+0BETo06tkREfiEiy0WkRUSeEZHCqOMXich6+9wlIjI9keduH7/LfhY7ROTcqP3XiEil/Z3sEJHPJXIfyqGPCoGSbK4CHrZ/zg53giLiBJ4DPgbGAaOBx+xjlwG32+fmYlkS+xK8XhlQCIwFrsf6G3/A3h4DeIHoju/vQCYwEygFfmXv/xvw+ahy5wF1xpjVca75KHBl1PbZwF5jzPtY4pcHVABFwA12G/pFREYDzwM/te/n28CTIlISVewq4FpgJBAAfmufO8Vu0zeBEmAx8C8Rcff33G2OBTYDxcD/An8Riyy7/nONMTnACcCage5DOUwwxuiP/iTlBzgR8APF9vYm4Bb78/FAPeCKc95LwM191GmASVHbDwI/tT+fCvgATz9tmgM02p9HAiGgIE65UUArkGtvPwF8t486J9llM+3th4Ef25+vBZYCs/fz2X0P+Huc53K1/XkJcGfUsRn2vTuB/wQejzrmAGrs59Pfc78G2Ba1nWk/7zIgC2gCLgUyhvtvS38G90ctAiWZXA28bIzZa28/Qrd7qAL42BgTiHNeBbD9AK9Zb4zpDG+ISKaI/FlEPhaRFuBNIN9+M64AGowxjT0rMcbUAu8Al4pIPnAuVgffC2PMNmAjcKGIZGJZMI/Yh/+O1YE/Zruf/ldE0hK4j7HAZbZrp0lEmrCEdWRUmaqozx8DaVhv8qPs7XD7QnbZ0fT/3AF2RZ3XYX/MNsa0A/+BZdHUicjzIjItgftQDgM0mKYkBRHJAC4HnLa/HiAdqxM+EqtjGiMirjidUhUwsY+qO7DeVMOUAdVR2z3T6d4KTAWONcbsEpE5wGpA7OsUiki+MaYpzrX+CnwZ6//kXWNMTd93HHEPOYANtjhgjPEDPwF+YgfOF2O5Xv7ST13Ybfu7Mea6fspURH0eg2V97QVqgVnhAyIidtkaoIu+n3u/GGNeAl6yv9ufAvdiDQRQDnPUIlCSxaeAIJbLYo79Mx14C8u3vRyoA+4UkSw7qLrAPvc+4NsiMs/2T08SkbH2sTXAZ0XEKSLnAKcM0I4cLJ98kx1M/a/wAWNMHfAC8Ac7qJwmIidHnfs0MBe4GStm0B+PAWcBX6XbGkBEThORWbYF0oLVWYcGqAvgISwL42z7Xj12MLw8qsznRWSGbYXcATxhjAkCjwPni8jptvVxK5YALKX/594nIjJCRC62YwVdQFuC96EcBqgQKMniauABY8xOY8yu8A9WoPZzWG/kF2L513divdX/B4Ax5h/Az7A61FasDjk8IuZm+7wmu56nB2jHr4EMrDfl94AXexz/AlbnvAnYgxVgxW6HF3gSGA/8s7+L2KLyLlYQdVHUoTKs+EILlvvoDSx3ESLyJxH5Ux/1VQEXAz/A8ulXAd8h9n/271gxkl2AB/iGfe5mrED37+z7vhC40Bjjs4Ui7nMfAAfwLSxrowFLgL+awHnKYYAYowvTKEpfiMiPgSnGmM8PWHgIEZElwEPGmPuGuy3K4Y/GCBSlD2xX0pewrAZF+cSiriFFiYOIXIfljnnBGPPmcLdHUZKJuoYURVFSHLUIFEVRUpzDLkZQXFxsxo0bN9zNUBRFOaxYtWrVXmNMSbxjh50QjBs3jpUrVw53MxRFUQ4rROTjvo6pa0hRFCXFUSFQFEVJcVQIFEVRUpykCYGI3C8ie0RkXR/HRUR+KyLbRGSt2AuPKIqiKENLMi2CB4Fz+jl+LjDZ/rke+GMS26IoiqL0QdKEwJ6N2dBPkYuBvxmL97DSE4/sp7yiKIqSBIYzRjCa2IU1qu19vRCR60VkpYisrK+vH5LGKYqipAqHRbDYGHOPMWa+MWZ+SUnc+RCK8omivrWL3762lV++vJklm/f0We6DqiaW7+jP8I7P1t2t/HvT7oTKPr+2jj0tnbR1BXhiVTWJpKV5Z9tefvnKFrbtaQWgucPPohU7CYViz/UHQ9zz5nbue6uSYI9j//qglt0t1mJzdc1enl9bF3P8yVXVNLb72NfWxTNreq8Z1BUI8siynVQ1dETOfX3THn758mZ++9pW9rZ1sbulk1+/uiXmOS9asZPfvbaV5g4/ANv2tEaOLf6wjsr6Nh5e9jFVDR08vTr2uqGQ4fEVVdQ2eXs9q2fW1PDLlzdz9+vbYs4NP6vNu1pZtGInbV0Bapq8PLe2FoC3t+5l066WAZ/5wTCcE8pqiF1hqdzepygpz5PvV/PLV7YAMDo/g3duWxi33MV3vwPA1p+dS5oz8fe6Hz61jjVVTSz7wekUZLn7LLe3rYsbH3mf60+ewK7mTp79oJZpZTkcMTqvz3N8gRBff3Q1De0+apu83HXZkfzpze38ccl2RuZlcPKU7pe5xR/W8fPFmwA4bkJRpN6NdS18/dHVnDa1hAe+eAy3Pfkhb2ypZ2rZyUwqzaG6sYNb//EB15wwjryMNH7z2lbmjimgorB78bpfvbKVP72xnZKcdOpbu5hadgrf/scH7Gv3AeB0CDVNXh5ZthOAnHQXD157DN978kMA/CHDt86cwpX3LqO+tYt/3XQiX3v4ffIz02iyRQJg/rgCygus6z61uobvPrk2cizH4+LsmWV0BYLcsmgNYa37v5c2R879/j8/ZGdDB39ash1fMERVg5eP9rXz3No6po/M5fN/WQbAR3ee399XelAMp0XwLHCVPXroOKDZXtxDUYaEPa2dhEKGYMhQ39oV2d/Y7sMXsBbfCoYMG2pbWFvdRKPdgYQxxkTeWNu7ArR2+hmIumYvG2pbCIUMgWCIdTXN1Ld20ez14/UF2d1itWlnQweFWW6+sXASdc1e/MHei4EFovb9e1PfVkNPKuvbWP5RA75gKPImHb5uyH4WHb4Aa6ubWFZpWRvrapr5sKYZgKqGjsjbcvS5YInA71/fRoP9rPa0dhEIhnhylbWa6F+XfsTa6qbIz8Pv7YzUs6/dR3uXdd37394ROX93SydefxCAv7y9g7XVTWzZbVkaT6+p4f2d1pLTy3c0xNT94jqrOwl/t7/791b2tfv4yUUzGVOYycqPGvjXmlouOWo0j153HK1dAS7941LcTgezy/N4YmUVwZChqcO6lwt//zZAjAgArK/tfltf/GFsF/aPlVWsrW5i865WQgbuuuxI5lTkR46/u30fOxs68KQ58Nnf56Zdrby83rLWfvva1kjZx1dWsbeti2SQNItARB4FTgWKRaQaa4nANABjzJ+w1m49D9iGtQ7tF5PVFkXpybqaZi743dv8z6WzeHf7Pp5eU8um/z4HT5qTo/77FRZOK+X+a47myVXVkTe8maNyef4b3Uv0/vGN7fzvi5t567un8YsXNlLd6OWZGxdgLRHcG18gxMK73sDrD3LnJbNo9vr5xQubKC/IYE9rF26nA18gxHfPmUpVQwflBRmUF2QSMlDX1MmYosyY+rbXt0c+P7+2jrNnliV078+vrUMExhVl8fjKas6YMYKFd73B986dRpbbye3/Ws9xE4pYsrk7Hre+tgWnw7qvGx95n7FFWbz+7VOpaujg9P/3BredO41rTxzPr1/dwh+WbGdUnodpI3OpbfLy5tZ69rR2MWVENq9t2sNrPUTrkqNG88/VNTS2+7j5sTW8unF3zHWP/flrke1Hl1fx6PLu0GJTh5+3tu4F4NZ/fNDvfT+zxnK1zByVy8xRubywzlpK+7L5FRw3oZDxxVns2NvO2UeUcfbMEdz0yGqWbt9LrictYkVMGZHN1j1tTCvLZWNdS6SNZ88so70rwBtbYmOYr27cw6sbu++3vCCDK46uYE2VtUT2E7ZA/viCmfz4mXUEQiZy/5NKsyNtBvjuE2v56aeO4PPHjWWwSZoQGGOuHOC4AW5M1vUVpT/C/4Brqpp52v5nq23yMiLXA3S/YW/Z3YonzcHCaaW8unEPoZDBYXeIv7JdNx9UN7GprpXKve2sq2lhVnl8t0ltkzfyZvvo8p2Ra1U3egEiVsgjy3ZigBkjcykvzACgqrGjlxCsr7Xe0MtyPXy8r51EWVvTzPjiLL54wjj+85n13P7sBnzBEI8s+5gjy/Pp9IdiRACg2dv9FhwysGNvO/WtXTyxqhpfMMTDyz7miwvGserjRtJdDh67/nj++MZ21lY3sWhFFcXZbv5xwwm8/3EjoSi/udMhTB+Zyz9X17CxroV/b9rNZ+aVc96sMtbXtPD/7GcMcN6sMi6dW86f36hk+UcNOARKczzssq0ygM/MK+fcIyxBTHM6eHT5Tl5Yt4szplvfnwhMH9ktBGOLMjluQiEiwt+uPYate1qZN6YQj9tBfmYaD77zEfvafVx9/FhOnlLCnIp86tu6mFCczdY9rdz82Bo22N/DxroWAlFxjmPHF3LDKRN5bMVOXrLf8CsKMzlmXCGzyvO4+bE1LLPjO2fMKOXocSfx8LKdPLj0I44YncvXF07mK39fhQg8+dUTaGz3MbUsJ+HveX847JLOKZ8s2roCfOEvy/jhedOZP64w5lhXIMjlf3qX2uZOctJdPPaV4yjN8cSt5/XNe7j/7R08+MVjcDoEXyDE5/+yjFOmlPDo8p3ketJ4/IbjyU53EQqZSCAu+u3zlkVrKImq/6Lfv017V4DygkyOm1DE4g938fm/LOO4CUU8saoaf9D6p19X0xLpzB9fWcWs8jw21LZw3d9WRsz906aWcOGRowA4Z2YZL67fRZa7jdKcdPZEuaUy3U4q91qd+lkzR1Bh+56rGjpobPdx7V9XcOnccp58v5pxRVmkuxycMqWEVzbGBn4fX1nFXS9t5tSpJfgCISaWZPOvtbV0+kPsbOjgwiNHcdGRo/nv5zby6sbdZLqdbK9vZ1dzd6d69fFj+eu7feYpY31tM0++Xx05d01VExvqWvjMvHLGFGVSmpPO3jYfL63fzXUnjScvI43TppX2qicYMjgEHlj6ESEDN502iXHFWWSnp8WUO2J0HqdPH8G6mhaWf9RAbkYal88v57f/3hYp8/WFkxhblBXVxhZeWLeLG0+bxJqqZnI9LrLSXcwcZYn1ZfPKIxZcRWFmTIzhU3NG8+DSjwCYN66Q06ePAKAoOx2AmaPyLCtxbR1H/+xVumyRP2lyMW9t3cvUshxOm1ZKfVtXRAjKcj04HBI5d9ueNoqz0ynN8VCa4+GoMfk8uBQun1/BwmmlFGe7yctIY+6Ygj6/h8FAhUAZVlbvbGT1ziauvn856++InX+4qa6VD6qbOXpcASs+amRZZUOkM+3J4rV1vLV1L5X1bUwekUNds5flOxqiRtR4Wby2jsuPrmBvWxd72yxTPzo28EF1M9Ac2V5bbX0+bWpJpENeun0fS7fvA+D82SP5oKqJJZv34AuG8KQ5eGZNDT88fzp/XfoRjR0+Lp4zmnU1zTyzppZZdiD0poWTeG3Tbtp9Qa4+YRx/WLIdgBtPm8hpU0u5+v7ltPuClBdkMjLPg9MhVDd6eWT5TlbvbGL1zib72TWxcFopY4szabD961npLowx/HHJdva0dvH06tqIGEUzc1QueZlp/OKSWaza2cin5ozmmges64Y5bVops8rzmViSxasbd9PpD/H4iipauwKANQKnutHLTadN4vevb+OZNbW0dgYinWxJTnqkroXTRvT1J4DTIeRlpNHY4ae8IINxxVZHPm9sAd85eyq/eW0rvkAo8h3MHJULWHGZa08cT5rTwalTS1lX2xwjAgCXzS9HBI4sz+euy2ZHrJEFk4r51plT+MLx4/ps12XzyyNCUF6QEbfMdSdNICvdxYfVVgzF7XJw9LhC3tq6t1d7w/fa89zjJhRF9p05YwS3nDGFz8wrJ83p4P8uOxKGYO0wFQIl6XQFgtzzRiVXHT+OvMzYt7ywn7XdF+T7/1zLmMIsbjhlAs+trePlDdZb1C8umcW5v3mL9bUtjMr3sLulC38wxLiiLCaVZnPvW5arAODu17eR4XYxOr/7zf4z88pZvbORRSuruPzoCqoaOwAoynKzr93HhJIsKuv7dq1Yb4qxHcHs8jzu/uxcbn38A55833IzXX38OP78ZiU3PfI+S7fv44LZI/nFJbN4anU1tyz6gDe21JPmtFwhZ84YweIPd3HchCKeW1tHa6efb581FRHhgtmjWLSyioqCDFxOByPzPCxeV0dnVCcd5vL5FZGO/tv/+ID8TDcdvgA79rZzwsSiiGgBHFmRz476Nlo6A0wfaXVOl84r59J55QCcP2sk/1hVjSfNQac/xMxReZHO/Cj7jfSh9ywLwZPmYNFKy1d/ytQSHl9ZxeP2drjjixaCGVGdYTwKstw0dvgjnSdYneaNp03iXx/UsmlXK6V2fTNHW3X5g4b8TDdfP30yQFyXXHF2OjecMhGAU6d2WyNul4Nv2Of1RfitfX1tS0y7ojlidB4///Qs3t/ZyCV/WGoJlv23Ev49uTS+Oyd8bjSZbhc3n9HdrtOm9ragkoEKgZJ0nvugjv/3yhYKs9187tjYQFd4xMXYoky7QwxwxvRSvvPEB3T6Q2Snu5hQnM3k0hzW1zbzpze2x5z/XxfO4Nevdo+sCPv7w/HaNKdw7YLxvJSfwW9e20pbV4CqBsuNc9zEIp5fW8e0spxeQjBlRDZbdrcB1tvg6PzujmBCcRZfO9XqXI4eVxARgsvml7O+toUPqpspyHRz9QnjACJvyK9u3MPYokycDuG6kyZQ19zJUWPyuWxeOW2+QMRF8cUTx7FpVwuzy63RJefMLOOZD2pxCKS7HHQFQmS5nRxZkc/CaaWRWMEL63ZRkJmGy+ngiNG5fOfsqXz6D0utNpdYbS7JSee/n9vA3DHdI1fCXHvieLbsbuXTR43mvcqGmI48zB8+N5d736qkLNcTedZhn/vrm+vJTndF/NilUefnZaT1qiuawkw3lbT3ElyAn18yi588uz4ytLQs18NJk4u54ugx/dY5GHx94SQeWW7FOPrjqIp8zptVxqlTSzl6XCFHVuRH3Dlul4NL5o5mdj9DbocbFQIlIbbtaaOiMIN0l5O2rgArdjQwoSSLsUXWSIuyXA8ZbmfMObVNXjxpzsib4tqqZuaNbWFaWffb4fraFs6YXsp9Vx/Nio8auOxP7/I/L26i02+95bZ1BWyfam7cIZKPr6zutc8hRMZrL73tdEpy0qlrtjr/jXUtVDVYFsHUETk8Tx0FmbH/5GlO4cWbT+b6v6/i1Y27Kc5Oj7m31249JdJpnzd7JLf90xp3Xl6QyUNfPrZXeyYUZ0U68LCL4agxBTz1tQUAkTfaMNPKcnnmphMj2z+6YAY/umAGAPe+WcnPFm/kljOn8OWTJgDE+LXf/f7peNKstgaCIdJdDrLTXbz2re42h6/bk+kju697zYLxccucPn0Ep08fwTvb9kaEIDvdZbtk6jlzxojI9eMJSV+En2+8N++5YwpinoeI8Pcv9X7OyeCcI0ZyzhEDZ74REf7wuXmR7WdujH3Gv7x8zqC3bTBRIVAGZF9bF2f88g0+e+wYfv7pWfzu31v58xuVTBmRzXNfP4nzf/sWN542iRtPmxRz3gl3/jtme9HKKhatrGLlj86gODsdry9IZX0b582y/tGmj8xFxHpzDrtrLrPdFrPL8/jHqt6d/sa6lsiwv1mj8/iwppmrTxjHA+98xBxnJYXVr4AIc70+znSspWX1bnIaO7g0s4UzHS186NjC5TlNlJTXR96sCzLcOLYYvlyyD9m8g7neDtiUyflp77PVNcnqUI2BHW+Q62vnU2X1LN3lwrP9xdjGpefCuBNxeffx5ZKNbNndykJ3KWzqdteQOxpGzYGGStizccDv4nRHO8sdGznZ4wYmQEsdRTWrONOxihmjcvFsBzx5MHYBLqeDs0b5mObYinjnwd4tEOiE8ad0m0z7tlv7xy6AtEzY8YZVpmAcjJhplaldAy2xcz2PL7S+68srWmDT81yY3kiNYztfGdEKm6yyI4IhznS8z0mTi2HT89aJeeUw8sjuiqpXQttuZrZsokVclBdGHYtzXQDKZkNnMzT1FcgWGHs87NkE3obu62aVQO3qAZ9xv4jDelZ1a6CrNbFziqdY59Vvit2fUwaj58U/pydBP2xeDCPnQMFhNHxU+eRQ02S9TS+rtDqwD+wx0HVNndQ2eenwBdm2py3mnDY7oAjWG/q5s0ZGpvl/vK+d4ux0Nu5qIWTgCNt/nJ3uYnxRFpV72/nsMWO4ZG45WenWm+I5R4zkP59Z36tt6S4HT39tAZ2BIHkZaXh9QZ77sI4cOngy7cc4F1mWRQFwrxuIHmr+hr3vbTgSIGwYBIDH4DjgODfwirX7bicEJpwFXAnVK+BvFwPwK6ebwPQF8NjrvR/eV9+Fd37NdxoXWfVX2j9hnG74fg0s+gLsjpuxPYYJ4ft4/pcwZT08fyuy5UVr316r3QB87T0onc6v3H/AVf0ePPOu1ZEAXPsyjLHfqBd9Afash5NuhYrj4JHLrP2efLjtYwh0wV/OhGDsZDpH/hg++M9V5P52AjzWyrxwu5Z0l0kL7/vY/gFwpsMPasHpgo4GuO8MwHAbEHQLa7OsZ4q/0zoWijNJb9xJlkj4+umIp57Xfb8ALg+MPQG2/7vvcxJl6vmw+fnEyxdOsL7nnkIgTusZpycwJLR9Lzx+FVzwK5h/7f61NwFUCFKQxR/W8bWH3+fD288ix9O/7/az974XmfySbY9I2WD79Vu7Auywx69XNXSw6uNGPn/fMl6+5eSYsd2nTClh3piCiBBUNXiZN7Y7PjAzync6c3QeOxs6+PRRoymMSn1QkpMeCWJGc84RZeRlppFnzVXEk+akvCCDImnGSQgW/ggmnwXAfz6znvc/tmahnjK1hO+ePbXX/X7prysZW5TJj21XTAwvfh9Xhz1Ms9WeQTrz08j6p0jbtwXGHA/n/o+1f9c6eOZr0LbLKls2Cy6+O7a+9U/D278Eb6NVZsan4KRvxfkWerDzPXjhu9C22zpvzAlw7p32dT+EZ26E1l1QOh1XuzVpirooBWzb1f251Z6w1Lo75p5Y/5TVGXc2WSJw0rdhxkXW8WV/hg+fIM/ls96Kj70B5nx24Havfwre/pVVZ1YxtNcDBs64nSdXfsSlTQ9S5rJjNd4GSwSirwvw6u1Qv9kSgWO/CnPiTFd6/Kru+z3vLmiuhnd+bZ037iQ4+2cDt7Uv/n6JZQ0AfOpPMCLO30k07/4BNv7LEr4jPgMLvmHt3/wiLPm51cEnIgRe6++WjOQMI1UhSEH+aA9XrKxv58iK3kHDaKJHnWSlu6hu9NLSGWBaWQ6bdrWyzh5iWdXYwXNra/H6g9z/zg7G2n7rOy6eycmTSyjL8yACP/nXhoiPfkNtM/mZaYzK6x7hc8sZk/n0UaMiY7WjeeWWU1hf28w3HltDusvBnZfMZu7Y3u2vKMgkH7tDKTsy4oq44qJxFNjjuS+cPRJG9P4HvP7ycmtkU1mcUS55FbDTCr5G/jFHz7M6uJYay2UQdns407vLeRsht4dLBGCvHeTu2GeVKZrYu0w8/J2xdZdMj7quO7Z9XkvEY1ws4WOhkOViia4r+p46m7r3jZjZfY2iSRDs6haO0umJtbt+S/e1soq76y6bzVkLJ8M/H2SkO+reAMqOiK27YFz3W31f180ug6r3rM+j5lqusvAzmHBqYm3ti6wSqLddeOVHQ/Gk/ssXTwJ/O/ixnlv42s329+FtBOLHY2JQIVAGG0+alWKq0997OGKY9yr3sa6mOWbfrpZOrrzX+gc7aXIxm3a12mPvYXdLF4IdjFxdQ64njaIsN184bmz3aJgF47n79e1UN3p5fKWVKmDBpKKYlAwTSrKZUJIdt03hCT/l+ZvxpDk5f3b8IF55QQb5Yruqov5xrOGA/Y/cODZqTHcvMgq6O9bwP2bhhNjjPT97G61zRsQOE4wp01wFJpT4P3mk7ibrp6/rhoLdHX004bZ3tVjXjbSz0RKS3FGx+/q6t4bK3scSandj7O+MAnLCb8VxjsWto7/rxpTJT+ycRNnfuvoq3/NZDIQKgTLYpLssv3tLZ6DPMlfc816vfeEhltNH5nLCxGLufctKABZmTZX1x1pRkEkwZLh0bnmvvDsVhRlUNXawyk4Udvn8CvaXzx47hnRX3/kSPWlOLpySAR8xuP84GQVW5xn0251mOuSMjD0e+WxbKuHONF47DrZDbdtjtSf6PE/UdTubiTsbqWdn27OdGYWx+3rd2+ALAaFA38fi1dHfdXuWife9HCgxzzqB4aAqBMqhyDvb9pLmtDrnxo7e2TTf3raXEycV91vHU187ge311hv3ntYuMt1OOnxB3t/ZxOzyPJ6NGurXk/KCTFbvbGRfm48vnTiei+fEXYuoX8LDJvvj0ulZyRECsDrYcKeZGZUWI/qzKx3SsqzO2tcWvx3h8vvdodqdWeNHvc9L81ijf6I78awS2x8PZBb37myzSnsIQbQ1E6cDOth2D5YQZMamJOldRqzOOhkWQXqe5fcfsHxUG+O1PWEhaOfS8mIAACAASURBVOhdxyByWCxMowwOW3e38rn7lvGO7ffvmVZ51ceNfOEvy1n84a54pwPhoK0zJpB7fJQ7pXSAseNjCzOpbrSSr1X0MW1/UAj/gyXy1pYoPTvIXm+bcTqthh325zhvogf6Zu1MA3dO3+eFXVhhN1bYfZWeZ4lCz862cML+CcFgWgTisIbZevoRiXh19Hfd8H5PHjicgywE+bG/Byzfx7Uj99tEQngbweECd3y36cGiQpBC7G6x8uqEs1w29LAIwsNEX9kQKwSPXHcsPzxvOgD59gzR6ElYp04tiQjDQJOIwqkNIHYi1KDjbUz8rS1Rwv/IHQ3dvvn0XGsYYPTx6PL9dZbhc/e3Qx2o7owCuxO33yLDQhD2l8eLcwS7oKU2Vgg6GqwfccaObDlQIfDkAWLVGa7fkw8Oh/U9pefGCkG8ji8hIciPPR79MjBYFsH+il/Pzy63dW/74xrKKOie/zHIqBCkED07/qb22DHa4QRsb9r53cOU5qRHOvqsdKtjDc8eBZgxKo+p9gickj6yg4aJTsBV3kf+lkHB23jw/uCexLMIRHp3PJHy+f13luFzD0gI+jkvIgQ9AtrhTj6eRQBWfRkFVqcvzt732fM5NFRaweW0BL9Hh9PqlKOv39N/3/NYz44vXN7lgbQ+LMqenXX4utH7DpTBEoLw9v4KQZJQIUghmnoIQU9hCKdDbujhMsrPdJPjsQQgPMErmukjcxhpDwEtyOx/XsKYKCugr4yOg0Iy/nH6CgD31TlkFBAJ1iYS2PTsh3DF1N3jvHCHOqAQhF1H4eGLJkrcCnrfZ5i0zO5hqvv7ltpTiHp2lH0di7lv+v9u45XZ3w58f+ruj7CoQm83ZbTwDYQKgZIovkCIWxatiQRyo/nFCxt7LbT9yobd/N9L3bMdo1MyzxiZi9teAzc/Iy2Su6cwq7frJ9PtYrTdqcdbUjEaR1Qa3rB1kRSSIgQ9LYIelsDB+LPTMq1A7/62pa/rRgtBwfju/T3fut3ZkB2V4TL6nvoSgrBQ9Hdf/bU7lYQg/KziuSn32yLoIzg+CCR11JCInAP8BnAC9xlj7uxxfCxwP1ACNACfN8b0TiijJER1YwdPra5hdnkeE6PG4htj+PMblXHP+cOS7Vx5zBjKCzLZ09o9G3hMYSbNXj9tXQFcTgenTSvhc8eOiUmR+8vLj4zkV7/u5AnsbfPxHwlkhLzvqvmReETS8DZC/iBnp/TkA2JNpPJ3dI/8yCgkMkIlmr5GFEUT6Vj28588Up/0tiQyCq3772iw/O5Zxd3Xyiiw2u7v7CPgXdhdf2QyXJw1IDIKrJnNB9LucIzA2wglUbO7MwpjJ1rllvc+Pzwaq7+OOLMw9ne4bnFaz+NgiFf3QGQUxE+VkVFg5UNKhL7mogwSyVyz2AncDZwJVAMrRORZY8yGqGJ3AX8zxvxVRBYCvwC+kKw2fdIJ5/fpORqoZ1qGaIyBPf/4FuXBddxR30ajO40bfd/gDD7iu4H7CEkI/ngH6cDPAB7qPveS8Id3IRfry+PBgdt5RvjDBwOXPWAaP7KSqw0mDof1xvz+36xtT9TbsyfX8kVHE91ZuftIIxDuSPc3nhGuOz3HalfPY8EuWLvIqjciWAXdn+851QoOF4yJ7cyjLYLKN8AEoTROGoWDafeOt+CPJ1qpH6JFLKMAGndYx/ZuhhFH9F1HIhZBz7oz8g8+2Bqv7oHILLRyNvWqqxAatlv3OxAtNfv/rPeDZFoExwDbjDGVACLyGHAxEC0EM4BwcpXXgaeT2J5PPG32BLGevv/o9WbDOB2C2+lgyohsJtc9B/lF7AtlcYxjPbMdlRzVsYXyUC1bsuZD/iAOwRwqCsbC7MsHv94Tb4Gdy6xRH5NOt/bNvSp+Fskp50LNKiiZ1ruzDjPnSmuewZRz4h/vixkXW1lDR8/vfWzquVD7PgQDMPE0y/1z6g9g+oXgzrRyCQV8Vuxg2nnWpLijr7PewsfandLcq603aJH4eYSO/pLVKc69av/aPedz4PdabyAFY2HWZ7qPzb7csjLCx47sY9nzU75rZRPti/RcOPX7Vu6mMPOusTKSHiy55dbfwPQLEj/n+Bu750lEM/tya36HSWAJsoKxcMSliV9zPxGTSCMOpGKRzwDnGGO+bG9/ATjWGHNTVJlHgGXGmN+IyCXAk0CxMWZfj7quB64HGDNmzLyPP+57HdVU5uX1u7j+76s4f/ZIfnvFUbR1BcjLSGPL7lbO+tWbMWWvO2k8Pzx/Bt99fDV3bjiN9mO+yblvjeXt9G/yHf/1fG/sFopDDXDDW8N0N4qiDCYissoYE+fNYfiDxd8GThGR1cApQA3QKwGOMeYeY8x8Y8z8kpKSoW7jYUO0a+jOFzZy5E9exusL0hLHIshwW8bgxNwQDgy/fqeeZmPFFfJoJzvUmtRRCoqiHDokUwhqgOhEMuX2vgjGmFpjzCXGmKOAH9r7Epxqp/QkIgQd/sjqUTVN3riuoUx7Rajx2Zbvsslkc/bcyRhxcv3RBXj8LSoEipIiJFMIVgCTRWS8iLiBK4BnowuISLGIhNvwfawRRMoB0trZbRHk2EMzqxo7aOmMYxHYE8LKPZYQNJLNjQsnIxkFlLo6kj5uWVGUQ4ekCYExJgDcBLwEbAQeN8asF5E7RCS80sSpwGYR2QKMwB6YohwYYYugocMXGaNf3dBBi9faf8MpE7nkKCvJW3iN2LI0a8hok8m21hDIKLBTKKgQKEqqkNR5BMaYxcDiHvt+HPX5CeCJZLYhlQiPGvIFQpF8QlWN3oh1cOtZU7j/bSsJWtg1FM7b30yWNdkro8DOjx9UIVCUFGG4g8XKIBK9TvCOvdbaAdWNHTR7/WS6naQ5HWTbqSLCQuDotEIyVy08yjoxo+DAct8oinLYousRfIJojVpoxmeneqhq8JKd7iLXXps427YOMtLsr96e4n71wjnWdvS0dxUCRUkJ1CL4BNHW5cfdY+Wu7fVt7G7pIjfD6vjDid5G5EatqevOsXLcQ2znvz/T6BVFOWxRIfgE0dYVYE559zT0c2aW0eEL8saWevLsdQTmjS3k3e8v7F4XOF7ir3ifFUX5xKKuoUOYJ1ZV88OnPmTdT84mzRlHs7tarbwtJsTvX9/GqLomjhlfSL7DSur1xaLxFOXVUt/axexQPmy09o8EqLXr2LsFMvuwAlQIFCUlUCE4hLnzhY10BUI0tPsYkRsnRfG7d8OSXwDWOF3cQA18Obx42HI4Nrx/D7CojwtNi8qbkhc1B1CFQFFSAhWCQ5jwKmBPr65hZH4GFx3ZIx2wnU8+dM1iLvjd2wBMKs3G4RC27GrlzktnM3t0AgnjiiZ2f55yNty4wsqm6ep/2UlFUT4ZqBAcwoSHeP7iBStneS8h8HvBnUV74Qw22Ms4/PDCYxmR6+HnizcyefZccPdeUaxfRKBkykG3XVGUwwcVgkOY6HWBe9LhC7BvTwOluGmxh43+z6WzWDDJWoTk/muOHpI2Kopy+KNCcAjTnxA8vbqW/I93M0lC+OyFaMIjgxRFUfYHHT56CNOfEOxp7cSDj07cbN7VChCZNKYoirI/qBAcwvS3aFBThz8iBOtrWwDIVYtAUZQDQIXgEKbTH7tGTzDULQwN7T484qPTuFlf2wyoa0hRlANDheAQxttDCDr9Qby+IN9atIYNdS3kpwXpirYI1DWkKMoBoMHiQxivL1YIvP4gH+9r55+rrYXeMrP9SJqHto4AIpDj0a9TUZT9Ry2CQ5hOfyhm2+sLUt/aFdlOx4czPROwsoo6HDKk7VMU5ZOBCsEhTM8YQVcgyJ4oIXDjIzMzCyB+LiJFUZQESGrvISLniMhmEdkmIrfFOT5GRF4XkdUislZEzktmew43vP4g1500nnuvmm9t+0IxFoE71MXYsiLACh4riqIcCEkTAhFxAncD5wIzgCtFZEaPYj/CWsv4KKzF7f+QrPYcbhhj8PqDZKQ5IwvNe/1B9rSEhcDgDHUxotBKDJfRz5wDRVGU/khmdPEYYJsxphJARB4DLgY2RJUxQK79OY/u5MgpT1cghDHgcTvJcFt67fUHqW+zhCCNIA5CkObh7e+dhkM0PqAoyoGRTCEYDVRFbVdjZ0WO4nbgZRH5OpAFnBGvIhG5HrgeYMyYMYPe0EORcHzA43JGZhh7fUH2tHZa+7FdQa4Mygsyh6WNiqJ8MhjuCOOVwIPGmHLgPODvItKrTcaYe4wx840x80tKSoa8kcNBeMRQhrvbNdQVsEYNnTerjBtOGGkVTIuzToGiKMp+kEwhqAGiVjmh3N4XzZeAxwGMMe8CHqA4iW06bAhPJstI67YI2roC7G3zMb44ixtPHG0VdGUMVxMVRfmEkEwhWAFMFpHxIuLGCgY/26PMTuB0ABGZjiUE9Uls02FDeDKZJypY/O72fQRDhgnF2RCwXERqESiKcrAkTQiMMQGsFRRfAjZijQ5aLyJ3iMhFdrFbgetE5APgUeAa01+mtU8QH+9r7zOp3OZdrbxXuQ+wXUP24jLPra0j0+3k7CPKrEVpQC0CRVEOmqTmJDDGLAYW99j346jPG4AFyWzDocjmXa2c/es3+eF507nu5Akxx2qbvJz96zcj2xlpTtJd3Xp9zhFlZKe71CJQFGXQGO5gcUoSnvwVzhkUzdrqpphtT5oDiRoaeuz4QuuDWgSKogwSmqVsCPjzG9t5ek0tL9x8EmCN/gHYua89UubnizfidAguh+B0CDNG5vJhTTNuV6xWzxxlL0avFoGiKIOECsEQEF58PhgyOB1CW5e1xnC7L4gxBhHh5fW7yHC7GJnnYWJJFg99+Vj++X41U0fkxNQ1eUS29UEtAkVRBgkVgiGkscPHi+t2sbGuJbJvV0snpTkeapq85GW4aWjv4oSJxeRlpPHFBeN71ZHuslNJqEWgKMogoUIwhOxq7uRHT6+L2bdtTxsA/qBhr50+IvLWH8XXF06KXXgmbBGk6axiRVEODhWCIWRtdXOvfRvrWtixtz1m35jC3p37rWdNjd3hbbR+e/IHrX2KoqQmKgRDQJpT8AcN7+9sjOzzpDkIBA0/X7ypV/mKRHIHeRvBnQ0u92A2VVGUFESHjw4B4RQR0UKQl5HGqPz4gd6KOBZBL7yNkFEwKO1TFCW1USEYJH7z6la++MByAPa2dTHutuf52fMbmP/TV2jttEYJVdZ3u4Cy012UF/QWgiy3k4LMBBah9zZChrqFFEU5eFQIBokPqptYU2VNBluz0/p971s72NsWf+Ww7KjA7/UnT+CRL1sZussLMmMmkPWJWgSKogwSKgSDREO7jyavn2DIsGVP64Dlc9JdBENWrqEzpo/ghEnWkNGKwgTnBagQKIoySGiweJBo7PBhDDR7/ayvbel1fP7YAkSsReaXbt9HdrqLb589hXverOSoMZaL5/qTJzClxwSyPlEhUBRlkFAh6AdjDC+t382ZM0bgdPTvrmm08wc1dvjYEEcIrlkwjgtmj+Lfm3ZbQuBxMak0h//9zJGRMjeeNinRhqkQKIoyaKhrqB9eWLeLGx5axV/eruy3XCAYosUOCH9Y3cyOve29cgRlp1uaW5Dpjtk+IHxtEApARuGB16EoimKjQtAPLV4/AFt3t8U9Hs4Z1GSXA7j3rUpE4MZTY9/uczyxQhDePiDCk8nUIlAUZRBQIeiHTPutPdzhR7NldytH3fEyL63fFXELAayvbWHBxGJOnFwUUz473RolVJTtxuUQirIOYiKYCoGiKINIasYIXv85bFoMp94G0y/os1ggaC0gH08IHltehT9oeOi9j7mph2//+IlFzB1TwKPXHcdn73sPYyDbtgByPGk8+dUT4uYTiqF+Mzz9VQh09T7ms+cj6DwCRVEGgdQUgrWPQ+MOqFzSrxB02OsGhyeEPfTex+xq7uQbp0/mqdXVuF0O3t62l9OnlcacN3NULiLC8ROLGJHjYVdLJ1n2cpMAR1Yk0IHvfA9qVsGkM8AVJ8PomONg1FED16MoijIASRUCETkH+A3gBO4zxtzZ4/ivgNPszUyg1BiT/NfcTnsVMBPst1h4Afl22yIIZw4tyUmnscPPzadP5jevbeXtbftizossHgM8fN2xvPBhHXkZCcwWjrm47f65/G/gztq/cxVFUfaDpMUIRMQJ3A2cC8wArhSRGdFljDG3GGPmGGPmAL8D/pms9kQIhcBrC0Got8snmrBF0NM19F/PrmdknofPHjsGgA9rYpeXLMlJj3yeWJLNTQsnJzZbOBpvIzjdmmZaUZSkk0yL4BhgmzGmEkBEHgMuBjb0Uf5K4L+S2B6LrmbAmtFLqH+LoMNvCcC+dh/GGLLcTtp9QdwuB186cTylOel40hzsbukix+PizBkj6AqEBqed4XkC+ysgiqIo+0kyhWA0UBW1XQ0cG6+giIwFxgP/7uP49cD1AGPGjDm4Vnm7M4AOJARh15AvEGJXSyftviDfO2caXz11YqRMeUEm2/a0MWNkLr+8fM7Bta1nO3VUkKIoQ8ChMnz0CuAJY+I77Y0x9xhj5htj5peUlBzclWKEIDHXEBCZLVwa5fYBIqmko+MCg4K3USeMKYoyJAwoBCJyoYgciGDUABVR2+X2vnhcATx6ANfYf6KFYKBgsb/7+KZdViK5kh5C4LddQTNH5Q5SA8MXb1KLQFGUISGRDv4/gK0i8r8iMm0/6l4BTBaR8SLixursn+1ZyK6zAHh3P+o+cMKBYodrQIvAG2URbNltCUFpbqwQ5NtrB0wsHWBewP6iriFFUYaIAWMExpjPi0guVjD3QRExwAPAo8aYPvMtG2MCInIT8BLW8NH7jTHrReQOYKUxJiwKVwCPGWPMwd5MQoQtgszigYPFvgCj8zOoafKyOWwRZMcKwR0XH8Ex4ws5sjwZriGdMKYoSvJJKFhsjGkRkSeADOCbwKeB74jIb40xv+vnvMXA4h77ftxj+/b9bfRBERaCrIGFwOsLRoRgy+5WXA6J5AoKU5KTzhcXjB/cNga6wN+uFoGiKENCIjGCi0TkKWAJkAYcY4w5FzgSuDW5zUsC3kZw54ArPaFgcWGWm3SXg5CxAsWOAdJRD04bbfeVCoGiKENAIhbBpcCvjDFvRu80xnSIyJeS06wkEva9JxAj6PAFyXQ7Kch0s6ulk/JEFpUfrDaCCoGiKENCIsHi24Hl4Q0RyRCRcQDGmNeS0qpk0tkMnlxLCEz/k7+8/iAZbicFdqbQioIhEoJwCgzPIMcdFEVR4pCIEPwDiO4xg/a+w5NQwBIBcSRgEQTIdDvJTrcSxiW8nvDB4u+wfmt6CUVRhoBEhMBljIkk3Lc/H0Qy/WEmFASH03YN9R0sDoUMnf4QGW5XZGJZ+VBZBP5O63danKyjiqIog0wiQlAvIheFN0TkYmBv8pqUZEwQxDlgjCA8mSzT7YxkH60oGCKLIOC1fruG6HqKoqQ0iQSLbwAeFpHfA4KVP+iqpLYqmUQsAmfCQuAPWlMcwukkko5aBIqiDCGJTCjbDhwnItn2dvwFfA8XTKjbIugnWByeVZyR5uSPn5/Lo8t3MnqohEAtAkVRhpCEJpSJyPnATMATzqtvjLkjie1KHqEguNwDBovDcYFMt4vZ5fnMLh/CWb5qESiKMoQkMqHsT1j5hr6O5Rq6DBib5HYlj5gYQd/B4g6fJRKZUUtMDhlqESiKMoQkEiw+wRhzFdBojPkJcDwwJbnNSiIxo4ZiLYJQyOCzs4mGXUOetGEQAn+nZbE493N5S0VRlAMgESGw/RR0iMgowA+MTF6TkkzEInD2sgh+vngjF/3+bUIhE+UaGg6LoNOyBnR1MkVRhoBEYgT/EpF84P+A97HWebw3qa1KJqFQ96ihHusRrK1pZtOuVpZ/1ECHfxiFwN+h8QFFUYaMfoXAXpDmNWNME/CkiDwHeIwxzUPSumRggpbbJY5rqLrBmtH7+Ioqjp1grQ6WMSxC0KnxAUVRhox+XUPGmBBwd9R212EtAtAdI5DYeQThdYnTnMLidXXsaekCrFFDQ07AqxaBoihDRiIxgtdE5FKRT4jDuo9RQ3XNXkIG/uPoCjr9IRatrAKGyzWkFoGiKENHIkLwFawkc10i0iIirSLSkuR2JY+YmcXdQlDVYA3ZPH/WKEbnZ1Dd6EUE0l0HslzzQaIWgaIoQ8iAvZwxJscY4zDGuI0xufZ2Qiu1i8g5IrJZRLaJyG19lLlcRDaIyHoReWR/b2C/iR41FBUsrm604gMVhRmRdYkz05wMiyHk7wSXCoGiKEPDgA5wETk53v6eC9XEOc+JFV84E6gGVojIs8aYDVFlJgPfBxYYYxpFpHR/Gn9A9DGPoLrRi9MhlOV6IstRZgxHfAAsi8CTkNYqiqIcNIn0dN+J+uwBjgFWAQsHOO8YYJsxphJARB4DLgY2RJW5DrjbGNMIYIzZk2C7D5yQPWqoR7B4T2snxdluXE5HRAiGJT4AahEoijKkJJJ07sLobRGpAH6dQN2jsTKVhqkGju1RZopd5zuAE7jdGPNiz4pE5HrgeoAxY8YkcOl+MFEWgQmBMSDCntYuSnIsl1BhljWjd9iEIOCFNA0WK4oyNBxIJLQamD5I13cBk4FTgSuBe+3JazEYY+4xxsw3xswvKSk5uCuGomIE4W2gvrWL0hzrLTw/c5jX3VGLQFGUISSRGMHvsGYTgyUcc7BmGA9EDVARtV1u74umGlhmjPEDO0RkC5YwrEig/gPDRI0aAss95HSxp7WLI0ZZawQX2msUh/MODTmBTrUIFEUZMhKJEayM+hwAHjXGvJPAeSuAySIyHksArgA+26PM01iWwAMiUozlKqpMoO4DJxS1HgGACRIMGfa1dUVGC4VjBF3DJQR+r1oEiqIMGYkIwRNApzHWWEsRcYpIpjGmo7+TjDEBEbkJeAnL/3+/MWa9iNwBrDTGPGsfO0tENgBB4DvGmH0Hc0MDYqJmFgOEAuxr7yJkiMQICjKtGEGnv+801UkjFISQXy0CRVGGjESE4DXgDCC8MlkG8DJwwkAnGmMWA4t77Ptx1GcDfMv+GRpCUbmG7O36ViudRGkkWDyMFoE/vBaBWgSKogwNiQiBJ3p5SmNMm4hkJrFNyaVXjCDInlZrGGnEIrCFYEgtgqadULsauuxHrRaBoihDRCJC0C4ic40x7wOIyDzAm9xmJZFeo4YC1LdYQhAZNZRhuYYqCodQ7565EXZEzdHLHjF011YUJaVJRAi+CfxDRGqxlqosw1q68vDDGMBYbqGoYHF1k5VXaESuJQQup4P7rprPzNFDOLu3dTdMXAhn/RScbiiaNHTXVhQlpUlkQtkKEZkGTLV3bbaHex5+hJPM9QgWVzd2UJbrwR2VYO6MGUP8Ru5thLHHw4iZQ3tdRVFSnkQWr78RyDLGrDPGrAOyReRryW9aEggnmesRLK5u8FJRMIxhD2MsIcgoGL42KIqSsiQys/g6e4UyAOy8QNclr0lJJNoiiAoWVzV2UF44jMFZX7s1ZFSFQFGUYSARIXBGL0pjZxUd5hwMB0jEIugWAr/fx66WzuG1CLwN1u+MwuFrg6IoKUsiweIXgUUi8md7+yvAC8lrUhKJsQisW9/T0oExUF4wjBaBt9H6rRaBoijDQCJC8D2szJ832NtrsUYOHX4Ye4KYdAeL65vbASgfVotAhUBRlOEjkRXKQsAy4COsNQYWAhuT26wkEcci6PJZA6Cy04dpERpQIVAUZVjps/cTkSlYCeGuBPYCiwCMMacNTdOSQMyoIcsiCAYtIUhzDcOSlGFUCBRFGUb6ew3eBLwFXGCM2QYgIrcMSauSRZxRQ6FAAHCR5hyGRerDRISg11IMiqIoSae/3u8SoA54XUTuFZHTsWYWH77EjBqyNDAQsNJLuIdbCFwZml9IUZRhoU+LwBjzNPC0iGRhrTX8TaBURP4IPGWMeXmI2jh4xIkRnPretbzorqDs4SwYLjFoqVVrQFGUYSORFBPtwCPAIyJSAFyGNZLo8BOCOKOGAFrJwBROBNcwCUHRRBh38vBcW1GUlGe/hsrYs4rvsX8OP+LNLAZ+4f8sf730JtyetGFqmKIoyvAxjI7xYSDOqCGAZrKGN1isKIoyjCS19xORc0Rks4hsE5Hb4hy/RkTqRWSN/fPlZLYnXowAoMlkqxAoipKyJG0WlZ2T6G7gTKAaWCEizxpjNvQousgYc1Oy2hFDnFFDAK2OHJyOw3tAlKIoyoGSzNfgY4BtxphKY4wPeAxr9NHwEW89AsDp1NiAoiipSzKFYDRQFbVdbe/ryaUislZEnhCRingVicj1IrJSRFbW19cfeIuiRw1FxQjSnGoNKIqSugy3Y/xfwDhjzGzgFeCv8QoZY+4xxsw3xswvKSk58KtFLAIHe9oDkd3u4Ro2qiiKcgiQzB6wBoh+wy+390UwxuwzxnTZm/cB85LYnpgYwfUPr4ns1kCxoiipTDJ7wBXAZBEZLyJu4Arg2egCIjIyavMikp3VNCpGsLc9GNmtQqAoSiqTtFFDxpiAiNwEvAQ4gfuNMetF5A5gpTHmWeAbInIREAAagGuS1R6rUd0WQWfQbhUaI1AUJbVJahJ+Y8xiYHGPfT+O+vx94PvJbEMMtkUQxIEvZHX+XeJRi0BRlJQmtXpAe9SQ3wg+rCGjr2efT7oGixVFSWGGcVmuYcC2CAIhoZN0vlrxNK2hdNICA5ynKIryCSa1hMCOEfiM5RZqMRn4g0ZjBIqipDSp5ROxLQK/HR/wBUJ0BUOkqWtIUZQUJjUtgigh8AcNbrUIFEVJYVJLCMIWge0a6gqECIaMjhpSFCWlSS0hsEcNRSyCYIiQCoGiKClOaglB2CIIdruGjNFcQ4qipDapJQRxYgQGTTGhKEpqk1pCYFsEXVGuIUCDxYqipDSpJQQRi8Da9AWsD2oRKIqSyqSWEIQtgqgYgQg6j0BRlJQmtYQgPGrIAq4KrQAAEdpJREFUFoJAyABqESiKktqkVg8YtghM7G6NESiKksqklhCEYwTB2I5fLQJFUVKZ1OoBbYugMxi7W+cRKIqSyqRWD2jCweLY3WoRKIqSyiS1BxSRc0Rks4hsE5Hb+il3qYgYEZmfzPYQsoLFXYFY15BbhUBRlBQmaT2giDiBu4FzgRnAlSIyI065HOBmYFmy2hLBtgi8odjdaS4NFiuKkrok81X4GGCbMabSGOMDHgMujlPuv4H/ATqT2BaLUDhYHLvb7XQm/dKKoiiHKskUgtFAVdR2tb0vgojMBSqMMc/3V5GIXC8iK0VkZX19/YG3yARBnJEZxWGKs90HXqeiKMphzrA5x0XEAfwSuHWgssaYe4wx840x80tKSg78oqEgQRw8vGxnzO6SnPQDr1NRFOUwJ5lCUANURG2X2/vC5ABHAEtE5CPgOODZpAaMTZCA6X3LpbmepF1SURTlUCeZQrACmCwi40XEDVwBPBs+aIxpNsYUG2PGGWPGAe8BFxljViatRaEQQXoHhrPcGiNQFCV1SZoQGGMCwE3AS8BG4HFjzHoRuUNELkrWdfttUygQ1yIQ0VFDiqKkLklNOmeMWQws7rHvx32UPTWZbQHwBwIEU2wOnaIoykCkVK/Y2dmJL8USriqKogxESglBV1cn/h5CoF4hRVFSnZQTAp+JFYJ5YwqGqTWKoiiHBinlJ/H7uvDj4m/XHsOo/AyqGjqYq0KgKEqKk1JCEPB1ERAXJ00uRkSYVJo93E1SFEUZdlLKNWQCXYQkTYeLKoqiRJFSQkDIT8iRNtytUBRFOaRIKSGQoAqBoihKT1JKCBxGhUBRFKUnKRUsdoT8GJcKgaIcKvj9fqqrq+nsTP5yJKmCx+OhvLyctLTE+7qUEgJnyI9xqhAoyqFCdXU1OTk5jBs3TgdxDALGGPbt20d1dTXjx49P+LyUcg05jR8cugiNohwqdHZ2UlRUpCIwSIgIRUVF+21hpZgQBMCpQqAohxIqAoPLgTzPlBICl/EjLhUCRVGUaFJGCIwxuAioECiKEmHfvn3MmTOHOXPmUFZWxujRoyPbPp+v33NXrlzJN77xjQGvccIJJwxWc5NGygSLfcEQaQQQl65PrCiKRVFREWvWrAHg9ttvJzs7m29/+9uR44FAAJcrfjc5f/585s8feGXdpUuXDk5jk0jKCIHXFySTAA61CBTlkOQn/1rPhtqWQa1zxqhc/uvCmft1zjXXXIPH42H16tUsWLCAK664gptvvpnOzk4yMjJ44IEHmDp1KkuWLOGuu+7iueee4/bbb2fnzp1UVlayc+dOvvnNb0ashezsbNra2liyZAm33347xcXFrFu3jnnz5vHQQw8hIixevJhvfetbZGVlsWDBAiorK3nuuecG9Vn0RwoJQYB8CeJMU4tAUZT+qa6uZunSpTidTlpaWnjrrbdwuVy8+uqr/OAHP+DJJ5/sdc6mTZt4/fXXaW1tZerUqXz1q1/tNZZ/9erVrF+/nlGjRrFgwQLeeecd5s+fz1e+8hXefPNNxo8fz5VXXjlUtxkhqUIgIucAvwGcwH3GmDt7HL8BuBEIAm3A9caY/9/e/QdXVeZ3HH9/jSRBwsBmI5YhtAka+eECCQHcyg4aa8svh6w2CKHThrrtahZ3FMe6MouIIjNdoVvHiuyEIlBKvejqUjIT1l2jQ53ZrRJofgnLEtjsLIgY2SaGMZLEfvvHeRJvknsDCffmnuz5vmYyOec55577uQ8nPPd5zrnPPRaPLJ+526mSRliPwBg/Gug793hatmwZSUlJALS0tFBSUsLJkycRETo6OiI+ZsmSJaSkpJCSksK4ceM4f/48mZmZPfaZO3dud1lubi6NjY2kpaUxadKk7vv+i4uLKSsri+Or6ytuF4tFJAnYCiwCpgHFIjKt127/oarTVTUXeA74YbzyXOpqCOwagTHmMkaNGtW9/OSTT1JQUEB9fT3l5eVR79FPSfny/5akpCQ6OzsHtU8ixPOuoblAg6qeVtV2IAQUhu+gquEDgqMAjVeYNvePd22yNQTGmCvX0tLChAkTANi1a1fMjz958mROnz5NY2MjAPv27Yv5c1xOPBuCCcDvwtbPuLIeRGS1iJzC6xFEvBdLRL4tIlUiUtXU1DSoMJc+bwPgWrtGYIwZgMcff5y1a9eSl5cXl3fwI0eO5KWXXmLhwoXk5+czevRoxowZE/Pn6Y+oxudNuIgUAQtV9e/c+l8Dt6rqQ1H2XwksUNWS/o47e/ZsraqqGnCed947QsHBOzl7+xYmFPz9gB9vjIm948ePM3Xq1ETHSLiLFy+SlpaGqrJ69WpycnJYs2bNoI8XqV5F5IiqRrzfNZ49grPAxLD1TFcWTQj4ZrzCXLrkDQ0lJ6fG6ymMMWZQtm/fTm5uLrfccgstLS088MADQ/r88bxr6DCQIyLZeA3ACmBl+A4ikqOqJ93qEuAkcdLefgmA5BQbGjLG+MuaNWuuqgdwteLWEKhqp4g8BLyJd/voy6r6gYg8A1Sp6gHgIRG5C+gA/hfod1joanR09wisITDGmHBx/RyBqlYAFb3K1octPxzP5w837YaRACSnjByqpzTGmGEhMJPOTb3euzZgHygzxpieAtMQ8IWbSdC+j8AYY3oIUEPgPhZuDYExxikoKODNN9/sUfb8889TWloacf877riDrtvXFy9eTHNzc599NmzYwJYtW/p93v3793Ps2Jez6axfv5633nproPFjJkANgXfXEPadxcYYp7i4mFAo1KMsFApd0cRvFRUVjB07dlDP27sheOaZZ7jrrrsGdaxYCMzsozY0ZIzPHXwCPqqL7TH/aDos+seom4uKili3bh3t7e0kJyfT2NjIhx9+yCuvvMKjjz5KW1sbRUVFPP30030em5WVRVVVFRkZGWzatIndu3czbtw4Jk6cSH5+PuB9PqCsrIz29nZuuukm9uzZQ3V1NQcOHODQoUM8++yzvP7662zcuJG7776boqIiKisreeyxx+js7GTOnDls27aNlJQUsrKyKCkpoby8nI6ODl577TWmTJkSk2oKUI/AhoaMMT2lp6czd+5cDh48CHi9gfvuu49NmzZRVVVFbW0thw4dora2Nuoxjhw5QigUorq6moqKCg4fPty97d577+Xw4cPU1NQwdepUduzYwW233cbSpUvZvHkz1dXV3Hjjjd37f/7556xatYp9+/ZRV1dHZ2cn27Zt696ekZHB0aNHKS0tvezw00AEsEdgQ0PG+FI/79zjqWt4qLCwkFAoxI4dO3j11VcpKyujs7OTc+fOcezYMWbMmBHx8e+++y733HMP1113HQBLly7t3lZfX8+6detobm7m4sWLLFiwoN8sJ06cIDs7m5tvvhmAkpIStm7dyiOPPAJ4DQtAfn4+b7zxxlW/9i4B6hHY0JAxpq/CwkIqKys5evQon332Genp6WzZsoXKykpqa2tZsmRJ1KmnL2fVqlW8+OKL1NXV8dRTTw36OF26prGO9RTWAWoIbGjIGNNXWloaBQUF3H///RQXF/Ppp58yatQoxowZw/nz57uHjaKZP38++/fvp62tjdbWVsrLy7u3tba2Mn78eDo6Oti7d293+ejRo2ltbe1zrMmTJ9PY2EhDQwMAe/bs4fbbb4/RK40uQA2BDQ0ZYyIrLi6mpqaG4uJiZs6cSV5eHlOmTGHlypXMmzev38fOmjWL5cuXM3PmTBYtWsScOXO6t23cuJFbb72VefPm9biwu2LFCjZv3kxeXh6nTp3qLk9NTWXnzp0sW7aM6dOnc8011/Dggw/G/gX3ErdpqONlsNNQ86sKqA3Bvf8K9gX2xviCTUMdHwOdhjo4F4unLPZ+jDHG9BCcoSFjjDERWUNgjEmo4TY87XeDqU9rCIwxCZOamsqFCxesMYgRVeXChQukpg7smxiDc43AGOM7mZmZnDlzhqampkRH+YORmppKZmbmgB5jDYExJmFGjBhBdnZ2omMEng0NGWNMwFlDYIwxAWcNgTHGBNyw+2SxiDQBvx3kwzOAT2IYJ96GW14Yfpktb3xZ3vgaSN4/UdXrI20Ydg3B1RCRqmgfsfaj4ZYXhl9myxtflje+YpXXhoaMMSbgrCEwxpiAC1pDUJboAAM03PLC8MtseePL8sZXTPIG6hqBMcaYvoLWIzDGGNOLNQTGGBNwgWkIRGShiJwQkQYReSLReSIRkUYRqRORahGpcmXpIvJzETnpfn8lgfleFpGPRaQ+rCxiPvG84Oq7VkRm+STvBhE56+q4WkQWh21b6/KeEJEFCcg7UUTeEZFjIvKBiDzsyn1Zx/3k9WUdi0iqiLwvIjUu79OuPFtE3nO59olIsitPcesNbnuWT/LuEpHfhNVvrisf/Pmgqn/wP0AScAqYBCQDNcC0ROeKkLMRyOhV9hzwhFt+AvhBAvPNB2YB9ZfLBywGDgICfB14zyd5NwCPRdh3mjsvUoBsd74kDXHe8cAstzwa+LXL5cs67ievL+vY1VOaWx4BvOfq7VVghSv/EVDqlr8D/MgtrwD2DXH9Rsu7CyiKsP+gz4eg9AjmAg2qelpV24EQUJjgTFeqENjtlncD30xUEFX9L+D3vYqj5SsE/k09/w2MFZHxQ5PUEyVvNIVASFUvqepvgAa882bIqOo5VT3qlluB48AEfFrH/eSNJqF17Orpolsd4X4UuBP4sSvvXb9d9f5j4M9ERIYobn95oxn0+RCUhmAC8Luw9TP0f8ImigI/E5EjIvJtV3aDqp5zyx8BNyQmWlTR8vm5zh9yXeeXw4bafJXXDUPk4b0L9H0d98oLPq1jEUkSkWrgY+DneL2SZlXtjJCpO6/b3gJ8NZF5VbWrfje5+v1nEUnpnde54voNSkMwXHxDVWcBi4DVIjI/fKN6/T/f3u/r93zONuBGIBc4B/xTYuP0JSJpwOvAI6r6afg2P9ZxhLy+rWNV/UJVc4FMvN7IlARH6lfvvCLyNWAtXu45QDrwvat9nqA0BGeBiWHrma7MV1T1rPv9MfATvBP1fFf3zv3+OHEJI4qWz5d1rqrn3R/X/wHb+XJowhd5RWQE3n+qe1X1DVfs2zqOlNfvdQygqs3AO8Cf4g2hdH1JV3im7rxu+xjgwhBHBXrkXeiG5FRVLwE7iUH9BqUhOAzkuLsDkvEu/BxIcKYeRGSUiIzuWgb+AqjHy1nidisB/jMxCaOKlu8A8DfuToavAy1hwxsJ02vM9B68OgYv7wp3p0g2kAO8P8TZBNgBHFfVH4Zt8mUdR8vr1zoWketFZKxbHgn8Od51jXeAIrdb7/rtqvci4G3XI0tk3l+FvSkQvOsZ4fU7uPNhKK+CJ/IH74r6r/HGBL+f6DwR8k3Cu6OiBvigKyPemGQlcBJ4C0hPYMZX8Lr6HXjjj9+Klg/vzoWtrr7rgNk+ybvH5al1fzjjw/b/vst7AliUgLzfwBv2qQWq3c9iv9ZxP3l9WcfADOB/XK56YL0rn4TXIDUArwEprjzVrTe47ZN8kvdtV7/1wL/z5Z1Fgz4fbIoJY4wJuKAMDRljjInCGgJjjAk4awiMMSbgrCEwxpiAs4bAGGMCzhoCY3oRkS/CZnaslhjOVisiWRI2G6oxfnDt5XcxJnDa1PtYvzGBYD0CY66QeN8X8Zx43xnxvojc5MqzRORtNwlYpYj8sSu/QUR+4uaTrxGR29yhkkRku5tj/mfuU6PGJIw1BMb0NbLX0NDysG0tqjodeBF43pX9C7BbVWcAe4EXXPkLwCFVnYn3vQgfuPIcYKuq3gI0A38Z59djTL/sk8XG9CIiF1U1LUJ5I3Cnqp52k619pKpfFZFP8KZR6HDl51Q1Q0SagEz1JgfrOkYW3nTCOW79e8AIVX02/q/MmMisR2DMwGiU5YG4FLb8BXatziSYNQTGDMzysN+/dMu/wJvRFuCvgHfdciVQCt1fMDJmqEIaMxD2TsSYvka6b4Xq8lNV7bqF9CsiUov3rr7YlX0X2Cki/wA0AX/ryh8GykTkW3jv/EvxZkM1xlfsGoExV8hdI5itqp8kOosxsWRDQ8YYE3DWIzDGmICzHoExxgScNQTGGBNw1hAYY0zAWUNgjDEBZw2BMcYE3P8DMI6linjpjwgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w5NOgER-QPL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "508de15c-c43b-4da9-8058-da21f13e85c6"
      },
      "source": [
        "plt.plot(call_history.history['loss'])\n",
        "plt.plot(call_history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsBmI_qM5CYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e5141c-6ad8-4163-c23c-369c15d8e424"
      },
      "source": [
        "# Evaluate the model on the test set\n",
        "\n",
        "test_loss, test_acc = call_model.evaluate(test_data, test_targets, verbose=0)\n",
        "print(\"Test loss: {:.3f}\\nTest accuracy: {:.2f}%\".format(test_loss, 100 * test_acc))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.062\n",
            "Test accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqBMocM0-QPM"
      },
      "source": [
        "Congratulations for completing this programming assignment! In the next week of the course we will learn how to save and load pre-trained models."
      ]
    }
  ]
}